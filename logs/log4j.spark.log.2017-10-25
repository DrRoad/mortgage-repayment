17/10/25 20:46:03 INFO SparkContext: Running Spark version 2.1.0
17/10/25 20:46:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 20:46:05 INFO SecurityManager: Changing view acls to: scibr
17/10/25 20:46:05 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 20:46:05 INFO SecurityManager: Changing view acls groups to: 
17/10/25 20:46:05 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 20:46:05 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 20:46:06 INFO Utils: Successfully started service 'sparkDriver' on port 58330.
17/10/25 20:46:06 INFO SparkEnv: Registering MapOutputTracker
17/10/25 20:46:07 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 20:46:07 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 20:46:07 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 20:46:07 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-958b9e85-1cee-4e0a-83b9-796fc7a8a958
17/10/25 20:46:07 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 20:46:07 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 20:46:07 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/25 20:46:07 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/25 20:46:08 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:58330/jars/sparklyr-2.1-2.11.jar with timestamp 1508931968011
17/10/25 20:46:08 INFO Executor: Starting executor ID driver on host localhost
17/10/25 20:46:08 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58356.
17/10/25 20:46:08 INFO NettyBlockTransferService: Server created on 127.0.0.1:58356
17/10/25 20:46:08 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 20:46:08 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 58356, None)
17/10/25 20:46:08 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:58356 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 58356, None)
17/10/25 20:46:08 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 58356, None)
17/10/25 20:46:08 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 58356, None)
17/10/25 20:46:10 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/25 20:46:10 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/25 20:46:10 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/25 20:46:12 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/25 20:46:12 INFO ObjectStore: ObjectStore, initialize called
17/10/25 20:46:13 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/25 20:46:13 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/25 20:46:16 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/25 20:46:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 20:46:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 20:46:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 20:46:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 20:46:18 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/25 20:46:18 INFO ObjectStore: Initialized ObjectStore
17/10/25 20:46:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/25 20:46:20 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/25 20:46:20 INFO HiveMetaStore: Added admin role in metastore
17/10/25 20:46:20 INFO HiveMetaStore: Added public role in metastore
17/10/25 20:46:20 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/25 20:46:20 INFO HiveMetaStore: 0: get_all_databases
17/10/25 20:46:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/25 20:46:20 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/25 20:46:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/25 20:46:20 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 20:46:21 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/697023ad-f50f-4e23-9fec-6c47c4d02f4e_resources
17/10/25 20:46:21 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/697023ad-f50f-4e23-9fec-6c47c4d02f4e
17/10/25 20:46:21 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/697023ad-f50f-4e23-9fec-6c47c4d02f4e
17/10/25 20:46:21 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/697023ad-f50f-4e23-9fec-6c47c4d02f4e/_tmp_space.db
17/10/25 20:46:21 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/25 20:46:21 INFO HiveMetaStore: 0: get_database: default
17/10/25 20:46:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 20:46:21 INFO HiveMetaStore: 0: get_database: global_temp
17/10/25 20:46:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/25 20:46:21 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/25 20:46:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 20:46:27 INFO HiveMetaStore: 0: get_database: default
17/10/25 20:46:27 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 20:46:27 INFO HiveMetaStore: 0: get_database: default
17/10/25 20:46:27 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 20:46:27 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 20:46:27 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 20:46:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 20:46:28 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 20:46:28 INFO HiveMetaStore: 0: get_database: default
17/10/25 20:46:28 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 20:46:28 INFO HiveMetaStore: 0: get_database: default
17/10/25 20:46:28 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 20:46:28 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 20:46:28 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 20:52:52 INFO SparkContext: Running Spark version 2.1.0
17/10/25 20:52:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 20:52:53 INFO SecurityManager: Changing view acls to: scibr
17/10/25 20:52:53 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 20:52:53 INFO SecurityManager: Changing view acls groups to: 
17/10/25 20:52:53 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 20:52:53 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 20:52:53 INFO Utils: Successfully started service 'sparkDriver' on port 59047.
17/10/25 20:52:53 INFO SparkEnv: Registering MapOutputTracker
17/10/25 20:52:53 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 20:52:53 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 20:52:53 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 20:52:53 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-7e45f377-9d55-48c0-9ba0-cf87e7f4ebd5
17/10/25 20:52:53 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 20:52:53 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 20:52:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/10/25 20:52:53 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/10/25 20:52:53 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/10/25 20:52:53 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:59047/jars/sparklyr-2.1-2.11.jar with timestamp 1508932373976
17/10/25 20:52:54 INFO Executor: Starting executor ID driver on host localhost
17/10/25 20:52:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 59069.
17/10/25 20:52:54 INFO NettyBlockTransferService: Server created on 127.0.0.1:59069
17/10/25 20:52:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 20:52:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 59069, None)
17/10/25 20:52:54 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:59069 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 59069, None)
17/10/25 20:52:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 59069, None)
17/10/25 20:52:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 59069, None)
17/10/25 20:53:08 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 20:53:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/10/25 20:53:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 20:53:08 INFO MemoryStore: MemoryStore cleared
17/10/25 20:53:08 INFO BlockManager: BlockManager stopped
17/10/25 20:53:08 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 20:53:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 20:53:09 INFO SparkContext: Successfully stopped SparkContext
17/10/25 20:53:09 INFO ShutdownHookManager: Shutdown hook called
17/10/25 20:53:09 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-20966718-0c83-491c-85c7-2a2dd9f5c12c
17/10/25 21:07:59 INFO SparkContext: Running Spark version 2.1.0
17/10/25 21:07:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 21:07:59 INFO SecurityManager: Changing view acls to: scibr
17/10/25 21:07:59 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 21:07:59 INFO SecurityManager: Changing view acls groups to: 
17/10/25 21:07:59 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 21:07:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 21:08:00 INFO Utils: Successfully started service 'sparkDriver' on port 60713.
17/10/25 21:08:00 INFO SparkEnv: Registering MapOutputTracker
17/10/25 21:08:00 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 21:08:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 21:08:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 21:08:00 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-2654fdfa-bcc9-4e27-9cc2-ba9f2e02b2a8
17/10/25 21:08:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 21:08:00 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 21:08:00 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/10/25 21:08:00 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/10/25 21:08:00 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/10/25 21:08:00 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:60713/jars/sparklyr-2.1-2.11.jar with timestamp 1508933280445
17/10/25 21:08:00 INFO Executor: Starting executor ID driver on host localhost
17/10/25 21:08:00 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60735.
17/10/25 21:08:00 INFO NettyBlockTransferService: Server created on 127.0.0.1:60735
17/10/25 21:08:00 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 21:08:00 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60735, None)
17/10/25 21:08:00 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60735 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60735, None)
17/10/25 21:08:00 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60735, None)
17/10/25 21:08:00 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60735, None)
17/10/25 21:08:12 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 21:08:12 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/10/25 21:08:12 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 21:08:12 INFO MemoryStore: MemoryStore cleared
17/10/25 21:08:12 INFO BlockManager: BlockManager stopped
17/10/25 21:08:12 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 21:08:12 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 21:08:12 INFO SparkContext: Successfully stopped SparkContext
17/10/25 21:08:12 INFO ShutdownHookManager: Shutdown hook called
17/10/25 21:08:12 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-cac1b40d-a983-4622-a239-a89b4e207c01
17/10/25 21:08:57 INFO SparkContext: Running Spark version 2.1.0
17/10/25 21:08:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 21:08:58 INFO SecurityManager: Changing view acls to: scibr
17/10/25 21:08:58 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 21:08:58 INFO SecurityManager: Changing view acls groups to: 
17/10/25 21:08:58 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 21:08:58 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 21:08:58 INFO Utils: Successfully started service 'sparkDriver' on port 60823.
17/10/25 21:08:58 INFO SparkEnv: Registering MapOutputTracker
17/10/25 21:08:58 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 21:08:58 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 21:08:58 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 21:08:58 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-aaf0ba1d-6f06-4c53-8847-0d2b6b8fcec7
17/10/25 21:08:58 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 21:08:58 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 21:08:58 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
17/10/25 21:08:58 INFO Utils: Successfully started service 'SparkUI' on port 4041.
17/10/25 21:08:58 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4041
17/10/25 21:08:58 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:60823/jars/sparklyr-2.1-2.11.jar with timestamp 1508933338739
17/10/25 21:08:58 INFO Executor: Starting executor ID driver on host localhost
17/10/25 21:08:58 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 60844.
17/10/25 21:08:58 INFO NettyBlockTransferService: Server created on 127.0.0.1:60844
17/10/25 21:08:58 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 21:08:58 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 60844, None)
17/10/25 21:08:58 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:60844 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 60844, None)
17/10/25 21:08:58 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 60844, None)
17/10/25 21:08:58 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 60844, None)
17/10/25 21:09:10 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/25 21:09:10 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/25 21:09:10 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/25 21:09:10 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/25 21:09:10 INFO ObjectStore: ObjectStore, initialize called
17/10/25 21:09:11 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/25 21:09:11 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/25 21:09:12 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/25 21:09:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:09:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:09:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:09:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:09:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/25 21:09:14 INFO ObjectStore: Initialized ObjectStore
17/10/25 21:09:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/25 21:09:14 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/25 21:09:14 INFO HiveMetaStore: Added admin role in metastore
17/10/25 21:09:14 INFO HiveMetaStore: Added public role in metastore
17/10/25 21:09:14 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/25 21:09:14 INFO HiveMetaStore: 0: get_all_databases
17/10/25 21:09:14 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/25 21:09:14 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/25 21:09:14 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/25 21:09:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:09:15 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/0e5bb3bd-5ea5-45d3-9bf0-0086c8136e16_resources
17/10/25 21:09:15 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0e5bb3bd-5ea5-45d3-9bf0-0086c8136e16
17/10/25 21:09:15 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/0e5bb3bd-5ea5-45d3-9bf0-0086c8136e16
17/10/25 21:09:15 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0e5bb3bd-5ea5-45d3-9bf0-0086c8136e16/_tmp_space.db
17/10/25 21:09:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/25 21:09:15 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:09:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:09:15 INFO HiveMetaStore: 0: get_database: global_temp
17/10/25 21:09:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/25 21:09:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/25 21:09:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:09:17 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:09:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:09:17 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:09:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:09:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:09:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:09:21 INFO CodeGenerator: Code generated in 1474.987132 ms
17/10/25 21:09:23 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:09:23 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:09:23 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/25 21:09:23 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:09:23 INFO DAGScheduler: Missing parents: List()
17/10/25 21:09:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55), which has no missing parents
17/10/25 21:09:24 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/25 21:09:25 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/25 21:09:25 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:60844 (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:09:25 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[5] at map at utils.scala:55)
17/10/25 21:09:25 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/25 21:09:25 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/10/25 21:09:25 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/25 21:09:25 INFO Executor: Fetching spark://127.0.0.1:60823/jars/sparklyr-2.1-2.11.jar with timestamp 1508933338739
17/10/25 21:09:25 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:60823 after 112 ms (0 ms spent in bootstraps)
17/10/25 21:09:25 INFO Utils: Fetching spark://127.0.0.1:60823/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16\fetchFileTemp4434853381580502236.tmp
17/10/25 21:09:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09/userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16/sparklyr-2.1-2.11.jar to class loader
17/10/25 21:09:26 INFO CodeGenerator: Code generated in 19.134083 ms
17/10/25 21:09:26 INFO CodeGenerator: Code generated in 17.884992 ms
17/10/25 21:09:27 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/25 21:09:27 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1768 ms on localhost (executor driver) (1/1)
17/10/25 21:09:27 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/25 21:09:27 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 2.007 s
17/10/25 21:09:27 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 3.784635 s
17/10/25 21:09:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:09:44 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:60844 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:09:46 INFO SparkSqlParser: Parsing command: loan
17/10/25 21:09:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:09:46 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/25 21:09:46 INFO SparkSqlParser: Parsing command: `loan`
17/10/25 21:09:46 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:09:46 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:09:46 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: string ... 17 more fields>
17/10/25 21:09:46 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:09:47 INFO CodeGenerator: Code generated in 6.32038 ms
17/10/25 21:09:47 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/25 21:09:47 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/25 21:09:47 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:60844 (size: 23.9 KB, free: 366.3 MB)
17/10/25 21:09:47 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:09:47 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28629131 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:09:49 INFO CodeGenerator: Code generated in 34.261736 ms
17/10/25 21:09:49 INFO CodeGenerator: Code generated in 10.57006 ms
17/10/25 21:09:49 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:09:49 INFO DAGScheduler: Registering RDD 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:09:49 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:09:49 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:09:49 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/25 21:09:49 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/25 21:09:49 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:09:49 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/25 21:09:49 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 366.0 MB)
17/10/25 21:09:49 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:60844 (size: 11.2 KB, free: 366.3 MB)
17/10/25 21:09:49 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:49 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[12] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:09:49 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/25 21:09:49 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:09:49 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:09:49 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:09:49 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:09:49 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/25 21:09:49 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/25 21:09:49 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/25 21:09:49 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/25 21:09:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 57258262-85887393, partition values: [empty row]
17/10/25 21:09:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 85887393-110322221, partition values: [empty row]
17/10/25 21:09:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 0-28629131, partition values: [empty row]
17/10/25 21:09:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 28629131-57258262, partition values: [empty row]
17/10/25 21:09:51 INFO CodeGenerator: Code generated in 30.31432 ms
17/10/25 21:09:52 INFO ContextCleaner: Cleaned accumulator 54
17/10/25 21:09:54 INFO MemoryStore: Block rdd_9_3 stored as values in memory (estimated size 18.4 MB, free 347.5 MB)
17/10/25 21:09:54 INFO BlockManagerInfo: Added rdd_9_3 in memory on 127.0.0.1:60844 (size: 18.4 MB, free: 347.8 MB)
17/10/25 21:09:54 INFO CodeGenerator: Code generated in 5.207796 ms
17/10/25 21:09:54 INFO CodeGenerator: Code generated in 49.246722 ms
17/10/25 21:09:55 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/25 21:09:55 INFO MemoryStore: Block rdd_9_2 stored as values in memory (estimated size 21.6 MB, free 325.9 MB)
17/10/25 21:09:55 INFO BlockManagerInfo: Added rdd_9_2 in memory on 127.0.0.1:60844 (size: 21.6 MB, free: 326.3 MB)
17/10/25 21:09:55 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2983 bytes result sent to driver
17/10/25 21:09:55 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 5311 ms on localhost (executor driver) (1/4)
17/10/25 21:09:55 INFO MemoryStore: Block rdd_9_1 stored as values in memory (estimated size 21.6 MB, free 304.4 MB)
17/10/25 21:09:55 INFO BlockManagerInfo: Added rdd_9_1 in memory on 127.0.0.1:60844 (size: 21.6 MB, free: 304.7 MB)
17/10/25 21:09:55 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 5331 ms on localhost (executor driver) (2/4)
17/10/25 21:09:55 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2983 bytes result sent to driver
17/10/25 21:09:55 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 5349 ms on localhost (executor driver) (3/4)
17/10/25 21:09:55 INFO MemoryStore: Block rdd_9_0 stored as values in memory (estimated size 21.6 MB, free 282.8 MB)
17/10/25 21:09:55 INFO BlockManagerInfo: Added rdd_9_0 in memory on 127.0.0.1:60844 (size: 21.6 MB, free: 283.1 MB)
17/10/25 21:09:55 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2893 bytes result sent to driver
17/10/25 21:09:55 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5379 ms on localhost (executor driver) (4/4)
17/10/25 21:09:55 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/25 21:09:55 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 5.380 s
17/10/25 21:09:55 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:09:55 INFO DAGScheduler: running: Set()
17/10/25 21:09:55 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/25 21:09:55 INFO DAGScheduler: failed: Set()
17/10/25 21:09:55 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 282.8 MB)
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.8 MB)
17/10/25 21:09:56 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[15] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/25 21:09:56 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:09:56 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/25 21:09:56 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 25 ms
17/10/25 21:09:56 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2039 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 231 ms on localhost (executor driver) (1/1)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/25 21:09:56 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.232 s
17/10/25 21:09:56 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 6.639820 s
17/10/25 21:09:56 INFO CodeGenerator: Code generated in 15.959524 ms
17/10/25 21:09:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:09:56 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/25 21:09:56 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:60844 in memory (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:60844 in memory (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO ContextCleaner: Cleaned shuffle 0
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 66
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 65
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 64
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 63
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 62
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 61
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 60
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 59
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 58
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 57
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 56
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 55
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 1
17/10/25 21:09:56 INFO ContextCleaner: Cleaned accumulator 0
17/10/25 21:09:56 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:09:56 INFO DAGScheduler: Registering RDD 19 (collect at utils.scala:196)
17/10/25 21:09:56 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:09:56 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/25 21:09:56 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/25 21:09:56 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/25 21:09:56 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:196), which has no missing parents
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 282.8 MB)
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.8 MB)
17/10/25 21:09:56 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:60844 (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:56 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[19] at collect at utils.scala:196)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/25 21:09:56 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:09:56 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:09:56 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:09:56 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:09:56 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/25 21:09:56 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/25 21:09:56 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/25 21:09:56 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/25 21:09:56 INFO BlockManager: Found block rdd_9_1 locally
17/10/25 21:09:56 INFO BlockManager: Found block rdd_9_3 locally
17/10/25 21:09:56 INFO BlockManager: Found block rdd_9_2 locally
17/10/25 21:09:56 INFO BlockManager: Found block rdd_9_0 locally
17/10/25 21:09:56 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2109 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 34 ms on localhost (executor driver) (1/4)
17/10/25 21:09:56 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2098 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 44 ms on localhost (executor driver) (2/4)
17/10/25 21:09:56 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 52 ms on localhost (executor driver) (3/4)
17/10/25 21:09:56 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 53 ms on localhost (executor driver) (4/4)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/25 21:09:56 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.056 s
17/10/25 21:09:56 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:09:56 INFO DAGScheduler: running: Set()
17/10/25 21:09:56 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/25 21:09:56 INFO DAGScheduler: failed: Set()
17/10/25 21:09:56 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:196), which has no missing parents
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 282.8 MB)
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.8 MB)
17/10/25 21:09:56 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at collect at utils.scala:196)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/25 21:09:56 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:09:56 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/25 21:09:56 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:09:56 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/25 21:09:56 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/25 21:09:56 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/25 21:09:56 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/25 21:09:56 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.084725 s
17/10/25 21:09:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:09:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz1`
WHERE (0 = 1)
17/10/25 21:09:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:09:56 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:09:56 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:09:56 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:09:56 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:09:56 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:09:56 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:09:56 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:09:56 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:09:56 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:09:56 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/25 21:09:56 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:09:56 INFO DAGScheduler: Missing parents: List()
17/10/25 21:09:56 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[28] at map at utils.scala:55), which has no missing parents
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 282.8 MB)
17/10/25 21:09:56 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 282.8 MB)
17/10/25 21:09:56 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:60844 (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:09:56 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/25 21:09:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[28] at map at utils.scala:55)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/25 21:09:56 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/25 21:09:56 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/25 21:09:56 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1148 bytes result sent to driver
17/10/25 21:09:56 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.009 s
17/10/25 21:09:56 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.014902 s
17/10/25 21:09:56 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 9 ms on localhost (executor driver) (1/1)
17/10/25 21:09:56 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/25 21:10:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:06 INFO SparkSqlParser: Parsing command: payment
17/10/25 21:10:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:06 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/25 21:10:06 INFO SparkSqlParser: Parsing command: `payment`
17/10/25 21:10:06 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:10:06 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:10:06 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: string, principal: double ... 7 more fields>
17/10/25 21:10:06 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:10:06 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 282.5 MB)
17/10/25 21:10:06 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 282.5 MB)
17/10/25 21:10:06 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:60844 (size: 23.9 KB, free: 283.1 MB)
17/10/25 21:10:06 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:10:06 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14622813 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:10:06 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:10:06 INFO DAGScheduler: Registering RDD 35 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:06 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:10:06 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/25 21:10:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/25 21:10:06 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:10:06 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 282.4 MB)
17/10/25 21:10:06 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 282.4 MB)
17/10/25 21:10:06 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:60844 (size: 9.4 KB, free: 283.1 MB)
17/10/25 21:10:06 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:06 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[35] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:06 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/25 21:10:06 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:10:06 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:10:06 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:10:06 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:10:06 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/25 21:10:06 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/25 21:10:06 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/25 21:10:06 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/25 21:10:06 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 14622813-29245626, partition values: [empty row]
17/10/25 21:10:06 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 43868439-54296951, partition values: [empty row]
17/10/25 21:10:06 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 0-14622813, partition values: [empty row]
17/10/25 21:10:06 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 29245626-43868439, partition values: [empty row]
17/10/25 21:10:06 INFO CodeGenerator: Code generated in 15.366283 ms
17/10/25 21:10:06 INFO ContextCleaner: Cleaned accumulator 416
17/10/25 21:10:06 INFO ContextCleaner: Cleaned accumulator 235
17/10/25 21:10:06 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:60844 in memory (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:10:06 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:60844 in memory (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:10:06 INFO ContextCleaner: Cleaned accumulator 417
17/10/25 21:10:06 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:60844 in memory (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:10:06 INFO ContextCleaner: Cleaned accumulator 470
17/10/25 21:10:07 INFO MemoryStore: Block rdd_32_3 stored as values in memory (estimated size 4.5 MB, free 278.0 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added rdd_32_3 in memory on 127.0.0.1:60844 (size: 4.5 MB, free: 278.6 MB)
17/10/25 21:10:07 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1171 ms on localhost (executor driver) (1/4)
17/10/25 21:10:07 INFO MemoryStore: Block rdd_32_0 stored as values in memory (estimated size 6.3 MB, free 271.7 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added rdd_32_0 in memory on 127.0.0.1:60844 (size: 6.3 MB, free: 272.3 MB)
17/10/25 21:10:07 INFO MemoryStore: Block rdd_32_2 stored as values in memory (estimated size 6.2 MB, free 265.4 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added rdd_32_2 in memory on 127.0.0.1:60844 (size: 6.2 MB, free: 266.0 MB)
17/10/25 21:10:07 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 1427 ms on localhost (executor driver) (2/4)
17/10/25 21:10:07 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 1438 ms on localhost (executor driver) (3/4)
17/10/25 21:10:07 INFO MemoryStore: Block rdd_32_1 stored as values in memory (estimated size 6.3 MB, free 259.1 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added rdd_32_1 in memory on 127.0.0.1:60844 (size: 6.3 MB, free: 259.7 MB)
17/10/25 21:10:07 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2983 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 1667 ms on localhost (executor driver) (4/4)
17/10/25 21:10:07 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/25 21:10:07 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 1.670 s
17/10/25 21:10:07 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:10:07 INFO DAGScheduler: running: Set()
17/10/25 21:10:07 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/25 21:10:07 INFO DAGScheduler: failed: Set()
17/10/25 21:10:07 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:10:07 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 259.1 MB)
17/10/25 21:10:07 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.1 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:10:07 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:07 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/25 21:10:07 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:10:07 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/25 21:10:07 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:10:07 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:10:07 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1960 bytes result sent to driver
17/10/25 21:10:07 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/25 21:10:07 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 1.692633 s
17/10/25 21:10:07 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:10:07 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/25 21:10:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:07 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/25 21:10:07 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:10:07 INFO DAGScheduler: Registering RDD 42 (collect at utils.scala:196)
17/10/25 21:10:07 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:10:07 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/25 21:10:07 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/25 21:10:07 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/25 21:10:07 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[42] at collect at utils.scala:196), which has no missing parents
17/10/25 21:10:07 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 259.1 MB)
17/10/25 21:10:07 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 259.1 MB)
17/10/25 21:10:07 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:60844 (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:10:07 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:07 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[42] at collect at utils.scala:196)
17/10/25 21:10:07 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/25 21:10:07 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:10:07 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:10:07 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:10:07 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:10:07 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/25 21:10:07 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/25 21:10:07 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/25 21:10:07 INFO BlockManager: Found block rdd_32_1 locally
17/10/25 21:10:07 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/25 21:10:07 INFO BlockManager: Found block rdd_32_3 locally
17/10/25 21:10:07 INFO BlockManager: Found block rdd_32_0 locally
17/10/25 21:10:07 INFO BlockManager: Found block rdd_32_2 locally
17/10/25 21:10:07 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 33 ms on localhost (executor driver) (1/4)
17/10/25 21:10:07 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2098 bytes result sent to driver
17/10/25 21:10:07 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 40 ms on localhost (executor driver) (2/4)
17/10/25 21:10:08 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2019 bytes result sent to driver
17/10/25 21:10:08 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 43 ms on localhost (executor driver) (3/4)
17/10/25 21:10:08 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2098 bytes result sent to driver
17/10/25 21:10:08 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 49 ms on localhost (executor driver) (4/4)
17/10/25 21:10:08 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.051 s
17/10/25 21:10:08 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:10:08 INFO DAGScheduler: running: Set()
17/10/25 21:10:08 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/25 21:10:08 INFO DAGScheduler: failed: Set()
17/10/25 21:10:08 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/25 21:10:08 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[45] at collect at utils.scala:196), which has no missing parents
17/10/25 21:10:08 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 259.1 MB)
17/10/25 21:10:08 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.0 MB)
17/10/25 21:10:08 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:10:08 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[45] at collect at utils.scala:196)
17/10/25 21:10:08 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/25 21:10:08 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:10:08 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/25 21:10:08 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:10:08 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:10:08 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/25 21:10:08 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:10:08 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.072229 s
17/10/25 21:10:08 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:10:08 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/25 21:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz2`
WHERE (0 = 1)
17/10/25 21:10:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:08 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:10:08 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:10:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:10:08 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:10:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:10:08 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:10:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:10:08 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:10:08 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:10:08 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/25 21:10:08 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:10:08 INFO DAGScheduler: Missing parents: List()
17/10/25 21:10:08 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[51] at map at utils.scala:55), which has no missing parents
17/10/25 21:10:08 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 259.0 MB)
17/10/25 21:10:08 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 259.0 MB)
17/10/25 21:10:08 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:60844 (size: 4.6 KB, free: 259.7 MB)
17/10/25 21:10:08 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:08 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:60844 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:10:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[51] at map at utils.scala:55)
17/10/25 21:10:08 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/25 21:10:08 INFO ContextCleaner: Cleaned accumulator 651
17/10/25 21:10:08 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/25 21:10:08 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:60844 in memory (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:10:08 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/25 21:10:08 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1158 bytes result sent to driver
17/10/25 21:10:08 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 8 ms on localhost (executor driver) (1/1)
17/10/25 21:10:08 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/25 21:10:08 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.008 s
17/10/25 21:10:08 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.019932 s
17/10/25 21:10:08 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:60844 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:10:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:11 INFO SparkSqlParser: Parsing command: cuv
17/10/25 21:10:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:11 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/25 21:10:11 INFO SparkSqlParser: Parsing command: `cuv`
17/10/25 21:10:11 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:10:11 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:10:11 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/25 21:10:11 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 258.8 MB)
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 258.8 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:60844 (size: 23.9 KB, free: 259.7 MB)
17/10/25 21:10:11 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:10:11 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:10:11 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/25 21:10:11 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:10:11 INFO DAGScheduler: Registering RDD 58 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:11 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:10:11 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/25 21:10:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/25 21:10:11 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[58] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 258.7 MB)
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 258.7 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:60844 (size: 19.5 KB, free: 259.6 MB)
17/10/25 21:10:11 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[58] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:11 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/25 21:10:11 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:10:11 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:10:11 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:10:11 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:10:11 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/25 21:10:11 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/25 21:10:11 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/25 21:10:11 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/25 21:10:11 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/25 21:10:11 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/25 21:10:11 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/25 21:10:11 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpeIftYE/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/25 21:10:11 INFO CodeGenerator: Code generated in 45.375772 ms
17/10/25 21:10:11 INFO MemoryStore: Block rdd_55_3 stored as values in memory (estimated size 198.6 KB, free 258.5 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added rdd_55_3 in memory on 127.0.0.1:60844 (size: 198.6 KB, free: 259.5 MB)
17/10/25 21:10:11 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/25 21:10:11 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 165 ms on localhost (executor driver) (1/4)
17/10/25 21:10:11 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:60844 in memory (size: 4.6 KB, free: 259.5 MB)
17/10/25 21:10:11 INFO ContextCleaner: Cleaned accumulator 886
17/10/25 21:10:11 INFO MemoryStore: Block rdd_55_1 stored as values in memory (estimated size 1374.8 KB, free 257.2 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added rdd_55_1 in memory on 127.0.0.1:60844 (size: 1374.8 KB, free: 258.1 MB)
17/10/25 21:10:11 INFO MemoryStore: Block rdd_55_0 stored as values in memory (estimated size 1296.0 KB, free 255.9 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added rdd_55_0 in memory on 127.0.0.1:60844 (size: 1296.0 KB, free: 256.8 MB)
17/10/25 21:10:11 INFO MemoryStore: Block rdd_55_2 stored as values in memory (estimated size 1444.5 KB, free 254.5 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added rdd_55_2 in memory on 127.0.0.1:60844 (size: 1444.5 KB, free: 255.4 MB)
17/10/25 21:10:11 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/25 21:10:11 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 674 ms on localhost (executor driver) (2/4)
17/10/25 21:10:11 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/25 21:10:11 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 682 ms on localhost (executor driver) (3/4)
17/10/25 21:10:11 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/25 21:10:11 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 687 ms on localhost (executor driver) (4/4)
17/10/25 21:10:11 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/25 21:10:11 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.690 s
17/10/25 21:10:11 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:10:11 INFO DAGScheduler: running: Set()
17/10/25 21:10:11 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/25 21:10:11 INFO DAGScheduler: failed: Set()
17/10/25 21:10:11 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 254.5 MB)
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.5 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:10:11 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:10:11 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/25 21:10:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/25 21:10:11 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/25 21:10:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:10:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:10:11 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1952 bytes result sent to driver
17/10/25 21:10:11 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
17/10/25 21:10:11 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:10:11 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.709606 s
17/10/25 21:10:11 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/25 21:10:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/25 21:10:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:10:11 INFO DAGScheduler: Registering RDD 65 (collect at utils.scala:196)
17/10/25 21:10:11 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:10:11 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/25 21:10:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/25 21:10:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/25 21:10:11 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[65] at collect at utils.scala:196), which has no missing parents
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 254.4 MB)
17/10/25 21:10:11 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 254.4 MB)
17/10/25 21:10:11 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:60844 (size: 19.5 KB, free: 255.4 MB)
17/10/25 21:10:11 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[65] at collect at utils.scala:196)
17/10/25 21:10:11 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/25 21:10:12 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:10:12 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:10:12 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:10:12 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:10:12 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/25 21:10:12 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/25 21:10:12 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/25 21:10:12 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/25 21:10:12 INFO BlockManager: Found block rdd_55_3 locally
17/10/25 21:10:12 INFO BlockManager: Found block rdd_55_2 locally
17/10/25 21:10:12 INFO BlockManager: Found block rdd_55_0 locally
17/10/25 21:10:12 INFO BlockManager: Found block rdd_55_1 locally
17/10/25 21:10:12 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2188 bytes result sent to driver
17/10/25 21:10:12 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 24 ms on localhost (executor driver) (1/4)
17/10/25 21:10:12 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2019 bytes result sent to driver
17/10/25 21:10:12 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 30 ms on localhost (executor driver) (2/4)
17/10/25 21:10:12 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2019 bytes result sent to driver
17/10/25 21:10:12 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 34 ms on localhost (executor driver) (3/4)
17/10/25 21:10:12 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2275 bytes result sent to driver
17/10/25 21:10:12 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.040 s
17/10/25 21:10:12 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:10:12 INFO DAGScheduler: running: Set()
17/10/25 21:10:12 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/25 21:10:12 INFO DAGScheduler: failed: Set()
17/10/25 21:10:12 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/25 21:10:12 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 254.4 MB)
17/10/25 21:10:12 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.4 MB)
17/10/25 21:10:12 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 37 ms on localhost (executor driver) (4/4)
17/10/25 21:10:12 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/25 21:10:12 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:60844 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:10:12 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/25 21:10:12 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/25 21:10:12 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/25 21:10:12 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:10:12 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/25 21:10:12 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:10:12 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:10:12 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/25 21:10:12 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/25 21:10:12 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.058677 s
17/10/25 21:10:12 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:10:12 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/25 21:10:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:10:12 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz3`
WHERE (0 = 1)
17/10/25 21:10:15 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 21:10:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4041
17/10/25 21:10:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 21:10:15 INFO MemoryStore: MemoryStore cleared
17/10/25 21:10:15 INFO BlockManager: BlockManager stopped
17/10/25 21:10:15 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 21:10:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 21:10:15 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:10:15 INFO SparkContext: Successfully stopped SparkContext
17/10/25 21:10:15 INFO ShutdownHookManager: Shutdown hook called
17/10/25 21:10:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09
17/10/25 21:10:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:10:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16
17/10/25 21:10:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-e4c32c30-4414-4e8e-abc7-ccd4c1b02a09\userFiles-fa6f8b22-f525-422c-9d37-e2c645b53b16
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:12:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:22 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:22 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:12:23 INFO CodeGenerator: Code generated in 310.635697 ms
17/10/25 21:12:23 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:12:23 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:12:23 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/25 21:12:23 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:12:23 INFO DAGScheduler: Missing parents: List()
17/10/25 21:12:23 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/25 21:12:23 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/25 21:12:23 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/25 21:12:23 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:58356 (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:12:23 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/25 21:12:23 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/25 21:12:23 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/10/25 21:12:23 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/25 21:12:23 INFO Executor: Fetching spark://127.0.0.1:58330/jars/sparklyr-2.1-2.11.jar with timestamp 1508931968011
17/10/25 21:12:23 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:58330 after 15 ms (0 ms spent in bootstraps)
17/10/25 21:12:23 INFO Utils: Fetching spark://127.0.0.1:58330/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557\fetchFileTemp3602953868282735365.tmp
17/10/25 21:12:24 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1/userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557/sparklyr-2.1-2.11.jar to class loader
17/10/25 21:12:24 INFO CodeGenerator: Code generated in 32.44455 ms
17/10/25 21:12:24 INFO CodeGenerator: Code generated in 14.215724 ms
17/10/25 21:12:24 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/10/25 21:12:24 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.508 s
17/10/25 21:12:24 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.698287 s
17/10/25 21:12:24 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 487 ms on localhost (executor driver) (1/1)
17/10/25 21:12:24 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/25 21:12:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:39 INFO ContextCleaner: Cleaned accumulator 0
17/10/25 21:12:39 INFO ContextCleaner: Cleaned accumulator 1
17/10/25 21:12:39 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:58356 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:12:40 INFO SparkSqlParser: Parsing command: loan
17/10/25 21:12:40 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:40 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/25 21:12:40 INFO SparkSqlParser: Parsing command: `loan`
17/10/25 21:12:40 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:12:40 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:12:40 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: string ... 17 more fields>
17/10/25 21:12:40 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:12:40 INFO CodeGenerator: Code generated in 5.903161 ms
17/10/25 21:12:40 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/25 21:12:40 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/25 21:12:40 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:58356 (size: 23.9 KB, free: 366.3 MB)
17/10/25 21:12:40 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:40 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28629131 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:12:40 INFO CodeGenerator: Code generated in 13.219118 ms
17/10/25 21:12:40 INFO CodeGenerator: Code generated in 11.072981 ms
17/10/25 21:12:40 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:40 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:40 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:12:40 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:40 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/25 21:12:40 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/25 21:12:40 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:40 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/25 21:12:40 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 366.0 MB)
17/10/25 21:12:40 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:58356 (size: 11.2 KB, free: 366.3 MB)
17/10/25 21:12:40 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:40 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:40 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/25 21:12:40 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:40 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:40 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:40 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:40 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/25 21:12:40 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/25 21:12:40 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/25 21:12:40 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/25 21:12:40 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 28629131-57258262, partition values: [empty row]
17/10/25 21:12:40 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 85887393-110322221, partition values: [empty row]
17/10/25 21:12:40 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 57258262-85887393, partition values: [empty row]
17/10/25 21:12:40 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 0-28629131, partition values: [empty row]
17/10/25 21:12:40 INFO CodeGenerator: Code generated in 27.065862 ms
17/10/25 21:12:40 INFO ContextCleaner: Cleaned accumulator 54
17/10/25 21:12:43 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 18.4 MB, free 347.5 MB)
17/10/25 21:12:43 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:58356 (size: 18.4 MB, free: 347.8 MB)
17/10/25 21:12:43 INFO CodeGenerator: Code generated in 6.134094 ms
17/10/25 21:12:44 INFO CodeGenerator: Code generated in 29.594836 ms
17/10/25 21:12:44 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3594 ms on localhost (executor driver) (1/4)
17/10/25 21:12:44 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 21.6 MB, free 325.9 MB)
17/10/25 21:12:44 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:58356 (size: 21.6 MB, free: 326.3 MB)
17/10/25 21:12:44 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2983 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 3680 ms on localhost (executor driver) (2/4)
17/10/25 21:12:44 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 21.6 MB, free 304.4 MB)
17/10/25 21:12:44 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:58356 (size: 21.6 MB, free: 304.7 MB)
17/10/25 21:12:44 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3736 ms on localhost (executor driver) (3/4)
17/10/25 21:12:44 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 21.6 MB, free 282.8 MB)
17/10/25 21:12:44 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:58356 (size: 21.6 MB, free: 283.1 MB)
17/10/25 21:12:44 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/25 21:12:44 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 3.916 s
17/10/25 21:12:44 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 3911 ms on localhost (executor driver) (4/4)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/25 21:12:44 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:44 INFO DAGScheduler: running: Set()
17/10/25 21:12:44 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/25 21:12:44 INFO DAGScheduler: failed: Set()
17/10/25 21:12:44 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 282.8 MB)
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.8 MB)
17/10/25 21:12:44 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:12:44 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/25 21:12:44 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:12:44 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/25 21:12:44 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/10/25 21:12:44 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2039 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 45 ms on localhost (executor driver) (1/1)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/25 21:12:44 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.045 s
17/10/25 21:12:44 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.035624 s
17/10/25 21:12:44 INFO CodeGenerator: Code generated in 6.807905 ms
17/10/25 21:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:44 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/25 21:12:44 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:12:44 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/25 21:12:44 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:12:44 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/25 21:12:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/25 21:12:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/25 21:12:44 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 282.8 MB)
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.7 MB)
17/10/25 21:12:44 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:58356 (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:12:44 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/25 21:12:44 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:12:44 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:12:44 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:12:44 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:12:44 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/25 21:12:44 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/25 21:12:44 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/25 21:12:44 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/25 21:12:44 INFO BlockManager: Found block rdd_11_3 locally
17/10/25 21:12:44 INFO BlockManager: Found block rdd_11_1 locally
17/10/25 21:12:44 INFO BlockManager: Found block rdd_11_2 locally
17/10/25 21:12:44 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2188 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 34 ms on localhost (executor driver) (1/4)
17/10/25 21:12:44 INFO BlockManager: Found block rdd_11_0 locally
17/10/25 21:12:44 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/25 21:12:44 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2109 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 47 ms on localhost (executor driver) (2/4)
17/10/25 21:12:44 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 49 ms on localhost (executor driver) (3/4)
17/10/25 21:12:44 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/25 21:12:44 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.061 s
17/10/25 21:12:44 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:44 INFO DAGScheduler: running: Set()
17/10/25 21:12:44 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/25 21:12:44 INFO DAGScheduler: failed: Set()
17/10/25 21:12:44 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 282.7 MB)
17/10/25 21:12:44 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.7 MB)
17/10/25 21:12:44 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 61 ms on localhost (executor driver) (4/4)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/25 21:12:44 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:12:44 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:44 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/25 21:12:44 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:12:44 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/25 21:12:44 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:44 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/25 21:12:44 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1865 bytes result sent to driver
17/10/25 21:12:44 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:12:44 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/25 21:12:44 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.009 s
17/10/25 21:12:44 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.091068 s
17/10/25 21:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:44 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz1`
WHERE (0 = 1)
17/10/25 21:12:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:44 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:44 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:44 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:44 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:44 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:44 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:44 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:12:44 INFO CodeGenerator: Code generated in 8.510651 ms
17/10/25 21:12:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:45 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:45 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:45 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:12:45 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:12:45 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:12:45 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/25 21:12:45 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:12:45 INFO DAGScheduler: Missing parents: List()
17/10/25 21:12:45 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:55), which has no missing parents
17/10/25 21:12:45 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 282.7 MB)
17/10/25 21:12:45 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 282.7 MB)
17/10/25 21:12:45 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:58356 (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:12:45 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[31] at map at utils.scala:55)
17/10/25 21:12:45 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/25 21:12:45 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/25 21:12:45 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/25 21:12:45 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/25 21:12:45 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 15 ms on localhost (executor driver) (1/1)
17/10/25 21:12:45 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.016 s
17/10/25 21:12:45 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/25 21:12:45 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.022535 s
17/10/25 21:12:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:54 INFO SparkSqlParser: Parsing command: payment
17/10/25 21:12:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/25 21:12:54 INFO SparkSqlParser: Parsing command: `payment`
17/10/25 21:12:54 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:12:54 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:12:54 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: string, principal: double ... 7 more fields>
17/10/25 21:12:54 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:12:54 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 282.4 MB)
17/10/25 21:12:54 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 282.4 MB)
17/10/25 21:12:54 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:58356 (size: 23.9 KB, free: 283.1 MB)
17/10/25 21:12:54 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:54 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14622813 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:12:54 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:54 INFO DAGScheduler: Registering RDD 38 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:54 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:12:54 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/25 21:12:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/25 21:12:54 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:54 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 282.4 MB)
17/10/25 21:12:54 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 282.4 MB)
17/10/25 21:12:54 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:58356 (size: 9.4 KB, free: 283.0 MB)
17/10/25 21:12:54 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:54 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[38] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:54 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/25 21:12:54 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:54 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:54 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:54 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:12:54 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/25 21:12:54 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/25 21:12:54 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/25 21:12:54 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/25 21:12:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 14622813-29245626, partition values: [empty row]
17/10/25 21:12:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 0-14622813, partition values: [empty row]
17/10/25 21:12:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 29245626-43868439, partition values: [empty row]
17/10/25 21:12:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 43868439-54296951, partition values: [empty row]
17/10/25 21:12:54 INFO CodeGenerator: Code generated in 20.744969 ms
17/10/25 21:12:54 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 283.0 MB)
17/10/25 21:12:54 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:58356 in memory (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:12:54 INFO ContextCleaner: Cleaned accumulator 470
17/10/25 21:12:54 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:58356 in memory (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:12:54 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:12:54 INFO ContextCleaner: Cleaned accumulator 416
17/10/25 21:12:54 INFO ContextCleaner: Cleaned accumulator 417
17/10/25 21:12:54 INFO ContextCleaner: Cleaned accumulator 235
17/10/25 21:12:55 INFO MemoryStore: Block rdd_35_3 stored as values in memory (estimated size 4.5 MB, free 278.0 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added rdd_35_3 in memory on 127.0.0.1:58356 (size: 4.5 MB, free: 278.6 MB)
17/10/25 21:12:55 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1175 ms on localhost (executor driver) (1/4)
17/10/25 21:12:55 INFO MemoryStore: Block rdd_35_2 stored as values in memory (estimated size 6.2 MB, free 271.7 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added rdd_35_2 in memory on 127.0.0.1:58356 (size: 6.2 MB, free: 272.3 MB)
17/10/25 21:12:55 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 1380 ms on localhost (executor driver) (2/4)
17/10/25 21:12:55 INFO MemoryStore: Block rdd_35_0 stored as values in memory (estimated size 6.3 MB, free 265.4 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added rdd_35_0 in memory on 127.0.0.1:58356 (size: 6.3 MB, free: 266.0 MB)
17/10/25 21:12:55 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 1404 ms on localhost (executor driver) (3/4)
17/10/25 21:12:55 INFO MemoryStore: Block rdd_35_1 stored as values in memory (estimated size 6.3 MB, free 259.1 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added rdd_35_1 in memory on 127.0.0.1:58356 (size: 6.3 MB, free: 259.7 MB)
17/10/25 21:12:55 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 1420 ms on localhost (executor driver) (4/4)
17/10/25 21:12:55 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 1.422 s
17/10/25 21:12:55 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:55 INFO DAGScheduler: running: Set()
17/10/25 21:12:55 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/25 21:12:55 INFO DAGScheduler: failed: Set()
17/10/25 21:12:55 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[41] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:55 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 259.1 MB)
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.1 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:12:55 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[41] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/25 21:12:55 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:12:55 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/25 21:12:55 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:12:55 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/25 21:12:55 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/25 21:12:55 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 1.445721 s
17/10/25 21:12:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:55 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/25 21:12:55 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:12:55 INFO DAGScheduler: Registering RDD 45 (collect at utils.scala:196)
17/10/25 21:12:55 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:12:55 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/25 21:12:55 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/25 21:12:55 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/25 21:12:55 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[45] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 259.0 MB)
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 259.0 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:58356 (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:12:55 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:55 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[45] at collect at utils.scala:196)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/25 21:12:55 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:55 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:55 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:55 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:55 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/25 21:12:55 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/25 21:12:55 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/25 21:12:55 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/25 21:12:55 INFO BlockManager: Found block rdd_35_2 locally
17/10/25 21:12:55 INFO BlockManager: Found block rdd_35_3 locally
17/10/25 21:12:55 INFO BlockManager: Found block rdd_35_1 locally
17/10/25 21:12:55 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2098 bytes result sent to driver
17/10/25 21:12:55 INFO BlockManager: Found block rdd_35_0 locally
17/10/25 21:12:55 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 32 ms on localhost (executor driver) (1/4)
17/10/25 21:12:55 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 40 ms on localhost (executor driver) (2/4)
17/10/25 21:12:55 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 46 ms on localhost (executor driver) (3/4)
17/10/25 21:12:55 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2098 bytes result sent to driver
17/10/25 21:12:55 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.052 s
17/10/25 21:12:55 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:55 INFO DAGScheduler: running: Set()
17/10/25 21:12:55 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/25 21:12:55 INFO DAGScheduler: failed: Set()
17/10/25 21:12:55 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[48] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:55 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 52 ms on localhost (executor driver) (4/4)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 259.0 MB)
17/10/25 21:12:55 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.0 MB)
17/10/25 21:12:55 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:12:55 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:55 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[48] at collect at utils.scala:196)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/25 21:12:55 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:12:55 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/25 21:12:55 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:55 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:12:55 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/25 21:12:55 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:12:55 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/25 21:12:55 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:12:55 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.072996 s
17/10/25 21:12:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz2`
WHERE (0 = 1)
17/10/25 21:12:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:12:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:12:56 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:12:56 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:12:56 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/25 21:12:56 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:12:56 INFO DAGScheduler: Missing parents: List()
17/10/25 21:12:56 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55), which has no missing parents
17/10/25 21:12:56 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 259.0 MB)
17/10/25 21:12:56 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 259.0 MB)
17/10/25 21:12:56 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:58356 (size: 4.6 KB, free: 259.7 MB)
17/10/25 21:12:56 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55)
17/10/25 21:12:56 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/25 21:12:56 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/25 21:12:56 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/25 21:12:56 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/25 21:12:56 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:12:56 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.006 s
17/10/25 21:12:56 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.013051 s
17/10/25 21:12:56 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/25 21:12:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:58 INFO SparkSqlParser: Parsing command: cuv
17/10/25 21:12:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:58 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/25 21:12:58 INFO SparkSqlParser: Parsing command: `cuv`
17/10/25 21:12:58 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:12:58 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:12:58 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/25 21:12:58 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:12:58 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 258.7 MB)
17/10/25 21:12:58 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 258.7 MB)
17/10/25 21:12:58 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:58356 (size: 23.9 KB, free: 259.6 MB)
17/10/25 21:12:58 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:58 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:12:58 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/25 21:12:58 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:12:58 INFO DAGScheduler: Registering RDD 62 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:58 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:12:58 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/25 21:12:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/25 21:12:58 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:58 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 258.6 MB)
17/10/25 21:12:58 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.4 KB, free 258.6 MB)
17/10/25 21:12:58 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:58356 (size: 19.4 KB, free: 259.6 MB)
17/10/25 21:12:58 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:58 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:58 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/25 21:12:58 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:12:58 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:12:58 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:12:58 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:12:58 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/25 21:12:58 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/25 21:12:58 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/25 21:12:58 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/25 21:12:58 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/25 21:12:58 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/25 21:12:58 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/25 21:12:58 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/25 21:12:58 INFO CodeGenerator: Code generated in 60.396681 ms
17/10/25 21:12:59 INFO MemoryStore: Block rdd_59_3 stored as values in memory (estimated size 198.6 KB, free 258.4 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Added rdd_59_3 in memory on 127.0.0.1:58356 (size: 198.6 KB, free: 259.4 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:58356 in memory (size: 4.6 KB, free: 259.4 MB)
17/10/25 21:12:59 INFO ContextCleaner: Cleaned accumulator 886
17/10/25 21:12:59 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 259.4 MB)
17/10/25 21:12:59 INFO ContextCleaner: Cleaned accumulator 651
17/10/25 21:12:59 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:58356 in memory (size: 9.4 KB, free: 259.4 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 259.4 MB)
17/10/25 21:12:59 INFO ContextCleaner: Cleaned accumulator 832
17/10/25 21:12:59 INFO ContextCleaner: Cleaned accumulator 833
17/10/25 21:12:59 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2983 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 247 ms on localhost (executor driver) (1/4)
17/10/25 21:12:59 INFO MemoryStore: Block rdd_59_0 stored as values in memory (estimated size 1296.0 KB, free 257.2 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Added rdd_59_0 in memory on 127.0.0.1:58356 (size: 1296.0 KB, free: 258.2 MB)
17/10/25 21:12:59 INFO MemoryStore: Block rdd_59_1 stored as values in memory (estimated size 1374.8 KB, free 255.9 MB)
17/10/25 21:12:59 INFO MemoryStore: Block rdd_59_2 stored as values in memory (estimated size 1444.5 KB, free 254.5 MB)
17/10/25 21:12:59 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/25 21:12:59 INFO BlockManagerInfo: Added rdd_59_1 in memory on 127.0.0.1:58356 (size: 1374.8 KB, free: 256.8 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Added rdd_59_2 in memory on 127.0.0.1:58356 (size: 1444.5 KB, free: 255.4 MB)
17/10/25 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 671 ms on localhost (executor driver) (2/4)
17/10/25 21:12:59 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 686 ms on localhost (executor driver) (3/4)
17/10/25 21:12:59 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2983 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 688 ms on localhost (executor driver) (4/4)
17/10/25 21:12:59 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.693 s
17/10/25 21:12:59 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:59 INFO DAGScheduler: running: Set()
17/10/25 21:12:59 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/25 21:12:59 INFO DAGScheduler: failed: Set()
17/10/25 21:12:59 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 254.4 MB)
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.4 MB)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/25 21:12:59 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:12:59 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/25 21:12:59 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/25 21:12:59 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/25 21:12:59 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:12:59 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1952 bytes result sent to driver
17/10/25 21:12:59 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
17/10/25 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:12:59 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.717498 s
17/10/25 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/25 21:12:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:59 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/25 21:12:59 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:12:59 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:196)
17/10/25 21:12:59 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:12:59 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/25 21:12:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/25 21:12:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/25 21:12:59 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 254.4 MB)
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 254.4 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:58356 (size: 19.5 KB, free: 255.4 MB)
17/10/25 21:12:59 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:59 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/25 21:12:59 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:59 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:59 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:59 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:12:59 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/25 21:12:59 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/25 21:12:59 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/25 21:12:59 INFO BlockManager: Found block rdd_59_0 locally
17/10/25 21:12:59 INFO BlockManager: Found block rdd_59_2 locally
17/10/25 21:12:59 INFO BlockManager: Found block rdd_59_1 locally
17/10/25 21:12:59 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/25 21:12:59 INFO BlockManager: Found block rdd_59_3 locally
17/10/25 21:12:59 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2098 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 37 ms on localhost (executor driver) (1/4)
17/10/25 21:12:59 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2098 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 39 ms on localhost (executor driver) (2/4)
17/10/25 21:12:59 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/25 21:12:59 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 44 ms on localhost (executor driver) (3/4)
17/10/25 21:12:59 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/25 21:12:59 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.052 s
17/10/25 21:12:59 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:12:59 INFO DAGScheduler: running: Set()
17/10/25 21:12:59 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/25 21:12:59 INFO DAGScheduler: failed: Set()
17/10/25 21:12:59 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196), which has no missing parents
17/10/25 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 51 ms on localhost (executor driver) (4/4)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 254.3 MB)
17/10/25 21:12:59 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.3 MB)
17/10/25 21:12:59 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:58356 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:12:59 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/25 21:12:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/25 21:12:59 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:12:59 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/25 21:12:59 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:12:59 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:12:59 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/25 21:12:59 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.008 s
17/10/25 21:12:59 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.072032 s
17/10/25 21:12:59 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:12:59 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/25 21:12:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:59 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz3`
WHERE (0 = 1)
17/10/25 21:12:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:12:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:12:59 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:59 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:12:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:12:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:12:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:14:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:14:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:14:58 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:14:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:14:58 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:14:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:14:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:14:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:14:58 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:14:58 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:14:58 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:58)
17/10/25 21:14:58 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:14:58 INFO DAGScheduler: Missing parents: List()
17/10/25 21:14:58 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[79] at map at utils.scala:55), which has no missing parents
17/10/25 21:14:58 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.7 KB, free 254.3 MB)
17/10/25 21:14:58 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 254.3 MB)
17/10/25 21:14:58 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:58356 (size: 4.6 KB, free: 255.4 MB)
17/10/25 21:14:58 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/25 21:14:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[79] at map at utils.scala:55)
17/10/25 21:14:58 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/25 21:14:58 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6458 bytes)
17/10/25 21:14:58 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/25 21:14:58 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1085 bytes result sent to driver
17/10/25 21:14:58 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:58) finished in 0.010 s
17/10/25 21:14:58 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 8 ms on localhost (executor driver) (1/1)
17/10/25 21:14:58 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.014851 s
17/10/25 21:14:58 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/25 21:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:15:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:15:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:15:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:15:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:15:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 479
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 1248
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 1249
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:58356 in memory (size: 4.6 KB, free: 255.4 MB)
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:58356 in memory (size: 19.5 KB, free: 255.4 MB)
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:58356 in memory (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 1067
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:58356 in memory (size: 11.2 KB, free: 255.4 MB)
17/10/25 21:16:08 INFO ContextCleaner: Cleaned shuffle 0
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 66
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 65
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 64
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 63
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 62
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 61
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 60
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 59
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 58
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 57
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 56
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 55
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:58356 in memory (size: 19.4 KB, free: 255.5 MB)
17/10/25 21:16:08 INFO ContextCleaner: Cleaned shuffle 4
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 898
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 897
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 896
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 895
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 894
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 893
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 892
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 891
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 890
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 889
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 888
17/10/25 21:16:08 INFO ContextCleaner: Cleaned accumulator 887
17/10/25 21:16:08 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:58356 in memory (size: 9.4 KB, free: 255.5 MB)
17/10/25 21:16:09 INFO ContextCleaner: Cleaned shuffle 2
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 482
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 481
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 480
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 478
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 477
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 476
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 475
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 474
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 473
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 472
17/10/25 21:16:09 INFO ContextCleaner: Cleaned accumulator 471
17/10/25 21:19:24 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 21:19:24 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/25 21:19:24 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 21:19:24 INFO MemoryStore: MemoryStore cleared
17/10/25 21:19:24 INFO BlockManager: BlockManager stopped
17/10/25 21:19:24 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 21:19:24 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 21:19:24 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:19:24 INFO SparkContext: Successfully stopped SparkContext
17/10/25 21:19:24 INFO ShutdownHookManager: Shutdown hook called
17/10/25 21:19:24 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557
17/10/25 21:19:24 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1\userFiles-3fa8df9f-9edc-4c75-b866-7f53538a6557
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:19:24 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1
17/10/25 21:19:24 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-7b067558-c9a5-4275-acf0-f4caf88a5fc1
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:19:50 INFO SparkContext: Running Spark version 2.1.0
17/10/25 21:19:50 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 21:19:50 INFO SecurityManager: Changing view acls to: scibr
17/10/25 21:19:50 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 21:19:50 INFO SecurityManager: Changing view acls groups to: 
17/10/25 21:19:50 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 21:19:50 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 21:19:50 INFO Utils: Successfully started service 'sparkDriver' on port 61358.
17/10/25 21:19:50 INFO SparkEnv: Registering MapOutputTracker
17/10/25 21:19:50 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 21:19:50 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 21:19:50 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 21:19:50 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-bc62bfba-c227-45ae-964f-5f1980837257
17/10/25 21:19:51 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 21:19:51 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 21:19:51 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/25 21:19:51 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/25 21:19:51 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:61358/jars/sparklyr-2.1-2.11.jar with timestamp 1508933991354
17/10/25 21:19:51 INFO Executor: Starting executor ID driver on host localhost
17/10/25 21:19:51 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61379.
17/10/25 21:19:51 INFO NettyBlockTransferService: Server created on 127.0.0.1:61379
17/10/25 21:19:51 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 21:19:51 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61379, None)
17/10/25 21:19:51 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61379 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61379, None)
17/10/25 21:19:51 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61379, None)
17/10/25 21:19:51 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61379, None)
17/10/25 21:19:55 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/25 21:19:55 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/25 21:19:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/25 21:19:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/25 21:19:56 INFO ObjectStore: ObjectStore, initialize called
17/10/25 21:19:56 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/25 21:19:56 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/25 21:19:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/25 21:19:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:19:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:19:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:19:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:19:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/25 21:19:59 INFO ObjectStore: Initialized ObjectStore
17/10/25 21:19:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/25 21:19:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/25 21:20:00 INFO HiveMetaStore: Added admin role in metastore
17/10/25 21:20:00 INFO HiveMetaStore: Added public role in metastore
17/10/25 21:20:00 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/25 21:20:00 INFO HiveMetaStore: 0: get_all_databases
17/10/25 21:20:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/25 21:20:00 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/25 21:20:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/25 21:20:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:20:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/cbd3e20c-e5d0-48a7-9dd9-26468a225d34_resources
17/10/25 21:20:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cbd3e20c-e5d0-48a7-9dd9-26468a225d34
17/10/25 21:20:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/cbd3e20c-e5d0-48a7-9dd9-26468a225d34
17/10/25 21:20:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cbd3e20c-e5d0-48a7-9dd9-26468a225d34/_tmp_space.db
17/10/25 21:20:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/25 21:20:00 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:00 INFO HiveMetaStore: 0: get_database: global_temp
17/10/25 21:20:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/25 21:20:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/25 21:20:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:06 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:06 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:06 INFO CodeGenerator: Code generated in 304.231155 ms
17/10/25 21:20:07 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:20:07 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:20:07 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/25 21:20:07 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:20:07 INFO DAGScheduler: Missing parents: List()
17/10/25 21:20:07 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/25 21:20:07 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/25 21:20:07 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/25 21:20:07 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61379 (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:20:07 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:07 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/25 21:20:07 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/25 21:20:07 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/10/25 21:20:07 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/25 21:20:07 INFO Executor: Fetching spark://127.0.0.1:61358/jars/sparklyr-2.1-2.11.jar with timestamp 1508933991354
17/10/25 21:20:07 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61358 after 17 ms (0 ms spent in bootstraps)
17/10/25 21:20:07 INFO Utils: Fetching spark://127.0.0.1:61358/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f\fetchFileTemp2942844487700857390.tmp
17/10/25 21:20:07 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c8ccce13-526b-4c09-9bb0-257799d8fed1/userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f/sparklyr-2.1-2.11.jar to class loader
17/10/25 21:20:07 INFO CodeGenerator: Code generated in 26.865207 ms
17/10/25 21:20:08 INFO CodeGenerator: Code generated in 15.914364 ms
17/10/25 21:20:08 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/10/25 21:20:08 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.752 s
17/10/25 21:20:08 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 728 ms on localhost (executor driver) (1/1)
17/10/25 21:20:08 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/25 21:20:08 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 1.061053 s
17/10/25 21:20:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:12 INFO SparkSqlParser: Parsing command: loan
17/10/25 21:20:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:12 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/25 21:20:12 INFO SparkSqlParser: Parsing command: `loan`
17/10/25 21:20:12 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:20:12 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:20:12 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: string ... 17 more fields>
17/10/25 21:20:12 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:20:12 INFO CodeGenerator: Code generated in 7.970268 ms
17/10/25 21:20:12 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/25 21:20:12 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/25 21:20:12 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61379 (size: 23.9 KB, free: 366.3 MB)
17/10/25 21:20:12 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:12 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28629131 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:20:12 INFO CodeGenerator: Code generated in 13.058493 ms
17/10/25 21:20:12 INFO CodeGenerator: Code generated in 11.163815 ms
17/10/25 21:20:12 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:12 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:12 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:20:12 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:12 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/25 21:20:12 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/25 21:20:12 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:12 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/25 21:20:12 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/25 21:20:12 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61379 (size: 11.2 KB, free: 366.3 MB)
17/10/25 21:20:12 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:12 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:12 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/25 21:20:12 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:12 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:12 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:12 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:12 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/25 21:20:12 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/25 21:20:12 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/25 21:20:12 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/25 21:20:12 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 57258262-85887393, partition values: [empty row]
17/10/25 21:20:12 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 28629131-57258262, partition values: [empty row]
17/10/25 21:20:12 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 85887393-110322221, partition values: [empty row]
17/10/25 21:20:12 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 0-28629131, partition values: [empty row]
17/10/25 21:20:12 INFO CodeGenerator: Code generated in 26.611695 ms
17/10/25 21:20:15 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61379 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:20:15 INFO ContextCleaner: Cleaned accumulator 54
17/10/25 21:20:15 INFO ContextCleaner: Cleaned accumulator 1
17/10/25 21:20:15 INFO ContextCleaner: Cleaned accumulator 0
17/10/25 21:20:15 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 18.4 MB, free 347.5 MB)
17/10/25 21:20:15 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:61379 (size: 18.4 MB, free: 347.8 MB)
17/10/25 21:20:15 INFO CodeGenerator: Code generated in 6.215691 ms
17/10/25 21:20:15 INFO CodeGenerator: Code generated in 28.371917 ms
17/10/25 21:20:16 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3070 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3099 ms on localhost (executor driver) (1/4)
17/10/25 21:20:16 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 21.6 MB, free 326.0 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:61379 (size: 21.6 MB, free: 326.3 MB)
17/10/25 21:20:16 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2983 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 3279 ms on localhost (executor driver) (2/4)
17/10/25 21:20:16 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 21.6 MB, free 304.4 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:61379 (size: 21.6 MB, free: 304.7 MB)
17/10/25 21:20:16 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3326 ms on localhost (executor driver) (3/4)
17/10/25 21:20:16 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 21.6 MB, free 282.8 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:61379 (size: 21.6 MB, free: 283.1 MB)
17/10/25 21:20:16 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 3367 ms on localhost (executor driver) (4/4)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/25 21:20:16 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 3.372 s
17/10/25 21:20:16 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:16 INFO DAGScheduler: running: Set()
17/10/25 21:20:16 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/25 21:20:16 INFO DAGScheduler: failed: Set()
17/10/25 21:20:16 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 282.8 MB)
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.8 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:20:16 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/25 21:20:16 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:20:16 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/25 21:20:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/10/25 21:20:16 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 41 ms on localhost (executor driver) (1/1)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/25 21:20:16 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.042 s
17/10/25 21:20:16 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 3.482767 s
17/10/25 21:20:16 INFO CodeGenerator: Code generated in 6.604171 ms
17/10/25 21:20:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:16 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/25 21:20:16 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:20:16 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/25 21:20:16 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:20:16 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/25 21:20:16 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/25 21:20:16 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/25 21:20:16 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 282.8 MB)
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.7 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61379 (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:20:16 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:16 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/25 21:20:16 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:20:16 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:20:16 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:20:16 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:20:16 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/25 21:20:16 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/25 21:20:16 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/25 21:20:16 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/25 21:20:16 INFO BlockManager: Found block rdd_11_2 locally
17/10/25 21:20:16 INFO BlockManager: Found block rdd_11_3 locally
17/10/25 21:20:16 INFO BlockManager: Found block rdd_11_0 locally
17/10/25 21:20:16 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/25 21:20:16 INFO BlockManager: Found block rdd_11_1 locally
17/10/25 21:20:16 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 34 ms on localhost (executor driver) (1/4)
17/10/25 21:20:16 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2188 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 49 ms on localhost (executor driver) (2/4)
17/10/25 21:20:16 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/25 21:20:16 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 56 ms on localhost (executor driver) (3/4)
17/10/25 21:20:16 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/25 21:20:16 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.072 s
17/10/25 21:20:16 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:16 INFO DAGScheduler: running: Set()
17/10/25 21:20:16 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/25 21:20:16 INFO DAGScheduler: failed: Set()
17/10/25 21:20:16 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 282.7 MB)
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.7 MB)
17/10/25 21:20:16 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 66 ms on localhost (executor driver) (4/4)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/25 21:20:16 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:20:16 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/25 21:20:16 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:20:16 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/25 21:20:16 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:16 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:20:16 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/25 21:20:16 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.007 s
17/10/25 21:20:16 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:20:16 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.104566 s
17/10/25 21:20:16 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/25 21:20:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:16 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz4`
WHERE (0 = 1)
17/10/25 21:20:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:16 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:16 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:16 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:16 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:16 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:20:16 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:20:16 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/25 21:20:16 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:20:16 INFO DAGScheduler: Missing parents: List()
17/10/25 21:20:16 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 282.7 MB)
17/10/25 21:20:16 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 282.7 MB)
17/10/25 21:20:16 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61379 (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:20:16 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:16 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/25 21:20:16 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/25 21:20:16 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/25 21:20:16 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/25 21:20:16 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/25 21:20:16 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.018 s
17/10/25 21:20:16 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 16 ms on localhost (executor driver) (1/1)
17/10/25 21:20:16 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.042169 s
17/10/25 21:20:16 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/25 21:20:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:17 INFO SparkSqlParser: Parsing command: payment
17/10/25 21:20:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/25 21:20:17 INFO SparkSqlParser: Parsing command: `payment`
17/10/25 21:20:17 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:20:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:20:17 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: string, principal: double ... 7 more fields>
17/10/25 21:20:17 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:20:17 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 282.4 MB)
17/10/25 21:20:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 282.4 MB)
17/10/25 21:20:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61379 (size: 23.9 KB, free: 283.1 MB)
17/10/25 21:20:17 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14622813 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:20:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:18 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:18 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:20:18 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:18 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/25 21:20:18 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/25 21:20:18 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:18 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 282.4 MB)
17/10/25 21:20:18 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 282.4 MB)
17/10/25 21:20:18 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61379 (size: 9.4 KB, free: 283.0 MB)
17/10/25 21:20:18 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:18 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:18 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/25 21:20:18 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:18 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:18 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:18 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:20:18 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/25 21:20:18 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/25 21:20:18 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/25 21:20:18 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/25 21:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 14622813-29245626, partition values: [empty row]
17/10/25 21:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 0-14622813, partition values: [empty row]
17/10/25 21:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 29245626-43868439, partition values: [empty row]
17/10/25 21:20:18 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 43868439-54296951, partition values: [empty row]
17/10/25 21:20:18 INFO CodeGenerator: Code generated in 24.819654 ms
17/10/25 21:20:18 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61379 in memory (size: 3.7 KB, free: 283.0 MB)
17/10/25 21:20:18 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:61379 in memory (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:20:18 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:61379 in memory (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:20:18 INFO ContextCleaner: Cleaned accumulator 416
17/10/25 21:20:18 INFO ContextCleaner: Cleaned accumulator 417
17/10/25 21:20:18 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61379 in memory (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:20:18 INFO ContextCleaner: Cleaned accumulator 470
17/10/25 21:20:18 INFO ContextCleaner: Cleaned accumulator 235
17/10/25 21:20:19 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 4.5 MB, free 278.0 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:61379 (size: 4.5 MB, free: 278.6 MB)
17/10/25 21:20:19 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1131 ms on localhost (executor driver) (1/4)
17/10/25 21:20:19 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 6.3 MB, free 271.6 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:61379 (size: 6.3 MB, free: 272.2 MB)
17/10/25 21:20:19 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 1377 ms on localhost (executor driver) (2/4)
17/10/25 21:20:19 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 6.2 MB, free 265.4 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:61379 (size: 6.2 MB, free: 266.0 MB)
17/10/25 21:20:19 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 6.3 MB, free 259.1 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:61379 (size: 6.3 MB, free: 259.7 MB)
17/10/25 21:20:19 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 1397 ms on localhost (executor driver) (3/4)
17/10/25 21:20:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2983 bytes result sent to driver
17/10/25 21:20:19 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 1.414 s
17/10/25 21:20:19 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:19 INFO DAGScheduler: running: Set()
17/10/25 21:20:19 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/25 21:20:19 INFO DAGScheduler: failed: Set()
17/10/25 21:20:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 259.1 MB)
17/10/25 21:20:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 1414 ms on localhost (executor driver) (4/4)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.1 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/25 21:20:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:20:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/25 21:20:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:20:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:20:19 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/25 21:20:19 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 1.439486 s
17/10/25 21:20:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/25 21:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/25 21:20:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:20:19 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/25 21:20:19 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:20:19 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/25 21:20:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/25 21:20:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/25 21:20:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 259.0 MB)
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 259.0 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61379 (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/25 21:20:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:19 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:19 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:19 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/25 21:20:19 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/25 21:20:19 INFO BlockManager: Found block rdd_34_0 locally
17/10/25 21:20:19 INFO BlockManager: Found block rdd_34_1 locally
17/10/25 21:20:19 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/25 21:20:19 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/25 21:20:19 INFO BlockManager: Found block rdd_34_2 locally
17/10/25 21:20:19 INFO BlockManager: Found block rdd_34_3 locally
17/10/25 21:20:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2019 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 33 ms on localhost (executor driver) (1/4)
17/10/25 21:20:19 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2106 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 36 ms on localhost (executor driver) (2/4)
17/10/25 21:20:19 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2188 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 44 ms on localhost (executor driver) (3/4)
17/10/25 21:20:19 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/25 21:20:19 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.059 s
17/10/25 21:20:19 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:19 INFO DAGScheduler: running: Set()
17/10/25 21:20:19 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/25 21:20:19 INFO DAGScheduler: failed: Set()
17/10/25 21:20:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 259.0 MB)
17/10/25 21:20:19 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 56 ms on localhost (executor driver) (4/4)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.0 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/25 21:20:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:20:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/25 21:20:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:20:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/25 21:20:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 8 ms on localhost (executor driver) (1/1)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/25 21:20:19 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/25 21:20:19 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.082228 s
17/10/25 21:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz5`
WHERE (0 = 1)
17/10/25 21:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:19 INFO CodeGenerator: Code generated in 16.815003 ms
17/10/25 21:20:19 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61379 in memory (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61379 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61379 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO ContextCleaner: Cleaned accumulator 651
17/10/25 21:20:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:19 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:20:19 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:20:19 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/25 21:20:19 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:20:19 INFO DAGScheduler: Missing parents: List()
17/10/25 21:20:19 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 259.1 MB)
17/10/25 21:20:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 259.0 MB)
17/10/25 21:20:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61379 (size: 4.6 KB, free: 259.7 MB)
17/10/25 21:20:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/25 21:20:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/25 21:20:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/25 21:20:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1166 bytes result sent to driver
17/10/25 21:20:19 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.010 s
17/10/25 21:20:19 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.016456 s
17/10/25 21:20:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 8 ms on localhost (executor driver) (1/1)
17/10/25 21:20:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/25 21:20:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:20 INFO SparkSqlParser: Parsing command: cuv
17/10/25 21:20:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:20 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/25 21:20:20 INFO SparkSqlParser: Parsing command: `cuv`
17/10/25 21:20:20 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:20:20 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:20:20 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/25 21:20:20 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:20:20 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 258.8 MB)
17/10/25 21:20:20 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 258.7 MB)
17/10/25 21:20:20 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61379 (size: 23.9 KB, free: 259.7 MB)
17/10/25 21:20:20 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:20 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:20:20 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/25 21:20:20 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:20:20 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:20 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:20:20 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/25 21:20:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/25 21:20:20 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:20 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 258.7 MB)
17/10/25 21:20:20 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 258.7 MB)
17/10/25 21:20:20 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61379 (size: 19.5 KB, free: 259.6 MB)
17/10/25 21:20:20 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:20 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/25 21:20:20 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:20:20 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:20:20 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:20:20 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:20:20 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/25 21:20:20 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/25 21:20:20 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/25 21:20:20 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/25 21:20:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/25 21:20:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/25 21:20:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/25 21:20:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/25 21:20:20 INFO CodeGenerator: Code generated in 51.491904 ms
17/10/25 21:20:20 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 258.5 MB)
17/10/25 21:20:20 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:61379 (size: 198.6 KB, free: 259.4 MB)
17/10/25 21:20:20 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/25 21:20:20 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 294 ms on localhost (executor driver) (1/4)
17/10/25 21:20:20 INFO ContextCleaner: Cleaned accumulator 832
17/10/25 21:20:20 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61379 in memory (size: 4.6 KB, free: 259.4 MB)
17/10/25 21:20:20 INFO ContextCleaner: Cleaned accumulator 886
17/10/25 21:20:20 INFO ContextCleaner: Cleaned accumulator 833
17/10/25 21:20:21 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 257.1 MB)
17/10/25 21:20:21 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:61379 (size: 1374.8 KB, free: 258.1 MB)
17/10/25 21:20:21 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 254.5 MB)
17/10/25 21:20:21 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 254.5 MB)
17/10/25 21:20:21 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:61379 (size: 1444.5 KB, free: 256.7 MB)
17/10/25 21:20:21 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:61379 (size: 1296.0 KB, free: 255.4 MB)
17/10/25 21:20:21 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 697 ms on localhost (executor driver) (2/4)
17/10/25 21:20:21 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 704 ms on localhost (executor driver) (3/4)
17/10/25 21:20:21 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2980 bytes result sent to driver
17/10/25 21:20:21 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.722 s
17/10/25 21:20:21 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:21 INFO DAGScheduler: running: Set()
17/10/25 21:20:21 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/25 21:20:21 INFO DAGScheduler: failed: Set()
17/10/25 21:20:21 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 254.4 MB)
17/10/25 21:20:21 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 720 ms on localhost (executor driver) (4/4)
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.4 MB)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/25 21:20:21 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:20:21 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/25 21:20:21 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/25 21:20:21 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/25 21:20:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/25 21:20:21 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/25 21:20:21 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/25 21:20:21 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.744067 s
17/10/25 21:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:21 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/25 21:20:21 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:20:21 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/25 21:20:21 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:20:21 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/25 21:20:21 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/25 21:20:21 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/25 21:20:21 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 254.4 MB)
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 254.4 MB)
17/10/25 21:20:21 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61379 (size: 19.5 KB, free: 255.4 MB)
17/10/25 21:20:21 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:21 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/25 21:20:21 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:21 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:21 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:21 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:20:21 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/25 21:20:21 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/25 21:20:21 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/25 21:20:21 INFO BlockManager: Found block rdd_58_0 locally
17/10/25 21:20:21 INFO BlockManager: Found block rdd_58_2 locally
17/10/25 21:20:21 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/25 21:20:21 INFO BlockManager: Found block rdd_58_3 locally
17/10/25 21:20:21 INFO BlockManager: Found block rdd_58_1 locally
17/10/25 21:20:21 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2019 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 32 ms on localhost (executor driver) (1/4)
17/10/25 21:20:21 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2019 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 37 ms on localhost (executor driver) (2/4)
17/10/25 21:20:21 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2106 bytes result sent to driver
17/10/25 21:20:21 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 44 ms on localhost (executor driver) (3/4)
17/10/25 21:20:21 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2019 bytes result sent to driver
17/10/25 21:20:21 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.051 s
17/10/25 21:20:21 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:20:21 INFO DAGScheduler: running: Set()
17/10/25 21:20:21 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/25 21:20:21 INFO DAGScheduler: failed: Set()
17/10/25 21:20:21 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/25 21:20:21 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 46 ms on localhost (executor driver) (4/4)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 254.3 MB)
17/10/25 21:20:21 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.3 MB)
17/10/25 21:20:21 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61379 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:20:21 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/25 21:20:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/25 21:20:21 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:20:21 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/25 21:20:21 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:20:21 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:20:21 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/25 21:20:21 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:20:21 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.074150 s
17/10/25 21:20:21 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:20:21 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/25 21:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz6`
WHERE (0 = 1)
17/10/25 21:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:20:21 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:20:21 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:20:21 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:20:21 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 21:20:21 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/25 21:20:21 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 21:20:21 INFO MemoryStore: MemoryStore cleared
17/10/25 21:20:21 INFO BlockManager: BlockManager stopped
17/10/25 21:20:21 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 21:20:21 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 21:20:21 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:20:21 INFO SparkContext: Successfully stopped SparkContext
17/10/25 21:20:21 INFO ShutdownHookManager: Shutdown hook called
17/10/25 21:20:21 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f
17/10/25 21:20:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1\userFiles-402ec328-c04a-4b7f-ba8f-999246b5748f
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:20:21 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1
17/10/25 21:20:21 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c8ccce13-526b-4c09-9bb0-257799d8fed1
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:22:09 INFO SparkContext: Running Spark version 2.1.0
17/10/25 21:22:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/25 21:22:09 INFO SecurityManager: Changing view acls to: scibr
17/10/25 21:22:09 INFO SecurityManager: Changing modify acls to: scibr
17/10/25 21:22:09 INFO SecurityManager: Changing view acls groups to: 
17/10/25 21:22:09 INFO SecurityManager: Changing modify acls groups to: 
17/10/25 21:22:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/25 21:22:09 INFO Utils: Successfully started service 'sparkDriver' on port 61519.
17/10/25 21:22:09 INFO SparkEnv: Registering MapOutputTracker
17/10/25 21:22:09 INFO SparkEnv: Registering BlockManagerMaster
17/10/25 21:22:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/25 21:22:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/25 21:22:09 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-0135a6c9-7cb7-426d-8448-142d37186eb3
17/10/25 21:22:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/25 21:22:09 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/25 21:22:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/25 21:22:10 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/25 21:22:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:61519/jars/sparklyr-2.1-2.11.jar with timestamp 1508934130160
17/10/25 21:22:10 INFO Executor: Starting executor ID driver on host localhost
17/10/25 21:22:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 61540.
17/10/25 21:22:10 INFO NettyBlockTransferService: Server created on 127.0.0.1:61540
17/10/25 21:22:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/25 21:22:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 61540, None)
17/10/25 21:22:10 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:61540 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 61540, None)
17/10/25 21:22:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 61540, None)
17/10/25 21:22:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 61540, None)
17/10/25 21:22:10 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/25 21:22:10 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/25 21:22:10 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/25 21:22:11 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/25 21:22:11 INFO ObjectStore: ObjectStore, initialize called
17/10/25 21:22:11 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/25 21:22:11 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/25 21:22:13 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/25 21:22:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:22:13 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:22:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:22:14 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:22:14 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/25 21:22:14 INFO ObjectStore: Initialized ObjectStore
17/10/25 21:22:14 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/25 21:22:15 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/25 21:22:15 INFO HiveMetaStore: Added admin role in metastore
17/10/25 21:22:15 INFO HiveMetaStore: Added public role in metastore
17/10/25 21:22:15 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/25 21:22:15 INFO HiveMetaStore: 0: get_all_databases
17/10/25 21:22:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/25 21:22:15 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/25 21:22:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/25 21:22:15 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/25 21:22:15 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/7d818f01-9238-4a28-9d25-e0e3038faf0f_resources
17/10/25 21:22:15 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7d818f01-9238-4a28-9d25-e0e3038faf0f
17/10/25 21:22:15 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/7d818f01-9238-4a28-9d25-e0e3038faf0f
17/10/25 21:22:15 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7d818f01-9238-4a28-9d25-e0e3038faf0f/_tmp_space.db
17/10/25 21:22:15 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/25 21:22:15 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:22:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:22:15 INFO HiveMetaStore: 0: get_database: global_temp
17/10/25 21:22:15 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/25 21:22:15 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/25 21:22:15 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:22:18 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:22:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:22:18 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:22:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:22:18 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:22:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:22:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:22:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/25 21:22:18 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/25 21:22:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/25 21:22:18 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/25 21:22:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/25 21:22:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:22:29 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/25 21:22:29 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/25 21:22:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/25 21:22:29 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/25 21:22:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/25 21:22:36 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:22:36 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 10
17/10/25 21:22:36 INFO HiveMetaStore: 0: get_table : db=default tbl=payment
17/10/25 21:22:36 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=payment	
17/10/25 21:22:36 INFO HiveMetaStore: 0: get_table : db=default tbl=payment
17/10/25 21:22:36 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=payment	
17/10/25 21:22:57 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:22:57 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:22:57 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:22:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:22:57 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:22:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:22:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:22:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:22:57 INFO CodeGenerator: Code generated in 300.276042 ms
17/10/25 21:22:58 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:22:58 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:22:58 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/25 21:22:58 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:22:58 INFO DAGScheduler: Missing parents: List()
17/10/25 21:22:58 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/25 21:22:58 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/25 21:22:58 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/25 21:22:58 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:61540 (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:22:58 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/25 21:22:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/25 21:22:58 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/25 21:22:58 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6041 bytes)
17/10/25 21:22:58 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/25 21:22:58 INFO Executor: Fetching spark://127.0.0.1:61519/jars/sparklyr-2.1-2.11.jar with timestamp 1508934130160
17/10/25 21:22:58 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61519 after 15 ms (0 ms spent in bootstraps)
17/10/25 21:22:58 INFO Utils: Fetching spark://127.0.0.1:61519/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276\fetchFileTemp5592510018552229733.tmp
17/10/25 21:22:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5/userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276/sparklyr-2.1-2.11.jar to class loader
17/10/25 21:22:59 INFO CodeGenerator: Code generated in 16.950483 ms
17/10/25 21:22:59 INFO CodeGenerator: Code generated in 13.869837 ms
17/10/25 21:22:59 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/10/25 21:22:59 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 414 ms on localhost (executor driver) (1/1)
17/10/25 21:22:59 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/25 21:22:59 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 0.434 s
17/10/25 21:22:59 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 0.979068 s
17/10/25 21:23:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:02 INFO SparkSqlParser: Parsing command: loan
17/10/25 21:23:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:02 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/25 21:23:02 INFO SparkSqlParser: Parsing command: `loan`
17/10/25 21:23:02 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:23:02 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:23:02 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: string ... 17 more fields>
17/10/25 21:23:02 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:23:02 INFO CodeGenerator: Code generated in 7.085025 ms
17/10/25 21:23:03 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/25 21:23:03 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/25 21:23:03 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:61540 (size: 23.9 KB, free: 366.3 MB)
17/10/25 21:23:03 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 28629131 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:23:03 INFO CodeGenerator: Code generated in 12.370311 ms
17/10/25 21:23:03 INFO CodeGenerator: Code generated in 10.70041 ms
17/10/25 21:23:03 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:03 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:03 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:23:03 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/25 21:23:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/25 21:23:03 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:03 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/25 21:23:03 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/25 21:23:03 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:61540 (size: 11.2 KB, free: 366.3 MB)
17/10/25 21:23:03 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:03 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/25 21:23:03 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:03 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:03 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:03 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:03 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/25 21:23:03 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/25 21:23:03 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/25 21:23:03 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/25 21:23:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 0-28629131, partition values: [empty row]
17/10/25 21:23:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 85887393-110322221, partition values: [empty row]
17/10/25 21:23:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 28629131-57258262, partition values: [empty row]
17/10/25 21:23:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_245abd855135e5459979749f9fc868432855a71f056817f528af7d5719c4453f.csv, range: 57258262-85887393, partition values: [empty row]
17/10/25 21:23:03 INFO CodeGenerator: Code generated in 26.061047 ms
17/10/25 21:23:04 INFO ContextCleaner: Cleaned accumulator 54
17/10/25 21:23:05 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:61540 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/25 21:23:05 INFO ContextCleaner: Cleaned accumulator 1
17/10/25 21:23:05 INFO ContextCleaner: Cleaned accumulator 0
17/10/25 21:23:06 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 18.4 MB, free 347.5 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:61540 (size: 18.4 MB, free: 347.8 MB)
17/10/25 21:23:06 INFO CodeGenerator: Code generated in 7.773719 ms
17/10/25 21:23:06 INFO CodeGenerator: Code generated in 30.455959 ms
17/10/25 21:23:06 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3070 bytes result sent to driver
17/10/25 21:23:06 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 21.6 MB, free 326.0 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:61540 (size: 21.6 MB, free: 326.3 MB)
17/10/25 21:23:06 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 2992 ms on localhost (executor driver) (1/4)
17/10/25 21:23:06 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/25 21:23:06 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 3018 ms on localhost (executor driver) (2/4)
17/10/25 21:23:06 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 21.6 MB, free 304.4 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:61540 (size: 21.6 MB, free: 304.7 MB)
17/10/25 21:23:06 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/25 21:23:06 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 3058 ms on localhost (executor driver) (3/4)
17/10/25 21:23:06 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 21.6 MB, free 282.8 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:61540 (size: 21.6 MB, free: 283.1 MB)
17/10/25 21:23:06 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/25 21:23:06 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 3.137 s
17/10/25 21:23:06 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 3136 ms on localhost (executor driver) (4/4)
17/10/25 21:23:06 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:06 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/25 21:23:06 INFO DAGScheduler: running: Set()
17/10/25 21:23:06 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/25 21:23:06 INFO DAGScheduler: failed: Set()
17/10/25 21:23:06 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 282.8 MB)
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.8 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:23:06 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/25 21:23:06 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:23:06 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/25 21:23:06 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 9 ms
17/10/25 21:23:06 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/25 21:23:06 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.048 s
17/10/25 21:23:06 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 3.254875 s
17/10/25 21:23:06 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 47 ms on localhost (executor driver) (1/1)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/25 21:23:06 INFO CodeGenerator: Code generated in 6.567735 ms
17/10/25 21:23:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:06 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/25 21:23:06 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:23:06 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/25 21:23:06 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:23:06 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/25 21:23:06 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/25 21:23:06 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/25 21:23:06 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 282.8 MB)
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 282.7 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:61540 (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:23:06 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:06 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/25 21:23:06 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:06 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:06 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:06 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:06 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/25 21:23:06 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/25 21:23:06 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/25 21:23:06 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/25 21:23:06 INFO BlockManager: Found block rdd_10_3 locally
17/10/25 21:23:06 INFO BlockManager: Found block rdd_10_1 locally
17/10/25 21:23:06 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:23:06 INFO BlockManager: Found block rdd_10_2 locally
17/10/25 21:23:06 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2019 bytes result sent to driver
17/10/25 21:23:06 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 37 ms on localhost (executor driver) (1/4)
17/10/25 21:23:06 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2019 bytes result sent to driver
17/10/25 21:23:06 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 40 ms on localhost (executor driver) (2/4)
17/10/25 21:23:06 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2188 bytes result sent to driver
17/10/25 21:23:06 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2188 bytes result sent to driver
17/10/25 21:23:06 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 51 ms on localhost (executor driver) (3/4)
17/10/25 21:23:06 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 48 ms on localhost (executor driver) (4/4)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/25 21:23:06 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.052 s
17/10/25 21:23:06 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:06 INFO DAGScheduler: running: Set()
17/10/25 21:23:06 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/25 21:23:06 INFO DAGScheduler: failed: Set()
17/10/25 21:23:06 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 282.7 MB)
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 282.7 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:23:06 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/25 21:23:06 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:23:06 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/25 21:23:06 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:06 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:23:06 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/25 21:23:06 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.010 s
17/10/25 21:23:06 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
17/10/25 21:23:06 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.083392 s
17/10/25 21:23:06 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/25 21:23:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz7`
WHERE (0 = 1)
17/10/25 21:23:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:06 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:23:06 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:06 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:06 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:23:06 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:23:06 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:23:06 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:23:06 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/25 21:23:06 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:23:06 INFO DAGScheduler: Missing parents: List()
17/10/25 21:23:06 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55), which has no missing parents
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 282.7 MB)
17/10/25 21:23:06 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 282.7 MB)
17/10/25 21:23:06 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:61540 (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:23:06 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:06 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/25 21:23:06 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/25 21:23:06 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/25 21:23:06 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/25 21:23:06 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.015 s
17/10/25 21:23:06 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.020915 s
17/10/25 21:23:06 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 14 ms on localhost (executor driver) (1/1)
17/10/25 21:23:06 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/25 21:23:07 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:08 INFO SparkSqlParser: Parsing command: payment
17/10/25 21:23:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:08 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/25 21:23:08 INFO SparkSqlParser: Parsing command: `payment`
17/10/25 21:23:08 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:23:08 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:23:08 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: string, principal: double ... 7 more fields>
17/10/25 21:23:08 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:23:08 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 282.4 MB)
17/10/25 21:23:08 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 282.4 MB)
17/10/25 21:23:08 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:61540 (size: 23.9 KB, free: 283.1 MB)
17/10/25 21:23:08 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:08 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14622813 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:23:08 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:08 INFO DAGScheduler: Registering RDD 36 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:08 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:23:08 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:08 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/25 21:23:08 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/25 21:23:08 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:08 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 282.4 MB)
17/10/25 21:23:08 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 282.4 MB)
17/10/25 21:23:08 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:61540 (size: 9.4 KB, free: 283.0 MB)
17/10/25 21:23:08 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:08 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:08 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/25 21:23:08 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:08 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:08 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:08 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/25 21:23:08 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/25 21:23:08 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/25 21:23:08 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/25 21:23:08 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/25 21:23:08 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 0-14622813, partition values: [empty row]
17/10/25 21:23:08 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 29245626-43868439, partition values: [empty row]
17/10/25 21:23:08 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 14622813-29245626, partition values: [empty row]
17/10/25 21:23:08 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_e0879bba5ee8e21fc14a525a77c12ab77982908e75c6699a32f3cdc89a9a0d48.csv, range: 43868439-54296951, partition values: [empty row]
17/10/25 21:23:08 INFO CodeGenerator: Code generated in 16.479893 ms
17/10/25 21:23:08 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 283.0 MB)
17/10/25 21:23:08 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:61540 in memory (size: 11.2 KB, free: 283.1 MB)
17/10/25 21:23:08 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 283.1 MB)
17/10/25 21:23:08 INFO ContextCleaner: Cleaned accumulator 416
17/10/25 21:23:08 INFO ContextCleaner: Cleaned accumulator 417
17/10/25 21:23:08 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:61540 in memory (size: 4.6 KB, free: 283.1 MB)
17/10/25 21:23:08 INFO ContextCleaner: Cleaned accumulator 470
17/10/25 21:23:08 INFO ContextCleaner: Cleaned accumulator 235
17/10/25 21:23:09 INFO MemoryStore: Block rdd_33_3 stored as values in memory (estimated size 4.5 MB, free 278.0 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added rdd_33_3 in memory on 127.0.0.1:61540 (size: 4.5 MB, free: 278.6 MB)
17/10/25 21:23:09 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 942 ms on localhost (executor driver) (1/4)
17/10/25 21:23:09 INFO MemoryStore: Block rdd_33_2 stored as values in memory (estimated size 6.2 MB, free 271.7 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added rdd_33_2 in memory on 127.0.0.1:61540 (size: 6.2 MB, free: 272.3 MB)
17/10/25 21:23:09 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2983 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 1158 ms on localhost (executor driver) (2/4)
17/10/25 21:23:09 INFO MemoryStore: Block rdd_33_1 stored as values in memory (estimated size 6.3 MB, free 265.4 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added rdd_33_1 in memory on 127.0.0.1:61540 (size: 6.3 MB, free: 266.0 MB)
17/10/25 21:23:09 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 1190 ms on localhost (executor driver) (3/4)
17/10/25 21:23:09 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 6.3 MB, free 259.1 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:61540 (size: 6.3 MB, free: 259.7 MB)
17/10/25 21:23:09 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/25 21:23:09 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 1.208 s
17/10/25 21:23:09 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:09 INFO DAGScheduler: running: Set()
17/10/25 21:23:09 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/25 21:23:09 INFO DAGScheduler: failed: Set()
17/10/25 21:23:09 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:09 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 1206 ms on localhost (executor driver) (4/4)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 259.1 MB)
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.1 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:23:09 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/25 21:23:09 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/25 21:23:09 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/25 21:23:09 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:23:09 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/25 21:23:09 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/25 21:23:09 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 1.230131 s
17/10/25 21:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:09 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/25 21:23:09 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:23:09 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:196)
17/10/25 21:23:09 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:23:09 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/25 21:23:09 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/25 21:23:09 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/25 21:23:09 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 259.0 MB)
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 259.0 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:61540 (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:23:09 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:09 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/25 21:23:09 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:09 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:09 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:09 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/25 21:23:09 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/25 21:23:09 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/25 21:23:09 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:23:09 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/25 21:23:09 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/25 21:23:09 INFO BlockManager: Found block rdd_33_2 locally
17/10/25 21:23:09 INFO BlockManager: Found block rdd_33_3 locally
17/10/25 21:23:09 INFO BlockManager: Found block rdd_33_1 locally
17/10/25 21:23:09 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2019 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 30 ms on localhost (executor driver) (1/4)
17/10/25 21:23:09 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2098 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 38 ms on localhost (executor driver) (2/4)
17/10/25 21:23:09 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/25 21:23:09 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 43 ms on localhost (executor driver) (3/4)
17/10/25 21:23:09 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 46 ms on localhost (executor driver) (4/4)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/25 21:23:09 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.050 s
17/10/25 21:23:09 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:09 INFO DAGScheduler: running: Set()
17/10/25 21:23:09 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/25 21:23:09 INFO DAGScheduler: failed: Set()
17/10/25 21:23:09 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 259.0 MB)
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 259.0 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:23:09 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/25 21:23:09 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/25 21:23:09 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/25 21:23:09 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:09 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:23:09 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/25 21:23:09 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.007 s
17/10/25 21:23:09 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.071582 s
17/10/25 21:23:09 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/25 21:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:09 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz8`
WHERE (0 = 1)
17/10/25 21:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:23:09 INFO CodeGenerator: Code generated in 8.185292 ms
17/10/25 21:23:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:23:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:23:09 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/25 21:23:09 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/25 21:23:09 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/25 21:23:09 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:23:09 INFO DAGScheduler: Missing parents: List()
17/10/25 21:23:09 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[53] at map at utils.scala:55), which has no missing parents
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 259.0 MB)
17/10/25 21:23:09 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 259.0 MB)
17/10/25 21:23:09 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:61540 (size: 4.6 KB, free: 259.7 MB)
17/10/25 21:23:09 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[53] at map at utils.scala:55)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/25 21:23:09 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/25 21:23:09 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/25 21:23:09 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/25 21:23:09 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:23:09 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/25 21:23:09 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.005 s
17/10/25 21:23:09 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.012305 s
17/10/25 21:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:10 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:61540 in memory (size: 4.6 KB, free: 259.7 MB)
17/10/25 21:23:10 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:23:10 INFO ContextCleaner: Cleaned accumulator 651
17/10/25 21:23:10 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:61540 in memory (size: 9.4 KB, free: 259.7 MB)
17/10/25 21:23:10 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 259.7 MB)
17/10/25 21:23:10 INFO ContextCleaner: Cleaned accumulator 832
17/10/25 21:23:10 INFO ContextCleaner: Cleaned accumulator 833
17/10/25 21:23:10 INFO SparkSqlParser: Parsing command: cuv
17/10/25 21:23:10 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:10 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/25 21:23:10 INFO SparkSqlParser: Parsing command: `cuv`
17/10/25 21:23:10 INFO FileSourceStrategy: Pruning directories with: 
17/10/25 21:23:10 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/25 21:23:10 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/25 21:23:10 INFO FileSourceStrategy: Pushed Filters: 
17/10/25 21:23:10 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 258.8 MB)
17/10/25 21:23:10 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 258.8 MB)
17/10/25 21:23:10 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:61540 (size: 23.9 KB, free: 259.7 MB)
17/10/25 21:23:10 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:10 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/25 21:23:10 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/25 21:23:10 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/25 21:23:10 INFO DAGScheduler: Registering RDD 60 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:10 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/25 21:23:10 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:10 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/25 21:23:10 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/25 21:23:10 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[60] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:10 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 258.7 MB)
17/10/25 21:23:10 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 258.7 MB)
17/10/25 21:23:10 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:61540 (size: 19.5 KB, free: 259.6 MB)
17/10/25 21:23:10 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:10 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[60] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:10 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/25 21:23:10 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:23:10 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:23:10 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:23:10 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/25 21:23:10 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/25 21:23:10 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/25 21:23:10 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/25 21:23:10 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/25 21:23:10 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/25 21:23:10 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/25 21:23:10 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/25 21:23:10 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/Rtmp8kpifr/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/25 21:23:10 INFO CodeGenerator: Code generated in 84.768839 ms
17/10/25 21:23:10 INFO MemoryStore: Block rdd_57_3 stored as values in memory (estimated size 198.6 KB, free 258.5 MB)
17/10/25 21:23:10 INFO BlockManagerInfo: Added rdd_57_3 in memory on 127.0.0.1:61540 (size: 198.6 KB, free: 259.4 MB)
17/10/25 21:23:10 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/25 21:23:10 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 351 ms on localhost (executor driver) (1/4)
17/10/25 21:23:11 INFO ContextCleaner: Cleaned accumulator 886
17/10/25 21:23:11 INFO MemoryStore: Block rdd_57_2 stored as values in memory (estimated size 1444.5 KB, free 257.1 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added rdd_57_2 in memory on 127.0.0.1:61540 (size: 1444.5 KB, free: 258.0 MB)
17/10/25 21:23:11 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 657 ms on localhost (executor driver) (2/4)
17/10/25 21:23:11 INFO MemoryStore: Block rdd_57_0 stored as values in memory (estimated size 1296.0 KB, free 255.8 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added rdd_57_0 in memory on 127.0.0.1:61540 (size: 1296.0 KB, free: 256.8 MB)
17/10/25 21:23:11 INFO MemoryStore: Block rdd_57_1 stored as values in memory (estimated size 1374.8 KB, free 254.5 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added rdd_57_1 in memory on 127.0.0.1:61540 (size: 1374.8 KB, free: 255.4 MB)
17/10/25 21:23:11 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2983 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 687 ms on localhost (executor driver) (3/4)
17/10/25 21:23:11 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 688 ms on localhost (executor driver) (4/4)
17/10/25 21:23:11 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.690 s
17/10/25 21:23:11 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/25 21:23:11 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:11 INFO DAGScheduler: running: Set()
17/10/25 21:23:11 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/25 21:23:11 INFO DAGScheduler: failed: Set()
17/10/25 21:23:11 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 254.4 MB)
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.4 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:23:11 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0)
17/10/25 21:23:11 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/25 21:23:11 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/25 21:23:11 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/25 21:23:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/25 21:23:11 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/25 21:23:11 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/25 21:23:11 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.713794 s
17/10/25 21:23:11 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:23:11 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/25 21:23:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:11 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/25 21:23:11 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:23:11 INFO DAGScheduler: Registering RDD 67 (collect at utils.scala:196)
17/10/25 21:23:11 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:23:11 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/25 21:23:11 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/25 21:23:11 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/25 21:23:11 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[67] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 254.4 MB)
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 254.4 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:61540 (size: 19.5 KB, free: 255.4 MB)
17/10/25 21:23:11 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:11 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[67] at collect at utils.scala:196)
17/10/25 21:23:11 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/25 21:23:11 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:23:11 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:23:11 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:23:11 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/25 21:23:11 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/25 21:23:11 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/25 21:23:11 INFO BlockManager: Found block rdd_57_1 locally
17/10/25 21:23:11 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:23:11 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/25 21:23:11 INFO BlockManager: Found block rdd_57_2 locally
17/10/25 21:23:11 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/25 21:23:11 INFO BlockManager: Found block rdd_57_3 locally
17/10/25 21:23:11 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2098 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 34 ms on localhost (executor driver) (1/4)
17/10/25 21:23:11 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2188 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 38 ms on localhost (executor driver) (2/4)
17/10/25 21:23:11 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/25 21:23:11 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 46 ms on localhost (executor driver) (3/4)
17/10/25 21:23:11 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2019 bytes result sent to driver
17/10/25 21:23:11 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.053 s
17/10/25 21:23:11 INFO DAGScheduler: looking for newly runnable stages
17/10/25 21:23:11 INFO DAGScheduler: running: Set()
17/10/25 21:23:11 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/25 21:23:11 INFO DAGScheduler: failed: Set()
17/10/25 21:23:11 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[70] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:11 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 51 ms on localhost (executor driver) (4/4)
17/10/25 21:23:11 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 254.3 MB)
17/10/25 21:23:11 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 254.3 MB)
17/10/25 21:23:11 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:61540 (size: 3.7 KB, free: 255.4 MB)
17/10/25 21:23:11 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:11 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[70] at collect at utils.scala:196)
17/10/25 21:23:11 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/25 21:23:11 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/25 21:23:11 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/25 21:23:11 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/25 21:23:11 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/25 21:23:11 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1963 bytes result sent to driver
17/10/25 21:23:11 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/25 21:23:11 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:23:11 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.070104 s
17/10/25 21:23:11 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/25 21:23:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:11 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz9`
WHERE (0 = 1)
17/10/25 21:23:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:23:11 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:11 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:23:11 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:23:11 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:23:14 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:23:14 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/25 21:23:14 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:23:14 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:23:14 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/10/25 21:23:14 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:23:14 INFO DAGScheduler: Missing parents: List()
17/10/25 21:23:14 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at collect at utils.scala:196), which has no missing parents
17/10/25 21:23:14 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 23.0 KB, free 254.3 MB)
17/10/25 21:23:14 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.7 KB, free 254.3 MB)
17/10/25 21:23:14 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:61540 (size: 9.7 KB, free: 255.4 MB)
17/10/25 21:23:14 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/25 21:23:14 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at collect at utils.scala:196)
17/10/25 21:23:14 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/25 21:23:14 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:23:14 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/25 21:23:14 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:23:14 INFO CodeGenerator: Code generated in 352.910295 ms
17/10/25 21:23:14 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_10_0]
17/10/25 21:23:14 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 3107 bytes result sent to driver
17/10/25 21:23:14 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 415 ms on localhost (executor driver) (1/1)
17/10/25 21:23:14 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/25 21:23:14 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0.416 s
17/10/25 21:23:14 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.422269 s
17/10/25 21:23:14 INFO CodeGenerator: Code generated in 21.013365 ms
17/10/25 21:28:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:28:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 10
17/10/25 21:28:23 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:28:23 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:28:23 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/10/25 21:28:23 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:28:23 INFO DAGScheduler: Missing parents: List()
17/10/25 21:28:23 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[76] at collect at utils.scala:196), which has no missing parents
17/10/25 21:28:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 67.5 KB, free 254.2 MB)
17/10/25 21:28:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 17.6 KB, free 254.2 MB)
17/10/25 21:28:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:61540 (size: 17.6 KB, free: 255.4 MB)
17/10/25 21:28:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/25 21:28:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[76] at collect at utils.scala:196)
17/10/25 21:28:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/25 21:28:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:28:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
17/10/25 21:28:23 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:28:23 INFO CodeGenerator: Code generated in 29.384943 ms
17/10/25 21:28:23 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_57_0]
17/10/25 21:28:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 2659 bytes result sent to driver
17/10/25 21:28:23 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.042 s
17/10/25 21:28:23 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 0.049665 s
17/10/25 21:28:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 42 ms on localhost (executor driver) (1/1)
17/10/25 21:28:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/25 21:28:24 INFO CodeGenerator: Code generated in 23.170793 ms
17/10/25 21:29:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:29:21 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/25 21:29:21 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:29:21 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:29:21 INFO DAGScheduler: Final stage: ResultStage 17 (collect at utils.scala:196)
17/10/25 21:29:21 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:29:21 INFO DAGScheduler: Missing parents: List()
17/10/25 21:29:21 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/10/25 21:29:21 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 23.0 KB, free 254.2 MB)
17/10/25 21:29:21 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 9.7 KB, free 254.2 MB)
17/10/25 21:29:21 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:61540 (size: 9.7 KB, free: 255.4 MB)
17/10/25 21:29:21 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/25 21:29:21 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/10/25 21:29:21 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/25 21:29:21 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 35, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:29:21 INFO Executor: Running task 0.0 in stage 17.0 (TID 35)
17/10/25 21:29:21 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:29:21 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_10_0]
17/10/25 21:29:21 INFO Executor: Finished task 0.0 in stage 17.0 (TID 35). 3028 bytes result sent to driver
17/10/25 21:29:21 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 35) in 8 ms on localhost (executor driver) (1/1)
17/10/25 21:29:21 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/25 21:29:21 INFO DAGScheduler: ResultStage 17 (collect at utils.scala:196) finished in 0.009 s
17/10/25 21:29:21 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 0.018419 s
17/10/25 21:29:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:29:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 10
17/10/25 21:29:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:29:25 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:29:25 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/10/25 21:29:25 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:29:25 INFO DAGScheduler: Missing parents: List()
17/10/25 21:29:25 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/10/25 21:29:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 16.8 KB, free 254.2 MB)
17/10/25 21:29:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.2 MB)
17/10/25 21:29:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:29:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/25 21:29:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/10/25 21:29:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/10/25 21:29:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 36, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:29:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 36)
17/10/25 21:29:25 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:29:25 INFO CodeGenerator: Code generated in 21.428018 ms
17/10/25 21:29:25 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_33_0]
17/10/25 21:29:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 36). 1924 bytes result sent to driver
17/10/25 21:29:25 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.036 s
17/10/25 21:29:25 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.041764 s
17/10/25 21:29:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 36) in 36 ms on localhost (executor driver) (1/1)
17/10/25 21:29:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/25 21:29:25 INFO CodeGenerator: Code generated in 10.496675 ms
17/10/25 21:30:34 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:30:34 INFO SparkSqlParser: Parsing command: SELECT * FROM cuv LIMIT 5
17/10/25 21:30:34 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:30:34 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:30:34 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/10/25 21:30:34 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:30:34 INFO DAGScheduler: Missing parents: List()
17/10/25 21:30:34 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[82] at collect at utils.scala:196), which has no missing parents
17/10/25 21:30:34 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 67.5 KB, free 254.1 MB)
17/10/25 21:30:34 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 17.6 KB, free 254.1 MB)
17/10/25 21:30:34 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:61540 (size: 17.6 KB, free: 255.3 MB)
17/10/25 21:30:34 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/10/25 21:30:34 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[82] at collect at utils.scala:196)
17/10/25 21:30:34 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/10/25 21:30:34 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 37, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:30:34 INFO Executor: Running task 0.0 in stage 19.0 (TID 37)
17/10/25 21:30:34 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:30:34 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_57_0]
17/10/25 21:30:34 INFO Executor: Finished task 0.0 in stage 19.0 (TID 37). 2119 bytes result sent to driver
17/10/25 21:30:34 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.010 s
17/10/25 21:30:34 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.017703 s
17/10/25 21:30:34 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 37) in 10 ms on localhost (executor driver) (1/1)
17/10/25 21:30:34 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/10/25 21:30:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:30:45 INFO SparkSqlParser: Parsing command: SELECT * FROM loan LIMIT 5
17/10/25 21:30:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:30:45 INFO DAGScheduler: Got job 14 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:30:45 INFO DAGScheduler: Final stage: ResultStage 20 (collect at utils.scala:196)
17/10/25 21:30:45 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:30:45 INFO DAGScheduler: Missing parents: List()
17/10/25 21:30:45 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[84] at collect at utils.scala:196), which has no missing parents
17/10/25 21:30:45 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 23.0 KB, free 254.1 MB)
17/10/25 21:30:45 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 9.8 KB, free 254.1 MB)
17/10/25 21:30:45 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:61540 (size: 9.8 KB, free: 255.3 MB)
17/10/25 21:30:45 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/10/25 21:30:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 20 (MapPartitionsRDD[84] at collect at utils.scala:196)
17/10/25 21:30:45 INFO TaskSchedulerImpl: Adding task set 20.0 with 1 tasks
17/10/25 21:30:45 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 38, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:30:45 INFO Executor: Running task 0.0 in stage 20.0 (TID 38)
17/10/25 21:30:45 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:30:45 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_10_0]
17/10/25 21:30:45 INFO Executor: Finished task 0.0 in stage 20.0 (TID 38). 2341 bytes result sent to driver
17/10/25 21:30:45 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 38) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:30:45 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/10/25 21:30:45 INFO DAGScheduler: ResultStage 20 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:30:45 INFO DAGScheduler: Job 14 finished: collect at utils.scala:196, took 0.012062 s
17/10/25 21:30:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:30:52 INFO SparkSqlParser: Parsing command: SELECT * FROM payment LIMIT 5
17/10/25 21:30:52 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:30:52 INFO DAGScheduler: Got job 15 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:30:52 INFO DAGScheduler: Final stage: ResultStage 21 (collect at utils.scala:196)
17/10/25 21:30:52 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:30:52 INFO DAGScheduler: Missing parents: List()
17/10/25 21:30:52 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[86] at collect at utils.scala:196), which has no missing parents
17/10/25 21:30:52 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 16.8 KB, free 254.0 MB)
17/10/25 21:30:52 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.0 MB)
17/10/25 21:30:52 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.3 MB)
17/10/25 21:30:52 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/10/25 21:30:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[86] at collect at utils.scala:196)
17/10/25 21:30:52 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/10/25 21:30:52 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:30:52 INFO Executor: Running task 0.0 in stage 21.0 (TID 39)
17/10/25 21:30:52 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:30:52 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_33_0]
17/10/25 21:30:52 INFO Executor: Finished task 0.0 in stage 21.0 (TID 39). 1644 bytes result sent to driver
17/10/25 21:30:52 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 39) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:30:52 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/10/25 21:30:52 INFO DAGScheduler: ResultStage 21 (collect at utils.scala:196) finished in 0.005 s
17/10/25 21:30:52 INFO DAGScheduler: Job 15 finished: collect at utils.scala:196, took 0.011129 s
17/10/25 21:36:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:36:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 10
17/10/25 21:36:26 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:36:26 INFO DAGScheduler: Got job 16 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:36:26 INFO DAGScheduler: Final stage: ResultStage 22 (collect at utils.scala:196)
17/10/25 21:36:26 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:36:26 INFO DAGScheduler: Missing parents: List()
17/10/25 21:36:26 INFO DAGScheduler: Submitting ResultStage 22 (MapPartitionsRDD[88] at collect at utils.scala:196), which has no missing parents
17/10/25 21:36:26 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 67.5 KB, free 254.0 MB)
17/10/25 21:36:26 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 17.6 KB, free 253.9 MB)
17/10/25 21:36:26 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:61540 (size: 17.6 KB, free: 255.3 MB)
17/10/25 21:36:26 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/10/25 21:36:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (MapPartitionsRDD[88] at collect at utils.scala:196)
17/10/25 21:36:26 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/10/25 21:36:26 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 40, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:36:26 INFO Executor: Running task 0.0 in stage 22.0 (TID 40)
17/10/25 21:36:26 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:36:26 WARN Executor: 1 block locks were not released by TID = 40:
[rdd_57_0]
17/10/25 21:36:26 INFO Executor: Finished task 0.0 in stage 22.0 (TID 40). 2580 bytes result sent to driver
17/10/25 21:36:26 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 40) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:36:26 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/10/25 21:36:26 INFO DAGScheduler: ResultStage 22 (collect at utils.scala:196) finished in 0.008 s
17/10/25 21:36:26 INFO DAGScheduler: Job 16 finished: collect at utils.scala:196, took 0.014760 s
17/10/25 21:38:20 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:38:20 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 10
17/10/25 21:38:20 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:38:20 INFO DAGScheduler: Got job 17 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:38:20 INFO DAGScheduler: Final stage: ResultStage 23 (collect at utils.scala:196)
17/10/25 21:38:20 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:38:20 INFO DAGScheduler: Missing parents: List()
17/10/25 21:38:20 INFO DAGScheduler: Submitting ResultStage 23 (MapPartitionsRDD[90] at collect at utils.scala:196), which has no missing parents
17/10/25 21:38:20 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 16.8 KB, free 253.9 MB)
17/10/25 21:38:20 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 7.9 KB, free 253.9 MB)
17/10/25 21:38:20 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.3 MB)
17/10/25 21:38:20 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/10/25 21:38:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 23 (MapPartitionsRDD[90] at collect at utils.scala:196)
17/10/25 21:38:20 INFO TaskSchedulerImpl: Adding task set 23.0 with 1 tasks
17/10/25 21:38:20 INFO TaskSetManager: Starting task 0.0 in stage 23.0 (TID 41, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:38:20 INFO Executor: Running task 0.0 in stage 23.0 (TID 41)
17/10/25 21:38:20 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:38:20 WARN Executor: 1 block locks were not released by TID = 41:
[rdd_33_0]
17/10/25 21:38:20 INFO Executor: Finished task 0.0 in stage 23.0 (TID 41). 1924 bytes result sent to driver
17/10/25 21:38:20 INFO TaskSetManager: Finished task 0.0 in stage 23.0 (TID 41) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:38:20 INFO TaskSchedulerImpl: Removed TaskSet 23.0, whose tasks have all completed, from pool 
17/10/25 21:38:20 INFO DAGScheduler: ResultStage 23 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:38:20 INFO DAGScheduler: Job 17 finished: collect at utils.scala:196, took 0.012262 s
17/10/25 21:38:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:38:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
17/10/25 21:38:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:38:38 INFO DAGScheduler: Got job 18 (collect at utils.scala:196) with 4 output partitions
17/10/25 21:38:38 INFO DAGScheduler: Final stage: ResultStage 24 (collect at utils.scala:196)
17/10/25 21:38:38 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:38:38 INFO DAGScheduler: Missing parents: List()
17/10/25 21:38:38 INFO DAGScheduler: Submitting ResultStage 24 (MapPartitionsRDD[92] at collect at utils.scala:196), which has no missing parents
17/10/25 21:38:38 INFO MemoryStore: Block broadcast_27 stored as values in memory (estimated size 16.9 KB, free 253.9 MB)
17/10/25 21:38:38 INFO MemoryStore: Block broadcast_27_piece0 stored as bytes in memory (estimated size 8.0 KB, free 253.9 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Added broadcast_27_piece0 in memory on 127.0.0.1:61540 (size: 8.0 KB, free: 255.3 MB)
17/10/25 21:38:38 INFO SparkContext: Created broadcast 27 from broadcast at DAGScheduler.scala:996
17/10/25 21:38:38 INFO DAGScheduler: Submitting 4 missing tasks from ResultStage 24 (MapPartitionsRDD[92] at collect at utils.scala:196)
17/10/25 21:38:38 INFO TaskSchedulerImpl: Adding task set 24.0 with 4 tasks
17/10/25 21:38:38 INFO TaskSetManager: Starting task 0.0 in stage 24.0 (TID 42, localhost, executor driver, partition 0, PROCESS_LOCAL, 6681 bytes)
17/10/25 21:38:38 INFO TaskSetManager: Starting task 1.0 in stage 24.0 (TID 43, localhost, executor driver, partition 1, PROCESS_LOCAL, 6681 bytes)
17/10/25 21:38:38 INFO TaskSetManager: Starting task 2.0 in stage 24.0 (TID 44, localhost, executor driver, partition 2, PROCESS_LOCAL, 6681 bytes)
17/10/25 21:38:38 INFO TaskSetManager: Starting task 3.0 in stage 24.0 (TID 45, localhost, executor driver, partition 3, PROCESS_LOCAL, 6681 bytes)
17/10/25 21:38:38 INFO Executor: Running task 0.0 in stage 24.0 (TID 42)
17/10/25 21:38:38 INFO Executor: Running task 2.0 in stage 24.0 (TID 44)
17/10/25 21:38:38 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:38:38 INFO Executor: Running task 3.0 in stage 24.0 (TID 45)
17/10/25 21:38:38 INFO BlockManager: Found block rdd_33_2 locally
17/10/25 21:38:38 INFO BlockManager: Found block rdd_33_3 locally
17/10/25 21:38:38 INFO Executor: Running task 1.0 in stage 24.0 (TID 43)
17/10/25 21:38:38 INFO BlockManager: Found block rdd_33_1 locally
17/10/25 21:38:38 INFO MemoryStore: Block taskresult_45 stored as bytes in memory (estimated size 3.4 MB, free 250.5 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Added taskresult_45 in memory on 127.0.0.1:61540 (size: 3.4 MB, free: 251.9 MB)
17/10/25 21:38:38 INFO Executor: Finished task 3.0 in stage 24.0 (TID 45). 3546189 bytes result sent via BlockManager)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:61540 in memory (size: 17.6 KB, free: 251.9 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 251.9 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:61540 in memory (size: 17.6 KB, free: 251.9 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:61540 in memory (size: 9.7 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:61540 in memory (size: 17.6 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:61540 in memory (size: 9.8 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO ContextCleaner: Cleaned accumulator 1067
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:61540 in memory (size: 19.5 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:61540 in memory (size: 3.7 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:61540 in memory (size: 9.7 KB, free: 252.0 MB)
17/10/25 21:38:38 INFO MemoryStore: Block taskresult_43 stored as bytes in memory (estimated size 5.2 MB, free 245.9 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Added taskresult_43 in memory on 127.0.0.1:61540 (size: 5.2 MB, free: 246.9 MB)
17/10/25 21:38:38 INFO Executor: Finished task 1.0 in stage 24.0 (TID 43). 5418344 bytes result sent via BlockManager)
17/10/25 21:38:38 INFO MemoryStore: Block taskresult_42 stored as bytes in memory (estimated size 5.1 MB, free 240.8 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Added taskresult_42 in memory on 127.0.0.1:61540 (size: 5.1 MB, free: 241.8 MB)
17/10/25 21:38:38 INFO Executor: Finished task 0.0 in stage 24.0 (TID 42). 5361884 bytes result sent via BlockManager)
17/10/25 21:38:38 INFO MemoryStore: Block taskresult_44 stored as bytes in memory (estimated size 5.0 MB, free 235.7 MB)
17/10/25 21:38:38 INFO BlockManagerInfo: Added taskresult_44 in memory on 127.0.0.1:61540 (size: 5.0 MB, free: 236.7 MB)
17/10/25 21:38:38 INFO Executor: Finished task 2.0 in stage 24.0 (TID 44). 5290644 bytes result sent via BlockManager)
17/10/25 21:38:38 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:61540 after 3 ms (0 ms spent in bootstraps)
17/10/25 21:38:38 INFO TaskSetManager: Finished task 1.0 in stage 24.0 (TID 43) in 316 ms on localhost (executor driver) (1/4)
17/10/25 21:38:38 INFO BlockManagerInfo: Removed taskresult_43 on 127.0.0.1:61540 in memory (size: 5.2 MB, free: 241.9 MB)
17/10/25 21:38:39 INFO TaskSetManager: Finished task 0.0 in stage 24.0 (TID 42) in 353 ms on localhost (executor driver) (2/4)
17/10/25 21:38:39 INFO BlockManagerInfo: Removed taskresult_42 on 127.0.0.1:61540 in memory (size: 5.1 MB, free: 247.0 MB)
17/10/25 21:38:39 INFO TaskSetManager: Finished task 3.0 in stage 24.0 (TID 45) in 372 ms on localhost (executor driver) (3/4)
17/10/25 21:38:39 INFO BlockManagerInfo: Removed taskresult_45 on 127.0.0.1:61540 in memory (size: 3.4 MB, free: 250.4 MB)
17/10/25 21:38:39 INFO TaskSetManager: Finished task 2.0 in stage 24.0 (TID 44) in 414 ms on localhost (executor driver) (4/4)
17/10/25 21:38:39 INFO TaskSchedulerImpl: Removed TaskSet 24.0, whose tasks have all completed, from pool 
17/10/25 21:38:39 INFO DAGScheduler: ResultStage 24 (collect at utils.scala:196) finished in 0.417 s
17/10/25 21:38:39 INFO BlockManagerInfo: Removed taskresult_44 on 127.0.0.1:61540 in memory (size: 5.0 MB, free: 255.4 MB)
17/10/25 21:38:39 INFO DAGScheduler: Job 18 finished: collect at utils.scala:196, took 0.421520 s
17/10/25 21:38:40 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:61540 in memory (size: 9.4 KB, free: 255.4 MB)
17/10/25 21:38:40 INFO ContextCleaner: Cleaned shuffle 2
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 482
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 481
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 480
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 479
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 478
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 477
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 476
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 475
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 474
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 473
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 472
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 471
17/10/25 21:38:40 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:61540 in memory (size: 11.2 KB, free: 255.4 MB)
17/10/25 21:38:40 INFO ContextCleaner: Cleaned shuffle 0
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 66
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 65
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 64
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 63
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 62
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 61
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 60
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 59
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 58
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 57
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 56
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 55
17/10/25 21:38:40 INFO BlockManagerInfo: Removed broadcast_27_piece0 on 127.0.0.1:61540 in memory (size: 8.0 KB, free: 255.4 MB)
17/10/25 21:38:40 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:61540 in memory (size: 19.5 KB, free: 255.5 MB)
17/10/25 21:38:40 INFO ContextCleaner: Cleaned shuffle 4
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 898
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 897
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 896
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 895
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 894
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 893
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 892
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 891
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 890
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 889
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 888
17/10/25 21:38:40 INFO ContextCleaner: Cleaned accumulator 887
17/10/25 21:41:56 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:41:56 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 6
17/10/25 21:41:56 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:41:56 INFO DAGScheduler: Got job 19 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:41:56 INFO DAGScheduler: Final stage: ResultStage 25 (collect at utils.scala:196)
17/10/25 21:41:56 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:41:56 INFO DAGScheduler: Missing parents: List()
17/10/25 21:41:56 INFO DAGScheduler: Submitting ResultStage 25 (MapPartitionsRDD[94] at collect at utils.scala:196), which has no missing parents
17/10/25 21:41:56 INFO MemoryStore: Block broadcast_28 stored as values in memory (estimated size 16.8 KB, free 254.6 MB)
17/10/25 21:41:56 INFO MemoryStore: Block broadcast_28_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.6 MB)
17/10/25 21:41:56 INFO BlockManagerInfo: Added broadcast_28_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.5 MB)
17/10/25 21:41:56 INFO SparkContext: Created broadcast 28 from broadcast at DAGScheduler.scala:996
17/10/25 21:41:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 25 (MapPartitionsRDD[94] at collect at utils.scala:196)
17/10/25 21:41:56 INFO TaskSchedulerImpl: Adding task set 25.0 with 1 tasks
17/10/25 21:41:56 INFO TaskSetManager: Starting task 0.0 in stage 25.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:41:56 INFO Executor: Running task 0.0 in stage 25.0 (TID 46)
17/10/25 21:41:56 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:41:56 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_33_0]
17/10/25 21:41:56 INFO Executor: Finished task 0.0 in stage 25.0 (TID 46). 1674 bytes result sent to driver
17/10/25 21:41:56 INFO TaskSetManager: Finished task 0.0 in stage 25.0 (TID 46) in 16 ms on localhost (executor driver) (1/1)
17/10/25 21:41:56 INFO TaskSchedulerImpl: Removed TaskSet 25.0, whose tasks have all completed, from pool 
17/10/25 21:41:56 INFO DAGScheduler: ResultStage 25 (collect at utils.scala:196) finished in 0.016 s
17/10/25 21:41:56 INFO DAGScheduler: Job 19 finished: collect at utils.scala:196, took 0.062321 s
17/10/25 21:42:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:42:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 6
17/10/25 21:42:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:42:25 INFO DAGScheduler: Got job 20 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:42:25 INFO DAGScheduler: Final stage: ResultStage 26 (collect at utils.scala:196)
17/10/25 21:42:25 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:42:25 INFO DAGScheduler: Missing parents: List()
17/10/25 21:42:25 INFO DAGScheduler: Submitting ResultStage 26 (MapPartitionsRDD[96] at collect at utils.scala:196), which has no missing parents
17/10/25 21:42:25 INFO MemoryStore: Block broadcast_29 stored as values in memory (estimated size 16.8 KB, free 254.6 MB)
17/10/25 21:42:25 INFO MemoryStore: Block broadcast_29_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.6 MB)
17/10/25 21:42:25 INFO BlockManagerInfo: Added broadcast_29_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:42:25 INFO SparkContext: Created broadcast 29 from broadcast at DAGScheduler.scala:996
17/10/25 21:42:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 26 (MapPartitionsRDD[96] at collect at utils.scala:196)
17/10/25 21:42:25 INFO TaskSchedulerImpl: Adding task set 26.0 with 1 tasks
17/10/25 21:42:25 INFO TaskSetManager: Starting task 0.0 in stage 26.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:42:25 INFO Executor: Running task 0.0 in stage 26.0 (TID 47)
17/10/25 21:42:25 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:42:25 WARN Executor: 1 block locks were not released by TID = 47:
[rdd_33_0]
17/10/25 21:42:25 INFO Executor: Finished task 0.0 in stage 26.0 (TID 47). 1674 bytes result sent to driver
17/10/25 21:42:25 INFO TaskSetManager: Finished task 0.0 in stage 26.0 (TID 47) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:42:25 INFO TaskSchedulerImpl: Removed TaskSet 26.0, whose tasks have all completed, from pool 
17/10/25 21:42:25 INFO DAGScheduler: ResultStage 26 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:42:25 INFO DAGScheduler: Job 20 finished: collect at utils.scala:196, took 0.013229 s
17/10/25 21:42:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:42:41 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 6
17/10/25 21:42:41 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:42:41 INFO DAGScheduler: Got job 21 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:42:41 INFO DAGScheduler: Final stage: ResultStage 27 (collect at utils.scala:196)
17/10/25 21:42:41 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:42:41 INFO DAGScheduler: Missing parents: List()
17/10/25 21:42:41 INFO DAGScheduler: Submitting ResultStage 27 (MapPartitionsRDD[98] at collect at utils.scala:196), which has no missing parents
17/10/25 21:42:41 INFO MemoryStore: Block broadcast_30 stored as values in memory (estimated size 16.8 KB, free 254.5 MB)
17/10/25 21:42:41 INFO MemoryStore: Block broadcast_30_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.5 MB)
17/10/25 21:42:41 INFO BlockManagerInfo: Added broadcast_30_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:42:41 INFO SparkContext: Created broadcast 30 from broadcast at DAGScheduler.scala:996
17/10/25 21:42:41 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 27 (MapPartitionsRDD[98] at collect at utils.scala:196)
17/10/25 21:42:41 INFO TaskSchedulerImpl: Adding task set 27.0 with 1 tasks
17/10/25 21:42:41 INFO TaskSetManager: Starting task 0.0 in stage 27.0 (TID 48, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:42:41 INFO Executor: Running task 0.0 in stage 27.0 (TID 48)
17/10/25 21:42:41 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:42:41 WARN Executor: 1 block locks were not released by TID = 48:
[rdd_33_0]
17/10/25 21:42:41 INFO Executor: Finished task 0.0 in stage 27.0 (TID 48). 1761 bytes result sent to driver
17/10/25 21:42:41 INFO TaskSetManager: Finished task 0.0 in stage 27.0 (TID 48) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:42:41 INFO TaskSchedulerImpl: Removed TaskSet 27.0, whose tasks have all completed, from pool 
17/10/25 21:42:41 INFO DAGScheduler: ResultStage 27 (collect at utils.scala:196) finished in 0.005 s
17/10/25 21:42:41 INFO DAGScheduler: Job 21 finished: collect at utils.scala:196, took 0.012328 s
17/10/25 21:43:15 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:43:15 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 6
17/10/25 21:43:15 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:43:15 INFO DAGScheduler: Got job 22 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:43:15 INFO DAGScheduler: Final stage: ResultStage 28 (collect at utils.scala:196)
17/10/25 21:43:15 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:43:15 INFO DAGScheduler: Missing parents: List()
17/10/25 21:43:15 INFO DAGScheduler: Submitting ResultStage 28 (MapPartitionsRDD[100] at collect at utils.scala:196), which has no missing parents
17/10/25 21:43:15 INFO MemoryStore: Block broadcast_31 stored as values in memory (estimated size 23.0 KB, free 254.5 MB)
17/10/25 21:43:15 INFO MemoryStore: Block broadcast_31_piece0 stored as bytes in memory (estimated size 9.7 KB, free 254.5 MB)
17/10/25 21:43:15 INFO BlockManagerInfo: Added broadcast_31_piece0 in memory on 127.0.0.1:61540 (size: 9.7 KB, free: 255.4 MB)
17/10/25 21:43:15 INFO SparkContext: Created broadcast 31 from broadcast at DAGScheduler.scala:996
17/10/25 21:43:15 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 28 (MapPartitionsRDD[100] at collect at utils.scala:196)
17/10/25 21:43:15 INFO TaskSchedulerImpl: Adding task set 28.0 with 1 tasks
17/10/25 21:43:15 INFO TaskSetManager: Starting task 0.0 in stage 28.0 (TID 49, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:43:15 INFO Executor: Running task 0.0 in stage 28.0 (TID 49)
17/10/25 21:43:15 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:43:15 WARN Executor: 1 block locks were not released by TID = 49:
[rdd_10_0]
17/10/25 21:43:15 INFO Executor: Finished task 0.0 in stage 28.0 (TID 49). 2493 bytes result sent to driver
17/10/25 21:43:15 INFO TaskSetManager: Finished task 0.0 in stage 28.0 (TID 49) in 5 ms on localhost (executor driver) (1/1)
17/10/25 21:43:15 INFO TaskSchedulerImpl: Removed TaskSet 28.0, whose tasks have all completed, from pool 
17/10/25 21:43:15 INFO DAGScheduler: ResultStage 28 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:43:15 INFO DAGScheduler: Job 22 finished: collect at utils.scala:196, took 0.014326 s
17/10/25 21:43:15 INFO BlockManagerInfo: Removed broadcast_28_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:43:15 INFO BlockManagerInfo: Removed broadcast_29_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:43:15 INFO BlockManagerInfo: Removed broadcast_31_piece0 on 127.0.0.1:61540 in memory (size: 9.7 KB, free: 255.5 MB)
17/10/25 21:43:15 INFO BlockManagerInfo: Removed broadcast_30_piece0 on 127.0.0.1:61540 in memory (size: 7.9 KB, free: 255.5 MB)
17/10/25 21:44:05 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:44:05 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 6
17/10/25 21:44:05 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:44:05 INFO DAGScheduler: Got job 23 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:44:05 INFO DAGScheduler: Final stage: ResultStage 29 (collect at utils.scala:196)
17/10/25 21:44:05 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:44:05 INFO DAGScheduler: Missing parents: List()
17/10/25 21:44:05 INFO DAGScheduler: Submitting ResultStage 29 (MapPartitionsRDD[102] at collect at utils.scala:196), which has no missing parents
17/10/25 21:44:05 INFO MemoryStore: Block broadcast_32 stored as values in memory (estimated size 23.0 KB, free 254.6 MB)
17/10/25 21:44:05 INFO MemoryStore: Block broadcast_32_piece0 stored as bytes in memory (estimated size 9.8 KB, free 254.6 MB)
17/10/25 21:44:05 INFO BlockManagerInfo: Added broadcast_32_piece0 in memory on 127.0.0.1:61540 (size: 9.8 KB, free: 255.5 MB)
17/10/25 21:44:05 INFO SparkContext: Created broadcast 32 from broadcast at DAGScheduler.scala:996
17/10/25 21:44:05 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 29 (MapPartitionsRDD[102] at collect at utils.scala:196)
17/10/25 21:44:05 INFO TaskSchedulerImpl: Adding task set 29.0 with 1 tasks
17/10/25 21:44:05 INFO TaskSetManager: Starting task 0.0 in stage 29.0 (TID 50, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:44:05 INFO Executor: Running task 0.0 in stage 29.0 (TID 50)
17/10/25 21:44:05 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:44:05 WARN Executor: 1 block locks were not released by TID = 50:
[rdd_10_0]
17/10/25 21:44:05 INFO Executor: Finished task 0.0 in stage 29.0 (TID 50). 2493 bytes result sent to driver
17/10/25 21:44:05 INFO TaskSetManager: Finished task 0.0 in stage 29.0 (TID 50) in 6 ms on localhost (executor driver) (1/1)
17/10/25 21:44:05 INFO TaskSchedulerImpl: Removed TaskSet 29.0, whose tasks have all completed, from pool 
17/10/25 21:44:05 INFO DAGScheduler: ResultStage 29 (collect at utils.scala:196) finished in 0.006 s
17/10/25 21:44:05 INFO DAGScheduler: Job 23 finished: collect at utils.scala:196, took 0.012972 s
17/10/25 21:48:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:48:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:48:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:48:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_database: default
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/25 21:48:55 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/25 21:48:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/25 21:52:10 INFO BlockManagerInfo: Removed broadcast_32_piece0 on 127.0.0.1:61540 in memory (size: 9.8 KB, free: 255.5 MB)
17/10/25 21:52:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:52:45 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 6
17/10/25 21:52:45 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:52:45 INFO DAGScheduler: Got job 24 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:52:45 INFO DAGScheduler: Final stage: ResultStage 30 (collect at utils.scala:196)
17/10/25 21:52:45 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:52:45 INFO DAGScheduler: Missing parents: List()
17/10/25 21:52:45 INFO DAGScheduler: Submitting ResultStage 30 (MapPartitionsRDD[106] at collect at utils.scala:196), which has no missing parents
17/10/25 21:52:45 INFO MemoryStore: Block broadcast_33 stored as values in memory (estimated size 23.0 KB, free 254.6 MB)
17/10/25 21:52:45 INFO MemoryStore: Block broadcast_33_piece0 stored as bytes in memory (estimated size 9.7 KB, free 254.6 MB)
17/10/25 21:52:45 INFO BlockManagerInfo: Added broadcast_33_piece0 in memory on 127.0.0.1:61540 (size: 9.7 KB, free: 255.5 MB)
17/10/25 21:52:45 INFO SparkContext: Created broadcast 33 from broadcast at DAGScheduler.scala:996
17/10/25 21:52:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 30 (MapPartitionsRDD[106] at collect at utils.scala:196)
17/10/25 21:52:45 INFO TaskSchedulerImpl: Adding task set 30.0 with 1 tasks
17/10/25 21:52:45 INFO TaskSetManager: Starting task 0.0 in stage 30.0 (TID 51, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:52:45 INFO Executor: Running task 0.0 in stage 30.0 (TID 51)
17/10/25 21:52:45 INFO BlockManager: Found block rdd_10_0 locally
17/10/25 21:52:45 WARN Executor: 1 block locks were not released by TID = 51:
[rdd_10_0]
17/10/25 21:52:45 INFO Executor: Finished task 0.0 in stage 30.0 (TID 51). 2580 bytes result sent to driver
17/10/25 21:52:45 INFO DAGScheduler: ResultStage 30 (collect at utils.scala:196) finished in 0.009 s
17/10/25 21:52:45 INFO DAGScheduler: Job 24 finished: collect at utils.scala:196, took 0.016104 s
17/10/25 21:52:45 INFO TaskSetManager: Finished task 0.0 in stage 30.0 (TID 51) in 9 ms on localhost (executor driver) (1/1)
17/10/25 21:52:45 INFO TaskSchedulerImpl: Removed TaskSet 30.0, whose tasks have all completed, from pool 
17/10/25 21:53:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:53:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 6
17/10/25 21:53:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:53:31 INFO DAGScheduler: Got job 25 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:53:31 INFO DAGScheduler: Final stage: ResultStage 31 (collect at utils.scala:196)
17/10/25 21:53:31 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:53:31 INFO DAGScheduler: Missing parents: List()
17/10/25 21:53:31 INFO DAGScheduler: Submitting ResultStage 31 (MapPartitionsRDD[108] at collect at utils.scala:196), which has no missing parents
17/10/25 21:53:31 INFO MemoryStore: Block broadcast_34 stored as values in memory (estimated size 16.8 KB, free 254.6 MB)
17/10/25 21:53:31 INFO MemoryStore: Block broadcast_34_piece0 stored as bytes in memory (estimated size 7.9 KB, free 254.5 MB)
17/10/25 21:53:31 INFO BlockManagerInfo: Added broadcast_34_piece0 in memory on 127.0.0.1:61540 (size: 7.9 KB, free: 255.4 MB)
17/10/25 21:53:31 INFO SparkContext: Created broadcast 34 from broadcast at DAGScheduler.scala:996
17/10/25 21:53:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 31 (MapPartitionsRDD[108] at collect at utils.scala:196)
17/10/25 21:53:31 INFO TaskSchedulerImpl: Adding task set 31.0 with 1 tasks
17/10/25 21:53:31 INFO TaskSetManager: Starting task 0.0 in stage 31.0 (TID 52, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:53:31 INFO Executor: Running task 0.0 in stage 31.0 (TID 52)
17/10/25 21:53:31 INFO BlockManager: Found block rdd_33_0 locally
17/10/25 21:53:31 WARN Executor: 1 block locks were not released by TID = 52:
[rdd_33_0]
17/10/25 21:53:31 INFO Executor: Finished task 0.0 in stage 31.0 (TID 52). 1840 bytes result sent to driver
17/10/25 21:53:31 INFO DAGScheduler: ResultStage 31 (collect at utils.scala:196) finished in 0.009 s
17/10/25 21:53:31 INFO DAGScheduler: Job 25 finished: collect at utils.scala:196, took 0.017717 s
17/10/25 21:53:31 INFO TaskSetManager: Finished task 0.0 in stage 31.0 (TID 52) in 9 ms on localhost (executor driver) (1/1)
17/10/25 21:53:31 INFO TaskSchedulerImpl: Removed TaskSet 31.0, whose tasks have all completed, from pool 
17/10/25 21:54:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:54:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 6
17/10/25 21:54:08 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:54:08 INFO DAGScheduler: Got job 26 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:54:08 INFO DAGScheduler: Final stage: ResultStage 32 (collect at utils.scala:196)
17/10/25 21:54:08 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:54:08 INFO DAGScheduler: Missing parents: List()
17/10/25 21:54:08 INFO DAGScheduler: Submitting ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:196), which has no missing parents
17/10/25 21:54:08 INFO MemoryStore: Block broadcast_35 stored as values in memory (estimated size 67.5 KB, free 254.5 MB)
17/10/25 21:54:08 INFO MemoryStore: Block broadcast_35_piece0 stored as bytes in memory (estimated size 17.6 KB, free 254.5 MB)
17/10/25 21:54:08 INFO BlockManagerInfo: Added broadcast_35_piece0 in memory on 127.0.0.1:61540 (size: 17.6 KB, free: 255.4 MB)
17/10/25 21:54:08 INFO SparkContext: Created broadcast 35 from broadcast at DAGScheduler.scala:996
17/10/25 21:54:08 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 32 (MapPartitionsRDD[110] at collect at utils.scala:196)
17/10/25 21:54:08 INFO TaskSchedulerImpl: Adding task set 32.0 with 1 tasks
17/10/25 21:54:08 INFO TaskSetManager: Starting task 0.0 in stage 32.0 (TID 53, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:54:08 INFO Executor: Running task 0.0 in stage 32.0 (TID 53)
17/10/25 21:54:08 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:54:08 WARN Executor: 1 block locks were not released by TID = 53:
[rdd_57_0]
17/10/25 21:54:08 INFO Executor: Finished task 0.0 in stage 32.0 (TID 53). 2286 bytes result sent to driver
17/10/25 21:54:08 INFO TaskSetManager: Finished task 0.0 in stage 32.0 (TID 53) in 15 ms on localhost (executor driver) (1/1)
17/10/25 21:54:08 INFO TaskSchedulerImpl: Removed TaskSet 32.0, whose tasks have all completed, from pool 
17/10/25 21:54:08 INFO DAGScheduler: ResultStage 32 (collect at utils.scala:196) finished in 0.015 s
17/10/25 21:54:08 INFO DAGScheduler: Job 26 finished: collect at utils.scala:196, took 0.021802 s
17/10/25 21:54:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/25 21:54:27 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 6
17/10/25 21:54:28 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/25 21:54:28 INFO DAGScheduler: Got job 27 (collect at utils.scala:196) with 1 output partitions
17/10/25 21:54:28 INFO DAGScheduler: Final stage: ResultStage 33 (collect at utils.scala:196)
17/10/25 21:54:28 INFO DAGScheduler: Parents of final stage: List()
17/10/25 21:54:28 INFO DAGScheduler: Missing parents: List()
17/10/25 21:54:28 INFO DAGScheduler: Submitting ResultStage 33 (MapPartitionsRDD[112] at collect at utils.scala:196), which has no missing parents
17/10/25 21:54:28 INFO MemoryStore: Block broadcast_36 stored as values in memory (estimated size 67.5 KB, free 254.4 MB)
17/10/25 21:54:28 INFO MemoryStore: Block broadcast_36_piece0 stored as bytes in memory (estimated size 17.5 KB, free 254.4 MB)
17/10/25 21:54:28 INFO BlockManagerInfo: Added broadcast_36_piece0 in memory on 127.0.0.1:61540 (size: 17.5 KB, free: 255.4 MB)
17/10/25 21:54:28 INFO SparkContext: Created broadcast 36 from broadcast at DAGScheduler.scala:996
17/10/25 21:54:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 33 (MapPartitionsRDD[112] at collect at utils.scala:196)
17/10/25 21:54:28 INFO TaskSchedulerImpl: Adding task set 33.0 with 1 tasks
17/10/25 21:54:28 INFO TaskSetManager: Starting task 0.0 in stage 33.0 (TID 54, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/25 21:54:28 INFO Executor: Running task 0.0 in stage 33.0 (TID 54)
17/10/25 21:54:28 INFO BlockManager: Found block rdd_57_0 locally
17/10/25 21:54:28 WARN Executor: 1 block locks were not released by TID = 54:
[rdd_57_0]
17/10/25 21:54:28 INFO Executor: Finished task 0.0 in stage 33.0 (TID 54). 2196 bytes result sent to driver
17/10/25 21:54:28 INFO DAGScheduler: ResultStage 33 (collect at utils.scala:196) finished in 0.007 s
17/10/25 21:54:28 INFO DAGScheduler: Job 27 finished: collect at utils.scala:196, took 0.014162 s
17/10/25 21:54:28 INFO TaskSetManager: Finished task 0.0 in stage 33.0 (TID 54) in 7 ms on localhost (executor driver) (1/1)
17/10/25 21:54:28 INFO TaskSchedulerImpl: Removed TaskSet 33.0, whose tasks have all completed, from pool 
17/10/25 21:55:48 INFO SparkContext: Invoking stop() from shutdown hook
17/10/25 21:55:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/25 21:55:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/25 21:55:48 INFO MemoryStore: MemoryStore cleared
17/10/25 21:55:48 INFO BlockManager: BlockManager stopped
17/10/25 21:55:48 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/25 21:55:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/25 21:55:48 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:55:48 INFO SparkContext: Successfully stopped SparkContext
17/10/25 21:55:48 INFO ShutdownHookManager: Shutdown hook called
17/10/25 21:55:48 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276
17/10/25 21:55:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5\userFiles-2794eeed-40cf-480e-b7f0-41e3d41fb276
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/25 21:55:48 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5
17/10/25 21:55:48 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d00d7c9f-c77b-440d-813b-83e5fc21f0f5
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
