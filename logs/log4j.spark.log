17/10/26 11:12:19 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:12:19 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:12:19 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:12:20 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:12:20 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:12:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:12:20 INFO Utils: Successfully started service 'sparkDriver' on port 64462.
17/10/26 11:12:20 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:12:20 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:12:20 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-7e94fa26-ff15-476c-a22d-4bf96915d5df
17/10/26 11:12:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:12:20 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:12:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:12:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:12:20 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64462/jars/sparklyr-2.1-2.11.jar with timestamp 1508983940590
17/10/26 11:12:20 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:12:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64483.
17/10/26 11:12:20 INFO NettyBlockTransferService: Server created on 127.0.0.1:64483
17/10/26 11:12:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:12:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64483 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:12:22 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:12:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:12:24 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:12:24 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:12:25 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:12:25 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:12:28 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:12:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:12:30 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:12:30 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:12:30 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:12:31 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:12:31 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:12:32 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:12:32 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:12:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:12:32 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:12:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:12:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:32 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/870b007d-2d62-45e0-8217-faf8f9f71e31_resources
17/10/26 11:12:32 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/870b007d-2d62-45e0-8217-faf8f9f71e31
17/10/26 11:12:33 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/870b007d-2d62-45e0-8217-faf8f9f71e31
17/10/26 11:12:33 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/870b007d-2d62-45e0-8217-faf8f9f71e31/_tmp_space.db
17/10/26 11:12:33 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:12:33 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:33 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:33 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:12:33 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:12:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:12:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:12:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:12:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:13:08 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:13:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:13:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:13:09 INFO MemoryStore: MemoryStore cleared
17/10/26 11:13:09 INFO BlockManager: BlockManager stopped
17/10/26 11:13:09 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:13:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:13:09 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:13:09 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:13:09 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-fcc72061-2071-4fc4-9f02-c40dff673499
17/10/26 11:13:39 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:13:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:13:39 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:13:39 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:13:39 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:13:39 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:13:39 INFO Utils: Successfully started service 'sparkDriver' on port 64593.
17/10/26 11:13:39 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:13:40 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:13:40 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-b32c2790-5e80-4bc2-a702-e1a36981fd49
17/10/26 11:13:40 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:13:40 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:13:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:13:40 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:13:40 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar with timestamp 1508984020397
17/10/26 11:13:40 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:13:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64615.
17/10/26 11:13:40 INFO NettyBlockTransferService: Server created on 127.0.0.1:64615
17/10/26 11:13:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:13:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64615 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:41 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:13:41 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:13:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:13:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:13:41 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:13:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:13:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:13:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:13:44 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:13:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:13:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:13:45 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:13:45 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:13:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:13:45 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:13:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:13:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:13:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:13:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/0952b4da-6c2f-4425-be18-443d5516be6f_resources
17/10/26 11:13:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0952b4da-6c2f-4425-be18-443d5516be6f
17/10/26 11:13:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/0952b4da-6c2f-4425-be18-443d5516be6f
17/10/26 11:13:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0952b4da-6c2f-4425-be18-443d5516be6f/_tmp_space.db
17/10/26 11:13:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:13:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:46 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:13:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:13:46 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:13:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:13:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:13:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:26:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:26:27 INFO CodeGenerator: Code generated in 401.853725 ms
17/10/26 11:26:28 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:26:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:26:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:26:28 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:26:28 INFO DAGScheduler: Missing parents: List()
17/10/26 11:26:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/26 11:26:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:26:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:26:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:26:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:26:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/26 11:26:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:26:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/10/26 11:26:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:26:29 INFO Executor: Fetching spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar with timestamp 1508984020397
17/10/26 11:26:29 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64593 after 50 ms (0 ms spent in bootstraps)
17/10/26 11:26:29 INFO Utils: Fetching spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58\fetchFileTemp4993423065593793364.tmp
17/10/26 11:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-6104894c-0bb7-412c-a699-2dc0f02f4499/userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:26:30 INFO CodeGenerator: Code generated in 12.634089 ms
17/10/26 11:26:30 INFO CodeGenerator: Code generated in 13.814413 ms
17/10/26 11:26:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 11:26:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1496 ms on localhost (executor driver) (1/1)
17/10/26 11:26:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:26:30 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 1.594 s
17/10/26 11:26:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 2.428761 s
17/10/26 11:26:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:26:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:26:54 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:26:54 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:26:54 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:26:54 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:26:54 INFO CodeGenerator: Code generated in 8.718491 ms
17/10/26 11:26:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/26 11:26:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/26 11:26:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 366.3 MB)
17/10/26 11:26:55 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:26:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:26:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 41.231806 ms
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 11.004214 ms
17/10/26 11:26:57 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:26:57 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:26:57 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:26:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:26:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:26:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:26:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 366.0 MB)
17/10/26 11:26:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64615 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:26:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:26:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:26:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:26:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:26:57 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:26:57 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 25.195306 ms
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 15.4 MB, free 350.6 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:64615 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 4.869607 ms
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 75.236436 ms
17/10/26 11:27:02 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3070 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 5241 ms on localhost (executor driver) (1/4)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:27:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 5303 ms on localhost (executor driver) (2/4)
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2980 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5316 ms on localhost (executor driver) (3/4)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:27:02 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 11:27:02 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 5.353 s
17/10/26 11:27:02 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 5347 ms on localhost (executor driver) (4/4)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:02 INFO DAGScheduler: running: Set()
17/10/26 11:27:02 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:27:02 INFO DAGScheduler: failed: Set()
17/10/26 11:27:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2039 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 93 ms on localhost (executor driver) (1/1)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.094 s
17/10/26 11:27:02 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 5.608583 s
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 6.887962 ms
17/10/26 11:27:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:02 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:27:02 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:02 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/26 11:27:02 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:02 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:27:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:27:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:27:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64615 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:27:02 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:27:02 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:27:02 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_2 locally
17/10/26 11:27:02 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_3 locally
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_1 locally
17/10/26 11:27:02 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/26 11:27:02 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 49 ms on localhost (executor driver) (1/4)
17/10/26 11:27:02 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 47 ms on localhost (executor driver) (2/4)
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 55 ms on localhost (executor driver) (3/4)
17/10/26 11:27:02 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2019 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 58 ms on localhost (executor driver) (4/4)
17/10/26 11:27:02 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.061 s
17/10/26 11:27:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:02 INFO DAGScheduler: running: Set()
17/10/26 11:27:02 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:27:02 INFO DAGScheduler: failed: Set()
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 11:27:02 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:27:02 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.096795 s
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz1`
WHERE (0 = 1)
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 INFO CodeGenerator: Code generated in 8.664606 ms
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:27:03 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:27:03 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:27:03 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:27:03 INFO DAGScheduler: Missing parents: List()
17/10/26 11:27:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:55), which has no missing parents
17/10/26 11:27:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:27:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:27:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:27:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:55)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:27:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/26 11:27:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:27:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 11:27:03 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.012 s
17/10/26 11:27:03 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.017988 s
17/10/26 11:27:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:27:16 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:27:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:27:16 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:27:16 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:27:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 295.5 MB)
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 295.5 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:27:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:17 INFO DAGScheduler: Registering RDD 40 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:27:17 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:27:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:27:17 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.5 MB)
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.5 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64615 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:27:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:27:17 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:27:17 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:27:17 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:27:17 INFO CodeGenerator: Code generated in 21.190927 ms
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64615 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:27:18 INFO MemoryStore: Block rdd_37_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:27:18 INFO BlockManagerInfo: Added rdd_37_3 in memory on 127.0.0.1:64615 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:27:18 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/26 11:27:18 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1626 ms on localhost (executor driver) (1/4)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_1 stored as values in memory (estimated size 7.1 MB, free 283.3 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_1 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 284.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_2 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_2 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:27:19 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2132 ms on localhost (executor driver) (2/4)
17/10/26 11:27:19 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2134 ms on localhost (executor driver) (3/4)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 7.1 MB, free 269.1 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_0 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2980 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2182 ms on localhost (executor driver) (4/4)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.184 s
17/10/26 11:27:19 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:19 INFO DAGScheduler: running: Set()
17/10/26 11:27:19 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:27:19 INFO DAGScheduler: failed: Set()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.1 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.1 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.207284 s
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:27:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:19 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:196)
17/10/26 11:27:19 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:19 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:27:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:27:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:27:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.3 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64615 (size: 9.3 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:27:19 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:27:19 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:27:19 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_2 locally
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_1 locally
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_0 locally
17/10/26 11:27:19 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_3 locally
17/10/26 11:27:19 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 32 ms on localhost (executor driver) (1/4)
17/10/26 11:27:19 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2019 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 38 ms on localhost (executor driver) (2/4)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2098 bytes result sent to driver
17/10/26 11:27:19 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2109 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 47 ms on localhost (executor driver) (3/4)
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 51 ms on localhost (executor driver) (4/4)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.052 s
17/10/26 11:27:19 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:19 INFO DAGScheduler: running: Set()
17/10/26 11:27:19 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:27:19 INFO DAGScheduler: failed: Set()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.006 s
17/10/26 11:27:19 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.070712 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz2`
WHERE (0 = 1)
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:19 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:27:19 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:27:19 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:27:19 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:27:19 INFO DAGScheduler: Missing parents: List()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[56] at map at utils.scala:55), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[56] at map at utils.scala:55)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.007 s
17/10/26 11:27:19 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.014412 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:27:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:27:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:27:21 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:27:21 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:27:21 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:27:21 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:27:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 268.7 MB)
17/10/26 11:27:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 268.7 MB)
17/10/26 11:27:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 269.6 MB)
17/10/26 11:27:21 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:27:22 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:27:22 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:22 INFO DAGScheduler: Registering RDD 63 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:27:22 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:27:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:27:22 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.4 KB, free 268.6 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64615 (size: 19.4 KB, free: 269.6 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:27:22 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:27:22 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:27:22 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:27:22 INFO CodeGenerator: Code generated in 39.167265 ms
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_3 in memory on 127.0.0.1:64615 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2910 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 250 ms on localhost (executor driver) (1/4)
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64615 in memory (size: 9.3 KB, free: 269.5 MB)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_1 stored as values in memory (estimated size 1374.8 KB, free 267.1 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_1 in memory on 127.0.0.1:64615 (size: 1374.8 KB, free: 268.1 MB)
17/10/26 11:27:22 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 647 ms on localhost (executor driver) (2/4)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_0 stored as values in memory (estimated size 1296.0 KB, free 265.9 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_0 in memory on 127.0.0.1:64615 (size: 1296.0 KB, free: 266.8 MB)
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 678 ms on localhost (executor driver) (3/4)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_2 stored as values in memory (estimated size 1444.5 KB, free 264.5 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_2 in memory on 127.0.0.1:64615 (size: 1444.5 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 697 ms on localhost (executor driver) (4/4)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.700 s
17/10/26 11:27:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:22 INFO DAGScheduler: running: Set()
17/10/26 11:27:22 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:27:22 INFO DAGScheduler: failed: Set()
17/10/26 11:27:22 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[66] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.5 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.5 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[66] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 11:27:22 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.717888 s
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:27:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:22 INFO DAGScheduler: Registering RDD 70 (collect at utils.scala:196)
17/10/26 11:27:22 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:22 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:27:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:27:22 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[70] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.4 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64615 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[70] at collect at utils.scala:196)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:27:22 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:27:22 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:27:22 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_0 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_3 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_1 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_2 locally
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 31 ms on localhost (executor driver) (1/4)
17/10/26 11:27:22 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2019 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 33 ms on localhost (executor driver) (2/4)
17/10/26 11:27:22 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2188 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 37 ms on localhost (executor driver) (3/4)
17/10/26 11:27:22 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2098 bytes result sent to driver
17/10/26 11:27:22 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.046 s
17/10/26 11:27:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:22 INFO DAGScheduler: running: Set()
17/10/26 11:27:22 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:27:22 INFO DAGScheduler: failed: Set()
17/10/26 11:27:22 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 44 ms on localhost (executor driver) (4/4)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[73] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[73] at collect at utils.scala:196)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1960 bytes result sent to driver
17/10/26 11:27:22 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:27:22 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.067163 s
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz3`
WHERE (0 = 1)
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
17/10/26 11:28:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:28:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:28:24 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:28:24 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:28:24 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/10/26 11:28:24 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:28:24 INFO DAGScheduler: Missing parents: List()
17/10/26 11:28:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
17/10/26 11:28:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 23.0 KB, free 264.3 MB)
17/10/26 11:28:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.3 MB)
17/10/26 11:28:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64615 (size: 9.8 KB, free: 265.4 MB)
17/10/26 11:28:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:28:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[77] at collect at utils.scala:196)
17/10/26 11:28:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 11:28:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/26 11:28:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:28:24 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 11:28:24 INFO CodeGenerator: Code generated in 62.006541 ms
17/10/26 11:28:24 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_11_0]
17/10/26 11:28:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 2860 bytes result sent to driver
17/10/26 11:28:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 108 ms on localhost (executor driver) (1/1)
17/10/26 11:28:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:28:24 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0.109 s
17/10/26 11:28:24 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.115748 s
17/10/26 11:28:24 INFO CodeGenerator: Code generated in 17.369242 ms
17/10/26 11:29:41 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:29:41 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:29:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:29:41 INFO MemoryStore: MemoryStore cleared
17/10/26 11:29:41 INFO BlockManager: BlockManager stopped
17/10/26 11:29:41 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:29:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:29:41 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:29:41 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:29:41 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:29:41 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
17/10/26 11:29:41 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:29:41 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
17/10/26 11:29:41 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:30:32 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:30:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:30:32 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:30:32 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:30:32 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:30:32 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:30:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:30:32 INFO Utils: Successfully started service 'sparkDriver' on port 65262.
17/10/26 11:30:32 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:30:32 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:30:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:30:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:30:32 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-69af9806-99d1-4263-90ce-9620b1bdbc06
17/10/26 11:30:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:30:32 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:30:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:30:33 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985033145
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar with timestamp 1508985033154
17/10/26 11:30:33 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:30:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65283.
17/10/26 11:30:33 INFO NettyBlockTransferService: Server created on 127.0.0.1:65283
17/10/26 11:30:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:30:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:65283 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:41 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:30:41 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:30:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:30:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:30:41 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:30:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:30:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:30:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:30:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:30:45 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:30:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:30:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:30:45 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:30:45 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:30:46 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:30:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/6f028488-7bbf-4664-8d80-842b7c2b6b34_resources
17/10/26 11:30:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/6f028488-7bbf-4664-8d80-842b7c2b6b34
17/10/26 11:30:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/6f028488-7bbf-4664-8d80-842b7c2b6b34
17/10/26 11:30:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/6f028488-7bbf-4664-8d80-842b7c2b6b34/_tmp_space.db
17/10/26 11:30:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:30:46 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:30:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:30:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:30:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:30:53 INFO CodeGenerator: Code generated in 271.205681 ms
17/10/26 11:30:53 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:30:53 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:30:53 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:30:53 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:30:53 INFO DAGScheduler: Missing parents: List()
17/10/26 11:30:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 11:30:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:30:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:30:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:30:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 11:30:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:30:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 11:30:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:30:53 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:53 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:65262 after 18 ms (0 ms spent in bootstraps)
17/10/26 11:30:53 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2742840931220966368.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4459510818799516931.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985033150
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp806323082261986288.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985033149
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5727980669263494518.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6363069439010329908.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985033151
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6456646630038532034.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5827752843724667175.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2374141353783570734.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985033150
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5459187579081402625.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8318711755761403145.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-io_commons-io-2.4.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3976337685721216165.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8079391995626263115.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7872495369477527078.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7049418588962961197.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9177074596825187002.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1575936606421766094.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985033149
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3109802348462174428.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985033151
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5098455962150965998.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2435543965608014044.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4451874115972699900.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985033151
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2092075019770869602.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985033152
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9102851984076533288.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7673749527030128392.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar with timestamp 1508985033154
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3696092973937146954.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7649542475055932380.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985033153
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2738266663623783929.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar with timestamp 1508985033152
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6910144874801542968.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.tukaani_xz-1.5.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2655093586842437800.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985033151
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4348555572459277080.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6686947476830474629.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2147881421688984089.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3702793189969396276.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985033153
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp598645522178341403.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6456419726235665463.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5278909898596820882.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985033152
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3784038837263464794.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1080052153816943820.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985033150
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4032381652221548810.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5264299048380423706.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985033151
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9223159889164206347.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2392405958270334718.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6484109447926852383.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985033152
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp791593056402977457.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985033149
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2445228675130561356.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985033153
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1876369035523055284.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985033145
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7995274885593316670.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985033147
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6427445503060559425.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.joda_joda-convert-1.7.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985033149
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2054029196635337288.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985033152
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5849724063797702355.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1783111062550501170.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985033148
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3455182515077089237.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2844829993012792331.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985033153
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8874064892466738527.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985033152
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7266062966894123961.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5631392224240216564.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985033150
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2903732657095302908.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6529625397537245116.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1686645793607711125.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985033148
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp669141001862117894.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985033152
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2166702723214688091.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7349055150038510692.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8708210806227670694.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985033153
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2890084703183649163.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985033148
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8165379553186466694.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985033153
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4039885743655703438.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1228569479435347302.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985033147
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7962072925868012878.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985033152
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp325251362956542388.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985033149
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5860663511604687017.tmp
17/10/26 11:31:03 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 11:31:03 INFO Executor: Fetching spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar with timestamp 1508985033149
17/10/26 11:31:03 INFO Utils: Fetching spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4429527471070616632.tmp
17/10/26 11:31:03 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/log4j_log4j-1.2.15.jar to class loader
17/10/26 11:31:03 INFO CodeGenerator: Code generated in 17.035672 ms
17/10/26 11:31:03 INFO CodeGenerator: Code generated in 16.152481 ms
17/10/26 11:31:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 11:31:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9596 ms on localhost (executor driver) (1/1)
17/10/26 11:31:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:31:03 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 9.636 s
17/10/26 11:31:03 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 9.816381 s
17/10/26 11:31:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:31:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:31:26 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:26 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:26 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:31:26 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:26 INFO CodeGenerator: Code generated in 6.430202 ms
17/10/26 11:31:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 11:31:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 11:31:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 366.3 MB)
17/10/26 11:31:26 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:26 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:31:26 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:31:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:26 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 12.906076 ms
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 10.011203 ms
17/10/26 11:31:27 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:27 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:27 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:31:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:31:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:31:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 11:31:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:65283 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:31:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:31:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:31:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:31:27 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:31:27 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 25.697199 ms
17/10/26 11:31:28 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:31:30 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 11:31:30 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:65283 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:31:30 INFO CodeGenerator: Code generated in 5.044603 ms
17/10/26 11:31:30 INFO CodeGenerator: Code generated in 44.516187 ms
17/10/26 11:31:31 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3897 ms on localhost (executor driver) (1/4)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/26 11:31:31 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4171 ms on localhost (executor driver) (2/4)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4166 ms on localhost (executor driver) (3/4)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:31:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.358 s
17/10/26 11:31:31 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4352 ms on localhost (executor driver) (4/4)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO DAGScheduler: running: Set()
17/10/26 11:31:31 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:31:31 INFO DAGScheduler: failed: Set()
17/10/26 11:31:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.045 s
17/10/26 11:31:31 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.467621 s
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 43 ms on localhost (executor driver) (1/1)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO CodeGenerator: Code generated in 7.207676 ms
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:31:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:31 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 11:31:31 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:31 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:31:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:31:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:31:31 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:65283 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:31:31 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:31:31 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:31:31 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 11:31:31 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 51 ms on localhost (executor driver) (1/4)
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/26 11:31:31 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2188 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 63 ms on localhost (executor driver) (2/4)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 68 ms on localhost (executor driver) (3/4)
17/10/26 11:31:31 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2109 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.078 s
17/10/26 11:31:31 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:31 INFO DAGScheduler: running: Set()
17/10/26 11:31:31 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:31:31 INFO DAGScheduler: failed: Set()
17/10/26 11:31:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 72 ms on localhost (executor driver) (4/4)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:31 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.107258 s
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz4`
WHERE (0 = 1)
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:32 INFO CodeGenerator: Code generated in 8.774941 ms
17/10/26 11:31:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:32 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:31:32 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:31:32 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:31:32 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:31:32 INFO DAGScheduler: Missing parents: List()
17/10/26 11:31:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 11:31:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:31:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:31:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:31:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 11:31:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:31:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 11:31:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:31:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 11:31:32 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.017 s
17/10/26 11:31:32 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.023656 s
17/10/26 11:31:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 16 ms on localhost (executor driver) (1/1)
17/10/26 11:31:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:65283 in memory (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:31:45 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:45 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:45 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:31:45 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.6 MB)
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:45 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:45 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:45 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:31:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.5 MB)
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.5 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:65283 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:31:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:31:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:31:45 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:31:45 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:31:45 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:31:45 INFO CodeGenerator: Code generated in 22.687372 ms
17/10/26 11:31:46 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:31:47 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:31:47 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:65283 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:31:47 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/26 11:31:47 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1907 ms on localhost (executor driver) (1/4)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 283.9 MB)
17/10/26 11:31:48 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2388 ms on localhost (executor driver) (2/4)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 276.1 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2426 ms on localhost (executor driver) (3/4)
17/10/26 11:31:48 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2980 bytes result sent to driver
17/10/26 11:31:48 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.431 s
17/10/26 11:31:48 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:48 INFO DAGScheduler: running: Set()
17/10/26 11:31:48 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:31:48 INFO DAGScheduler: failed: Set()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:48 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2429 ms on localhost (executor driver) (4/4)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1960 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 11:31:48 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.455388 s
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:31:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:48 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 11:31:48 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:48 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:31:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:31:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:31:48 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:65283 (size: 9.4 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:31:48 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:31:48 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:31:48 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2188 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 37 ms on localhost (executor driver) (1/4)
17/10/26 11:31:48 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2098 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 41 ms on localhost (executor driver) (2/4)
17/10/26 11:31:48 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2188 bytes result sent to driver
17/10/26 11:31:48 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 49 ms on localhost (executor driver) (3/4)
17/10/26 11:31:48 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 50 ms on localhost (executor driver) (4/4)
17/10/26 11:31:48 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.054 s
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:48 INFO DAGScheduler: running: Set()
17/10/26 11:31:48 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:31:48 INFO DAGScheduler: failed: Set()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:31:48 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.076117 s
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz5`
WHERE (0 = 1)
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:48 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:31:48 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:31:48 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:31:48 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:31:48 INFO DAGScheduler: Missing parents: List()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1169 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.008 s
17/10/26 11:31:48 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.014947 s
17/10/26 11:31:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:31:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:31:51 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:51 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:51 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:31:51 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 269.6 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:51 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:31:51 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:51 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:51 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:31:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:31:51 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:65283 (size: 19.5 KB, free: 269.6 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:31:51 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:31:51 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:31:51 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:31:51 INFO CodeGenerator: Code generated in 48.321964 ms
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:65283 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:65283 in memory (size: 9.4 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 326 ms on localhost (executor driver) (1/4)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 267.2 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:65283 (size: 1296.0 KB, free: 268.2 MB)
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 575 ms on localhost (executor driver) (2/4)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 265.8 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:65283 (size: 1444.5 KB, free: 266.8 MB)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 264.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:65283 (size: 1374.8 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 608 ms on localhost (executor driver) (3/4)
17/10/26 11:31:51 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.619 s
17/10/26 11:31:51 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:51 INFO DAGScheduler: running: Set()
17/10/26 11:31:51 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:31:51 INFO DAGScheduler: failed: Set()
17/10/26 11:31:51 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:31:51 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 617 ms on localhost (executor driver) (4/4)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:31:51 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:31:51 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/26 11:31:51 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.640584 s
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:31:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:31:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:51 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 11:31:51 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:51 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:31:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:31:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:31:51 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:65283 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:31:51 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:31:51 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 11:31:51 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2188 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 21 ms on localhost (executor driver) (1/4)
17/10/26 11:31:52 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2109 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 198 ms on localhost (executor driver) (2/4)
17/10/26 11:31:52 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2109 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 202 ms on localhost (executor driver) (3/4)
17/10/26 11:31:52 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 11:31:52 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.209 s
17/10/26 11:31:52 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:52 INFO DAGScheduler: running: Set()
17/10/26 11:31:52 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:31:52 INFO DAGScheduler: failed: Set()
17/10/26 11:31:52 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:52 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 207 ms on localhost (executor driver) (4/4)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:31:52 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 11:31:52 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 11:31:52 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:31:52 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:31:52 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:31:52 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:31:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:31:52 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1960 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:31:52 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.007 s
17/10/26 11:31:52 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.227617 s
17/10/26 11:31:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz6`
WHERE (0 = 1)
17/10/26 11:31:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:32:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:32:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:32:26 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 11:32:26 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 11:32:26 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_246708450
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 11:32:26 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 11:32:26 INFO DAGScheduler: Got job 9 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 11:32:26 INFO DAGScheduler: Final stage: ResultStage 15 (collect at SpreadRDDBuilder.scala:105)
17/10/26 11:32:26 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:26 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:26 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.1 KB, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1361.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:65283 (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:26 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Adding task set 15.0 with 11 tasks
17/10/26 11:32:26 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:32:26 INFO Executor: Running task 1.0 in stage 15.0 (TID 34)
17/10/26 11:32:26 INFO Executor: Running task 2.0 in stage 15.0 (TID 35)
17/10/26 11:32:26 INFO Executor: Running task 3.0 in stage 15.0 (TID 36)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_2 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 16.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_3 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_2 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:65283 (size: 16.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_3 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_73_2]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_73_0]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_73_3]
17/10/26 11:32:26 INFO Executor: Finished task 3.0 in stage 15.0 (TID 36). 1627 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 2.0 in stage 15.0 (TID 35). 1627 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_73_1]
17/10/26 11:32:26 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1717 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 1.0 in stage 15.0 (TID 34). 1717 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 37, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 4.0 in stage 15.0 (TID 37)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 38, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 39, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 40, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 35) in 38 ms on localhost (executor driver) (1/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 53 ms on localhost (executor driver) (2/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 34) in 38 ms on localhost (executor driver) (3/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 36) in 38 ms on localhost (executor driver) (4/11)
17/10/26 11:32:26 INFO Executor: Running task 5.0 in stage 15.0 (TID 38)
17/10/26 11:32:26 INFO Executor: Running task 6.0 in stage 15.0 (TID 39)
17/10/26 11:32:26 INFO Executor: Running task 7.0 in stage 15.0 (TID 40)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_4 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_6 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_7 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_5 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_4 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_73_4]
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_6 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_7 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_5 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO Executor: Finished task 4.0 in stage 15.0 (TID 37). 1548 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_73_6]
17/10/26 11:32:26 INFO Executor: Finished task 6.0 in stage 15.0 (TID 39). 1461 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 40:
[rdd_73_7]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_73_5]
17/10/26 11:32:26 INFO Executor: Finished task 7.0 in stage 15.0 (TID 40). 1461 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 5.0 in stage 15.0 (TID 38). 1461 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 41, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 42, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 43, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 8.0 in stage 15.0 (TID 41)
17/10/26 11:32:26 INFO Executor: Running task 9.0 in stage 15.0 (TID 42)
17/10/26 11:32:26 INFO Executor: Running task 10.0 in stage 15.0 (TID 43)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 40) in 15 ms on localhost (executor driver) (5/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 38) in 15 ms on localhost (executor driver) (6/11)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_8 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 39) in 15 ms on localhost (executor driver) (7/11)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_9 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_10 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_8 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_9 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_10 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 37) in 31 ms on localhost (executor driver) (8/11)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 41:
[rdd_73_8]
17/10/26 11:32:26 INFO Executor: Finished task 8.0 in stage 15.0 (TID 41). 1540 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 42:
[rdd_73_9]
17/10/26 11:32:26 INFO Executor: Finished task 9.0 in stage 15.0 (TID 42). 1619 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 43:
[rdd_73_10]
17/10/26 11:32:26 INFO Executor: Finished task 10.0 in stage 15.0 (TID 43). 1540 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 41) in 16 ms on localhost (executor driver) (9/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 42) in 16 ms on localhost (executor driver) (10/11)
17/10/26 11:32:26 INFO DAGScheduler: ResultStage 15 (collect at SpreadRDDBuilder.scala:105) finished in 0.069 s
17/10/26 11:32:26 INFO DAGScheduler: Job 9 finished: collect at SpreadRDDBuilder.scala:105, took 0.073755 s
17/10/26 11:32:26 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 43) in 16 ms on localhost (executor driver) (11/11)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:32:26 INFO ParallelCollectionRDD: Removing RDD 73 from persistence list
17/10/26 11:32:26 INFO BlockManager: Removing RDD 73
17/10/26 11:32:26 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 11:32:26 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 11:32:26 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 11:32:26 INFO DAGScheduler: Got job 10 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 11:32:26 INFO DAGScheduler: Final stage: ResultStage 16 (collect at InternalBackendUtils.scala:163)
17/10/26 11:32:26 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:26 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:26 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.0 KB, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1948.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:65283 (size: 1948.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 11:32:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 44, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:32:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 44)
17/10/26 11:32:27 INFO Reflections: Reflections took 262 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 11:32:27 INFO Reflections: Reflections took 125 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO BlockManager: Removing RDD 73
17/10/26 11:32:28 INFO ContextCleaner: Cleaned RDD 73
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:65283 in memory (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:65283 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO Server: jetty-8.1.17.v20150415
17/10/26 11:32:29 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/10/26 11:32:29 INFO Executor: Finished task 0.0 in stage 16.0 (TID 44). 1523 bytes result sent to driver
17/10/26 11:32:29 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 44) in 2633 ms on localhost (executor driver) (1/1)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 11:32:29 INFO DAGScheduler: ResultStage 16 (collect at InternalBackendUtils.scala:163) finished in 2.634 s
17/10/26 11:32:29 INFO DAGScheduler: Job 10 finished: collect at InternalBackendUtils.scala:163, took 2.638711 s
17/10/26 11:32:29 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 11:32:29 INFO DAGScheduler: Got job 11 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 11:32:29 INFO DAGScheduler: Final stage: ResultStage 17 (foreach at InternalBackendUtils.scala:175)
17/10/26 11:32:29 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:29 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:29 INFO DAGScheduler: Submitting ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 11:32:29 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1672.0 B, free 264.4 MB)
17/10/26 11:32:29 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1161.0 B, free 264.4 MB)
17/10/26 11:32:29 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:65283 (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:32:29 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 11:32:29 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 45, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:32:29 INFO Executor: Running task 0.0 in stage 17.0 (TID 45)
17/10/26 11:32:29 INFO Executor: Finished task 0.0 in stage 17.0 (TID 45). 843 bytes result sent to driver
17/10/26 11:32:29 INFO DAGScheduler: ResultStage 17 (foreach at InternalBackendUtils.scala:175) finished in 0.006 s
17/10/26 11:32:29 INFO DAGScheduler: Job 11 finished: foreach at InternalBackendUtils.scala:175, took 0.010409 s
17/10/26 11:32:29 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 45) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 11:32:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:32:31 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:65283 in memory (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:65283 in memory (size: 1948.0 B, free: 265.4 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 1536
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:65283 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:65283 in memory (size: 9.4 KB, free: 265.5 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:65283 in memory (size: 11.2 KB, free: 265.5 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 11:32:44 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_246708450
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)
    
17/10/26 11:33:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:33:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
17/10/26 11:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:33:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:33:25 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:33:25 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/10/26 11:33:25 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:33:25 INFO DAGScheduler: Missing parents: List()
17/10/26 11:33:25 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/10/26 11:33:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 23.0 KB, free 264.6 MB)
17/10/26 11:33:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:33:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:65283 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:33:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 11:33:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/10/26 11:33:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/10/26 11:33:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:33:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 46)
17/10/26 11:33:25 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:33:25 INFO CodeGenerator: Code generated in 22.407174 ms
17/10/26 11:33:25 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_10_0]
17/10/26 11:33:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 46). 2860 bytes result sent to driver
17/10/26 11:33:25 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.040 s
17/10/26 11:33:25 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.046536 s
17/10/26 11:33:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 46) in 40 ms on localhost (executor driver) (1/1)
17/10/26 11:33:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 11:33:25 INFO CodeGenerator: Code generated in 15.539739 ms
17/10/26 11:34:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:34:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 100
17/10/26 11:34:39 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:34:39 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:34:39 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/10/26 11:34:39 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:34:39 INFO DAGScheduler: Missing parents: List()
17/10/26 11:34:39 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/10/26 11:34:39 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 23.0 KB, free 264.5 MB)
17/10/26 11:34:39 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:34:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:65283 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:34:39 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/10/26 11:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/10/26 11:34:39 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/10/26 11:34:39 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:34:39 INFO Executor: Running task 0.0 in stage 19.0 (TID 47)
17/10/26 11:34:39 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:34:39 WARN Executor: 1 block locks were not released by TID = 47:
[rdd_10_0]
17/10/26 11:34:39 INFO Executor: Finished task 0.0 in stage 19.0 (TID 47). 11361 bytes result sent to driver
17/10/26 11:34:39 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.016 s
17/10/26 11:34:39 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.026791 s
17/10/26 11:34:39 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 47) in 16 ms on localhost (executor driver) (1/1)
17/10/26 11:34:39 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/10/26 11:34:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:34:39 INFO SparkSqlParser: Parsing command: SELECT `apr`, `applicationDate`, `originatedDate`, `nPaidOff`, `isFunded`, `loanAmount`, `originallyScheduledPaymentAmount`, `leadCost`, `hasCF`, FACTOR(`loanId`) AS `loanId`, FACTOR(`anon_ssn`) AS `anon_ssn`, FACTOR(`payFrequency`) AS `payFrequency`, FACTOR(`originated`) AS `originated`, FACTOR(`approved`) AS `approved`, FACTOR(`loanStatus`) AS `loanStatus`, FACTOR(`state`) AS `state`, FACTOR(`leadType`) AS `leadType`, FACTOR(`fpStatus`) AS `fpStatus`, FACTOR(`clarityFraudId`) AS `clarityFraudId`
FROM `loan`
LIMIT 10
17/10/26 11:35:30 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:35:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:35:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:35:30 INFO MemoryStore: MemoryStore cleared
17/10/26 11:35:30 INFO BlockManager: BlockManager stopped
17/10/26 11:35:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:35:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:35:30 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:35:30 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
17/10/26 11:35:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
17/10/26 11:35:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\repl-e5ba46c8-6c57-4796-833d-55a6329d7062
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\repl-b5bf31ce-4847-40e9-8a85-1bba88865fa2
17/10/26 11:35:48 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:35:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:35:48 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:35:48 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:35:48 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:35:48 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:35:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:35:48 INFO Utils: Successfully started service 'sparkDriver' on port 49242.
17/10/26 11:35:48 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:35:48 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:35:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:35:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:35:48 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-ea5b5713-d783-4f39-8f26-8f9e9931e145
17/10/26 11:35:48 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:35:48 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:35:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:35:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985349260
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar with timestamp 1508985349269
17/10/26 11:35:49 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:35:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49263.
17/10/26 11:35:49 INFO NettyBlockTransferService: Server created on 127.0.0.1:49263
17/10/26 11:35:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:35:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49263 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:35:49 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:35:49 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:35:50 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:35:50 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:35:50 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:35:50 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:35:52 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:35:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:35:54 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:35:54 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:35:54 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:35:54 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:35:54 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:35:54 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:35:54 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:35:54 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:35:54 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:35:54 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:55 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/bd805857-a126-4cf3-94a1-b53e4eb0d016_resources
17/10/26 11:35:55 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/bd805857-a126-4cf3-94a1-b53e4eb0d016
17/10/26 11:35:55 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/bd805857-a126-4cf3-94a1-b53e4eb0d016
17/10/26 11:35:55 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/bd805857-a126-4cf3-94a1-b53e4eb0d016/_tmp_space.db
17/10/26 11:35:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:35:55 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:55 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:35:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:35:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:35:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:36:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:36:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:36:47 INFO CodeGenerator: Code generated in 279.58701 ms
17/10/26 11:36:47 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:36:47 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:36:47 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:36:47 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:36:47 INFO DAGScheduler: Missing parents: List()
17/10/26 11:36:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 11:36:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:36:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:36:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:36:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:36:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 11:36:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:36:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 11:36:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985349264
17/10/26 11:36:48 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49242 after 18 ms (0 ms spent in bootstraps)
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7099022872101261667.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4457851290711550382.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985349267
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7515862775347599857.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5632011647670701909.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp743374830407151821.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.joda_joda-convert-1.7.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6784425471332003603.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8616551078329832098.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3863287528581176774.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9106857532424174059.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1307445188569078265.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2107255762906542912.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6274637415954319902.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4406831319122227075.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985349263
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp661950053945877469.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2096553949258846015.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985349268
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6897285019073145497.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3979239866090984231.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1321599625916174287.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3765435435511429518.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985349267
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8391801606041843348.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4931854523593092098.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985349261
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5179374036203545670.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985349263
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8125149525095666075.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7371063743848336896.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985349264
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5512116028498334268.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985349265
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3630785145735074832.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3610690887356858877.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985349267
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8462889245972438742.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985349264
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp408867795018716190.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985349268
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7128698782397883924.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5830406160074661861.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar with timestamp 1508985349263
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2219992831800262421.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-io_commons-io-2.4.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3649391203784980779.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985349267
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5976320340013746917.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985349263
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8846458398390179708.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5641350498847306355.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985349266
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp698508405393785301.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985349267
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7708425362127576715.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3038090721154960156.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1704537831351666054.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp282826203984250379.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985349267
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3906729287021557439.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985349265
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3909037709063139488.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar with timestamp 1508985349264
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6885180444758383485.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/log4j_log4j-1.2.15.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985349268
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2382092932818638506.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2266533419428265896.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985349266
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7378871615393046043.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar with timestamp 1508985349267
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2849212555980497024.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.tukaani_xz-1.5.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985349267
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1665514356797007770.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985349264
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5535078285700964506.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7063538184059139430.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985349265
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5460527104822557397.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985349264
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9028176571213731959.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985349268
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3303635742964503710.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985349267
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3916785233869192865.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3295705801780887345.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp886431032940629911.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985349266
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp855244860050280782.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7966509415253378523.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985349268
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp975262726344299547.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985349263
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3077059031547778890.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985349263
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2055683495743836947.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar with timestamp 1508985349269
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9164242362767592591.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5765335591335327926.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985349267
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7954983538827032523.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985349266
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7850567985955856972.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985349264
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7558686923174303078.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1255309679213821782.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985349264
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4000971753579703565.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985349260
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3558362053931360892.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 11:36:56 INFO CodeGenerator: Code generated in 14.509265 ms
17/10/26 11:36:56 INFO CodeGenerator: Code generated in 15.437103 ms
17/10/26 11:36:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/10/26 11:36:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8600 ms on localhost (executor driver) (1/1)
17/10/26 11:36:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:36:56 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 8.619 s
17/10/26 11:36:56 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 8.993098 s
17/10/26 11:37:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:37:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:37:17 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:17 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:37:17 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 6.614435 ms
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 11:37:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:37:17 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 13.544991 ms
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 10.325272 ms
17/10/26 11:37:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:17 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:17 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:37:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:37:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 11:37:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49263 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:37:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:37:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:37:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:37:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 22.147503 ms
17/10/26 11:37:18 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:37:21 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 11:37:21 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:49263 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:37:21 INFO CodeGenerator: Code generated in 6.474848 ms
17/10/26 11:37:21 INFO CodeGenerator: Code generated in 40.852563 ms
17/10/26 11:37:21 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 11:37:21 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3882 ms on localhost (executor driver) (1/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2893 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4151 ms on localhost (executor driver) (2/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:37:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4181 ms on localhost (executor driver) (3/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:37:22 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2983 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.271 s
17/10/26 11:37:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:22 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4266 ms on localhost (executor driver) (4/4)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO DAGScheduler: running: Set()
17/10/26 11:37:22 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:37:22 INFO DAGScheduler: failed: Set()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.045 s
17/10/26 11:37:22 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.383105 s
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 44 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO CodeGenerator: Code generated in 7.392936 ms
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:37:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:22 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 11:37:22 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:22 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:37:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:37:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:37:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49263 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:37:22 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:37:22 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:37:22 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:37:22 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2109 bytes result sent to driver
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 49 ms on localhost (executor driver) (1/4)
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 53 ms on localhost (executor driver) (2/4)
17/10/26 11:37:22 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/26 11:37:22 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2188 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 60 ms on localhost (executor driver) (3/4)
17/10/26 11:37:22 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.065 s
17/10/26 11:37:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:22 INFO DAGScheduler: running: Set()
17/10/26 11:37:22 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:37:22 INFO DAGScheduler: failed: Set()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:22 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 56 ms on localhost (executor driver) (4/4)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1952 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.007 s
17/10/26 11:37:22 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.091469 s
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz7`
WHERE (0 = 1)
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:22 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:37:22 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:37:22 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:37:22 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:22 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1156 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.012 s
17/10/26 11:37:22 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.016744 s
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:37:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:37:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:37:35 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:35 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:35 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:37:35 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.5 MB)
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 11:37:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 296.1 MB)
17/10/26 11:37:35 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:35 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:35 INFO DAGScheduler: Registering RDD 36 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:35 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:37:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:37:35 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.4 MB)
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.4 MB)
17/10/26 11:37:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49263 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:37:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:37:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:37:35 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:37:35 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:37:35 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:37:35 INFO CodeGenerator: Code generated in 29.552755 ms
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49263 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:37:37 INFO MemoryStore: Block rdd_33_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:37:37 INFO BlockManagerInfo: Added rdd_33_3 in memory on 127.0.0.1:49263 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:37:37 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 11:37:37 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1997 ms on localhost (executor driver) (1/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_2 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 283.9 MB)
17/10/26 11:37:38 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2665 ms on localhost (executor driver) (2/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_1 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_1 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:37:38 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2738 ms on localhost (executor driver) (3/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2983 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2784 ms on localhost (executor driver) (4/4)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.786 s
17/10/26 11:37:38 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:38 INFO DAGScheduler: running: Set()
17/10/26 11:37:38 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:37:38 INFO DAGScheduler: failed: Set()
17/10/26 11:37:38 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1952 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:37:38 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.808552 s
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:37:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:38 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:196)
17/10/26 11:37:38 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:38 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:37:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:37:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:37:38 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49263 (size: 9.4 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:37:38 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:37:38 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_2 locally
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_0 locally
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_3 locally
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2109 bytes result sent to driver
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_1 locally
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 35 ms on localhost (executor driver) (1/4)
17/10/26 11:37:38 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2188 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 38 ms on localhost (executor driver) (2/4)
17/10/26 11:37:38 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 44 ms on localhost (executor driver) (3/4)
17/10/26 11:37:38 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 48 ms on localhost (executor driver) (4/4)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.053 s
17/10/26 11:37:38 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:38 INFO DAGScheduler: running: Set()
17/10/26 11:37:38 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:37:38 INFO DAGScheduler: failed: Set()
17/10/26 11:37:38 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/10/26 11:37:38 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:37:38 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.079526 s
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz8`
WHERE (0 = 1)
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:38 INFO CodeGenerator: Code generated in 9.032047 ms
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:39 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:37:39 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:37:39 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:37:39 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:39 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:39 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 11:37:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:37:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:37:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:37:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 11:37:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:37:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 11:37:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:37:39 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 11:37:39 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.007 s
17/10/26 11:37:39 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.013646 s
17/10/26 11:37:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:37:39 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:37:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:37:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:37:41 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:41 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:41 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:37:41 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 269.6 MB)
17/10/26 11:37:41 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:41 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:37:41 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:41 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:41 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:37:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:37:41 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49263 (size: 19.5 KB, free: 269.6 MB)
17/10/26 11:37:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:37:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:37:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:37:41 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:37:41 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:37:41 INFO CodeGenerator: Code generated in 71.766797 ms
17/10/26 11:37:41 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:49263 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/26 11:37:41 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 270 ms on localhost (executor driver) (1/4)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49263 in memory (size: 9.4 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 267.1 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:49263 (size: 1374.8 KB, free: 268.1 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 265.7 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:49263 (size: 1444.5 KB, free: 266.7 MB)
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 616 ms on localhost (executor driver) (2/4)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 264.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:49263 (size: 1296.0 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 634 ms on localhost (executor driver) (3/4)
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2983 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 645 ms on localhost (executor driver) (4/4)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.645 s
17/10/26 11:37:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:42 INFO DAGScheduler: running: Set()
17/10/26 11:37:42 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:37:42 INFO DAGScheduler: failed: Set()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 11:37:42 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.672190 s
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:42 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 11:37:42 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:37:42 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49263 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:37:42 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:37:42 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:37:42 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 16 ms on localhost (executor driver) (1/4)
17/10/26 11:37:42 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 19 ms on localhost (executor driver) (2/4)
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 25 ms on localhost (executor driver) (3/4)
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2019 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 28 ms on localhost (executor driver) (4/4)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.029 s
17/10/26 11:37:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:42 INFO DAGScheduler: running: Set()
17/10/26 11:37:42 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:37:42 INFO DAGScheduler: failed: Set()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 11:37:42 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.046518 s
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz9`
WHERE (0 = 1)
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:37:42 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 11:37:42 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 11:37:42 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_1934800255
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 11:37:42 INFO DAGScheduler: Got job 9 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 15 (collect at SpreadRDDBuilder.scala:105)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.1 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1361.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49263 (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 11 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:37:42 INFO Executor: Running task 1.0 in stage 15.0 (TID 34)
17/10/26 11:37:42 INFO Executor: Running task 2.0 in stage 15.0 (TID 35)
17/10/26 11:37:42 INFO Executor: Running task 3.0 in stage 15.0 (TID 36)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 16.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:49263 (size: 16.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_2 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_2 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_3 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_3 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_73_3]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_73_2]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_73_0]
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 15.0 (TID 35). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1706 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_73_1]
17/10/26 11:37:42 INFO Executor: Finished task 3.0 in stage 15.0 (TID 36). 1714 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 15.0 (TID 34). 1706 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 37, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 35) in 26 ms on localhost (executor driver) (1/11)
17/10/26 11:37:42 INFO Executor: Running task 4.0 in stage 15.0 (TID 37)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 38, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 39, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 5.0 in stage 15.0 (TID 38)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 40, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 6.0 in stage 15.0 (TID 39)
17/10/26 11:37:42 INFO Executor: Running task 7.0 in stage 15.0 (TID 40)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 36) in 30 ms on localhost (executor driver) (2/11)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_4 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 34) in 34 ms on localhost (executor driver) (3/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 43 ms on localhost (executor driver) (4/11)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_4 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_5 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_6 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_5 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_6 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_73_4]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_73_5]
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_7 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_7 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO Executor: Finished task 5.0 in stage 15.0 (TID 38). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_73_6]
17/10/26 11:37:42 INFO Executor: Finished task 6.0 in stage 15.0 (TID 39). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 4.0 in stage 15.0 (TID 37). 1714 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 41, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 42, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 40:
[rdd_73_7]
17/10/26 11:37:42 INFO Executor: Finished task 7.0 in stage 15.0 (TID 40). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 43, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 38) in 15 ms on localhost (executor driver) (5/11)
17/10/26 11:37:42 INFO Executor: Running task 8.0 in stage 15.0 (TID 41)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 39) in 13 ms on localhost (executor driver) (6/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 37) in 17 ms on localhost (executor driver) (7/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 40) in 14 ms on localhost (executor driver) (8/11)
17/10/26 11:37:42 INFO Executor: Running task 9.0 in stage 15.0 (TID 42)
17/10/26 11:37:42 INFO Executor: Running task 10.0 in stage 15.0 (TID 43)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_10 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_8 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_9 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_10 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_8 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 43:
[rdd_73_10]
17/10/26 11:37:42 INFO Executor: Finished task 10.0 in stage 15.0 (TID 43). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 41:
[rdd_73_8]
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_9 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 43) in 15 ms on localhost (executor driver) (9/11)
17/10/26 11:37:42 INFO Executor: Finished task 8.0 in stage 15.0 (TID 41). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 42:
[rdd_73_9]
17/10/26 11:37:42 INFO Executor: Finished task 9.0 in stage 15.0 (TID 42). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 41) in 19 ms on localhost (executor driver) (10/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 42) in 19 ms on localhost (executor driver) (11/11)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 15 (collect at SpreadRDDBuilder.scala:105) finished in 0.066 s
17/10/26 11:37:42 INFO DAGScheduler: Job 9 finished: collect at SpreadRDDBuilder.scala:105, took 0.070397 s
17/10/26 11:37:42 INFO ParallelCollectionRDD: Removing RDD 73 from persistence list
17/10/26 11:37:42 INFO BlockManager: Removing RDD 73
17/10/26 11:37:42 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 11:37:42 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 11:37:42 INFO DAGScheduler: Got job 10 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 16 (collect at InternalBackendUtils.scala:163)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.0 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1949.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49263 (size: 1949.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 44, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 16.0 (TID 44)
17/10/26 11:37:43 INFO Reflections: Reflections took 316 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 11:37:43 INFO Reflections: Reflections took 136 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 11:37:44 INFO Server: jetty-8.1.17.v20150415
17/10/26 11:37:44 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/10/26 11:37:45 INFO Executor: Finished task 0.0 in stage 16.0 (TID 44). 1371 bytes result sent to driver
17/10/26 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 44) in 2368 ms on localhost (executor driver) (1/1)
17/10/26 11:37:45 INFO DAGScheduler: ResultStage 16 (collect at InternalBackendUtils.scala:163) finished in 2.372 s
17/10/26 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 11:37:45 INFO DAGScheduler: Job 10 finished: collect at InternalBackendUtils.scala:163, took 2.386869 s
17/10/26 11:37:45 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 11:37:45 INFO DAGScheduler: Got job 11 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 11:37:45 INFO DAGScheduler: Final stage: ResultStage 17 (foreach at InternalBackendUtils.scala:175)
17/10/26 11:37:45 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:45 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:45 INFO DAGScheduler: Submitting ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 11:37:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1672.0 B, free 264.3 MB)
17/10/26 11:37:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1161.0 B, free 264.3 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49263 (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 11:37:45 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 45, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:37:45 INFO Executor: Running task 0.0 in stage 17.0 (TID 45)
17/10/26 11:37:45 INFO Executor: Finished task 0.0 in stage 17.0 (TID 45). 764 bytes result sent to driver
17/10/26 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 45) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 11:37:45 INFO DAGScheduler: ResultStage 17 (foreach at InternalBackendUtils.scala:175) finished in 0.006 s
17/10/26 11:37:45 INFO DAGScheduler: Job 11 finished: foreach at InternalBackendUtils.scala:175, took 0.009284 s
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManager: Removing RDD 73
17/10/26 11:37:45 INFO ContextCleaner: Cleaned RDD 73
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:49263 in memory (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:49263 in memory (size: 1949.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:49263 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:49263 in memory (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:37:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 1536
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49263 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:49263 in memory (size: 9.4 KB, free: 265.5 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49263 in memory (size: 11.2 KB, free: 265.5 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 11:37:53 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_1934800255
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)
    
17/10/26 11:38:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:38:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:38:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:38:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:38:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:38:48 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:38:48 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/10/26 11:38:48 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:38:48 INFO DAGScheduler: Missing parents: List()
17/10/26 11:38:48 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/10/26 11:38:48 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 23.0 KB, free 264.6 MB)
17/10/26 11:38:48 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:38:48 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:49263 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:38:48 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 11:38:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/10/26 11:38:48 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/10/26 11:38:48 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:38:48 INFO Executor: Running task 0.0 in stage 18.0 (TID 46)
17/10/26 11:38:48 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:38:48 INFO CodeGenerator: Code generated in 24.343932 ms
17/10/26 11:38:48 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_10_0]
17/10/26 11:38:48 INFO Executor: Finished task 0.0 in stage 18.0 (TID 46). 2773 bytes result sent to driver
17/10/26 11:38:48 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.047 s
17/10/26 11:38:48 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 46) in 47 ms on localhost (executor driver) (1/1)
17/10/26 11:38:48 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.063806 s
17/10/26 11:38:48 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 11:38:48 INFO CodeGenerator: Code generated in 16.5502 ms
17/10/26 11:47:01 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:49263 in memory (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:49:15 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:49:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:49:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:49:15 INFO MemoryStore: MemoryStore cleared
17/10/26 11:49:15 INFO BlockManager: BlockManager stopped
17/10/26 11:49:15 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:49:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:49:15 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:49:15 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:49:15 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\repl-2379c083-58b0-42da-b3fa-b5cfbb633655
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
17/10/26 11:49:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\repl-93efbd9d-cdeb-44fc-9c63-d9dceff563f1
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
17/10/26 11:49:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:31:53 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:31:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:31:54 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:31:54 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:31:54 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:31:54 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:31:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:31:54 INFO Utils: Successfully started service 'sparkDriver' on port 51014.
17/10/26 12:31:54 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:31:54 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:31:54 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-fe7dce3f-ca96-4aaf-af65-1cff15df6ffa
17/10/26 12:31:54 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:31:54 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:31:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:31:54 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:31:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51035.
17/10/26 12:31:54 INFO NettyBlockTransferService: Server created on 127.0.0.1:51035
17/10/26 12:31:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:31:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51035 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:55 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:31:55 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:31:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:31:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:31:56 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:31:56 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:31:56 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:31:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:31:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:31:59 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:31:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:31:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:31:59 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:31:59 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:31:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:32:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:32:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/1f954c31-031c-4df1-b1ca-f1d4ddc996dc_resources
17/10/26 12:32:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1f954c31-031c-4df1-b1ca-f1d4ddc996dc
17/10/26 12:32:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/1f954c31-031c-4df1-b1ca-f1d4ddc996dc
17/10/26 12:32:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1f954c31-031c-4df1-b1ca-f1d4ddc996dc/_tmp_space.db
17/10/26 12:32:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:32:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:32:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:32:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:32:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 12:32:03 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:03 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 12:32:08 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:08 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:33:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:09 INFO CodeGenerator: Code generated in 261.525995 ms
17/10/26 12:33:09 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:09 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 12:33:09 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:09 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 12:33:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 12:33:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 366.3 MB)
17/10/26 12:33:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/26 12:33:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 12:33:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11567 bytes)
17/10/26 12:33:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 12:33:09 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:09 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51014 after 21 ms (0 ms spent in bootstraps)
17/10/26 12:33:09 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4538265892678357967.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1236513025519203811.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1377536444527190445.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8179681095297755683.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-io_commons-io-2.4.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp109868044853850270.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4376044935354290871.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp291389613042413397.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2881234852237317599.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp296472265752173695.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5278027317843363465.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3565714841969790146.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4035740928405504691.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7214555985962094543.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1385207066554943384.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9156682542284577715.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4548688767074081013.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7434995111638416445.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6338910772806519009.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2216319545242161809.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1833434471663862358.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4196724794493333014.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7237494339960419907.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8528740447917964528.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4620540613676473195.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/log4j_log4j-1.2.15.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3227663094409964617.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9201625664266906999.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5256630960774460734.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2102617087062889560.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5075814489828172971.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5999499322108443416.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1853662851787099237.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3358259015777395391.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4983555126268866886.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6074303159581067209.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7152040242858127353.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5049634319436791711.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2427702402906067174.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2937106626256919957.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6884348441972350913.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp757294185447395660.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3043354224595078081.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2859253994937853049.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9002984649002133946.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8915385531346784278.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar with timestamp 1508988714625
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7920565673104483939.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.joda_joda-convert-1.7.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7585864083323856940.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.tukaani_xz-1.5.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2280057554288917348.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8140688235026206902.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508988714625
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3442801396414298015.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6795398039267343543.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2484551595630329114.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7791571876825715756.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8644539675530123879.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4270781903518583397.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3775787846042486786.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7805517981652153091.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2374144562178352733.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5142273720018394959.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2534457644108962218.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6200938923437399476.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/sparklyr-2.1-2.11.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp978319024549181825.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2065538873526141800.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp81212568038217726.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3449236676076474705.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5628138313220619796.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3935675755332170313.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5321257166640436909.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6111133669641660252.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 12:33:17 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508988714641
17/10/26 12:33:17 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5434003446556536773.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 12:33:17 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508988714641
17/10/26 12:33:17 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4303909923351482728.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 12:33:17 INFO CodeGenerator: Code generated in 14.02174 ms
17/10/26 12:33:17 INFO CodeGenerator: Code generated in 13.213475 ms
17/10/26 12:33:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 12:33:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7827 ms on localhost (executor driver) (1/1)
17/10/26 12:33:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 12:33:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 7.847 s
17/10/26 12:33:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 8.049218 s
17/10/26 12:33:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: loan
17/10/26 12:33:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 12:33:19 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:19 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:19 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 12:33:19 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:19 INFO CodeGenerator: Code generated in 6.776088 ms
17/10/26 12:33:19 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 12:33:19 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 12:33:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 12:33:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 12:33:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 366.3 MB)
17/10/26 12:33:19 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 13.290964 ms
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 10.703488 ms
17/10/26 12:33:20 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:20 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:20 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 12:33:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 12:33:20 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 12:33:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 12:33:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51035 (size: 11.2 KB, free: 366.3 MB)
17/10/26 12:33:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 12:33:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 12:33:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 12:33:20 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 12:33:20 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 53.225442 ms
17/10/26 12:33:21 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:51035 (size: 15.4 MB, free: 350.9 MB)
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 5.743047 ms
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 25.002861 ms
17/10/26 12:33:24 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 4117 ms on localhost (executor driver) (1/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 332.6 MB)
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2893 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4359 ms on localhost (executor driver) (2/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 314.4 MB)
17/10/26 12:33:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2983 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4450 ms on localhost (executor driver) (3/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 296.2 MB)
17/10/26 12:33:24 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4514 ms on localhost (executor driver) (4/4)
17/10/26 12:33:24 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.520 s
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:24 INFO DAGScheduler: running: Set()
17/10/26 12:33:24 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 12:33:24 INFO DAGScheduler: failed: Set()
17/10/26 12:33:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.049 s
17/10/26 12:33:24 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.644159 s
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 47 ms on localhost (executor driver) (1/1)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 6.763772 ms
17/10/26 12:33:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 12:33:24 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:24 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/26 12:33:24 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:24 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 12:33:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 12:33:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 12:33:24 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51035 (size: 11.2 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 12:33:24 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 12:33:24 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 12:33:24 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_2 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_3 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_1 locally
17/10/26 12:33:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2019 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 42 ms on localhost (executor driver) (1/4)
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 54 ms on localhost (executor driver) (2/4)
17/10/26 12:33:24 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2098 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 52 ms on localhost (executor driver) (3/4)
17/10/26 12:33:24 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2109 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.066 s
17/10/26 12:33:24 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:24 INFO DAGScheduler: running: Set()
17/10/26 12:33:24 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 12:33:24 INFO DAGScheduler: failed: Set()
17/10/26 12:33:24 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:24 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 63 ms on localhost (executor driver) (4/4)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/26 12:33:24 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.094926 s
17/10/26 12:33:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz10`
WHERE (0 = 1)
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:25 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:25 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:25 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 12:33:25 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:25 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 12:33:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 12:33:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 296.2 MB)
17/10/26 12:33:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 12:33:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 12:33:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 12:33:25 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1159 bytes result sent to driver
17/10/26 12:33:25 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.014 s
17/10/26 12:33:25 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.018642 s
17/10/26 12:33:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: payment
17/10/26 12:33:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 12:33:26 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:26 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:26 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 12:33:26 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.5 MB)
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:26 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:26 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:26 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 12:33:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 12:33:26 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.4 MB)
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.4 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51035 (size: 9.4 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:26 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 12:33:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 12:33:26 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 12:33:26 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 12:33:26 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 12:33:26 INFO CodeGenerator: Code generated in 19.158716 ms
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51035 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:51035 (size: 5.1 MB, free: 291.0 MB)
17/10/26 12:33:28 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1957 ms on localhost (executor driver) (1/4)
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 283.9 MB)
17/10/26 12:33:28 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2454 ms on localhost (executor driver) (2/4)
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 276.1 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 276.8 MB)
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 269.7 MB)
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2534 ms on localhost (executor driver) (3/4)
17/10/26 12:33:28 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.548 s
17/10/26 12:33:28 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:28 INFO DAGScheduler: running: Set()
17/10/26 12:33:28 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 12:33:28 INFO DAGScheduler: failed: Set()
17/10/26 12:33:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2545 ms on localhost (executor driver) (4/4)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
17/10/26 12:33:28 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.573610 s
17/10/26 12:33:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:28 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 12:33:28 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:28 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 12:33:28 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:28 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 12:33:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 12:33:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 12:33:28 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51035 (size: 9.4 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 12:33:28 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 12:33:28 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 12:33:28 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 12:33:28 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2185 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 37 ms on localhost (executor driver) (1/4)
17/10/26 12:33:28 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 41 ms on localhost (executor driver) (2/4)
17/10/26 12:33:28 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2098 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 49 ms on localhost (executor driver) (3/4)
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2019 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 54 ms on localhost (executor driver) (4/4)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.054 s
17/10/26 12:33:28 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:28 INFO DAGScheduler: running: Set()
17/10/26 12:33:28 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 12:33:28 INFO DAGScheduler: failed: Set()
17/10/26 12:33:28 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 12:33:28 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.077404 s
17/10/26 12:33:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz11`
WHERE (0 = 1)
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 INFO CodeGenerator: Code generated in 7.535087 ms
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:29 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:29 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 12:33:29 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:29 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:29 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 12:33:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 12:33:29 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 12:33:29 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 12:33:29 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.009 s
17/10/26 12:33:29 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.015390 s
17/10/26 12:33:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51035 in memory (size: 9.4 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: cuv
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 12:33:29 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:29 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:29 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 12:33:29 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.8 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:29 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 12:33:29 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:29 INFO DAGScheduler: Registering RDD 62 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:29 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 12:33:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 12:33:29 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.7 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51035 (size: 19.5 KB, free: 269.6 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:29 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 12:33:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 12:33:29 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 12:33:29 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 12:33:29 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 12:33:29 INFO CodeGenerator: Code generated in 37.229994 ms
17/10/26 12:33:29 INFO MemoryStore: Block rdd_59_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added rdd_59_3 in memory on 127.0.0.1:51035 (size: 198.6 KB, free: 269.4 MB)
17/10/26 12:33:29 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/26 12:33:29 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 290 ms on localhost (executor driver) (1/4)
17/10/26 12:33:30 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_2 stored as values in memory (estimated size 1444.5 KB, free 267.0 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_2 in memory on 127.0.0.1:51035 (size: 1444.5 KB, free: 268.0 MB)
17/10/26 12:33:30 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 618 ms on localhost (executor driver) (2/4)
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_0 stored as values in memory (estimated size 1296.0 KB, free 265.8 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_0 in memory on 127.0.0.1:51035 (size: 1296.0 KB, free: 266.8 MB)
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_1 stored as values in memory (estimated size 1374.8 KB, free 264.4 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_1 in memory on 127.0.0.1:51035 (size: 1374.8 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 642 ms on localhost (executor driver) (3/4)
17/10/26 12:33:30 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 654 ms on localhost (executor driver) (4/4)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.656 s
17/10/26 12:33:30 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:30 INFO DAGScheduler: running: Set()
17/10/26 12:33:30 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 12:33:30 INFO DAGScheduler: failed: Set()
17/10/26 12:33:30 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 12:33:30 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.683479 s
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 12:33:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:30 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:196)
17/10/26 12:33:30 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:30 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 12:33:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 12:33:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 12:33:30 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51035 (size: 19.5 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 12:33:30 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 12:33:30 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 12:33:30 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_1 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_3 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_0 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_2 locally
17/10/26 12:33:30 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 27 ms on localhost (executor driver) (1/4)
17/10/26 12:33:30 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2188 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 31 ms on localhost (executor driver) (2/4)
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2019 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 37 ms on localhost (executor driver) (3/4)
17/10/26 12:33:30 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2019 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 41 ms on localhost (executor driver) (4/4)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.043 s
17/10/26 12:33:30 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:30 INFO DAGScheduler: running: Set()
17/10/26 12:33:30 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 12:33:30 INFO DAGScheduler: failed: Set()
17/10/26 12:33:30 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 12:33:30 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 12:33:30 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.060612 s
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz12`
WHERE (0 = 1)
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 10
17/10/26 12:33:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:38 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:38 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/10/26 12:33:38 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:38 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:38 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[75] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:38 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 67.5 KB, free 264.3 MB)
17/10/26 12:33:38 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.6 KB, free 264.2 MB)
17/10/26 12:33:38 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51035 (size: 17.6 KB, free: 265.4 MB)
17/10/26 12:33:38 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[75] at collect at utils.scala:196)
17/10/26 12:33:38 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 12:33:38 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 12:33:38 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 12:33:38 INFO BlockManager: Found block rdd_59_0 locally
17/10/26 12:33:38 INFO CodeGenerator: Code generated in 53.019654 ms
17/10/26 12:33:38 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_59_0]
17/10/26 12:33:38 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 2749 bytes result sent to driver
17/10/26 12:33:38 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 102 ms on localhost (executor driver) (1/1)
17/10/26 12:33:38 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 12:33:38 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0.102 s
17/10/26 12:33:38 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.100025 s
17/10/26 12:33:38 INFO CodeGenerator: Code generated in 28.926156 ms
17/10/26 12:34:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:34:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 10
17/10/26 12:34:23 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:34:23 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:34:23 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/10/26 12:34:23 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:34:23 INFO DAGScheduler: Missing parents: List()
17/10/26 12:34:23 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
17/10/26 12:34:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 16.8 KB, free 264.2 MB)
17/10/26 12:34:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.9 KB, free 264.2 MB)
17/10/26 12:34:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51035 (size: 7.9 KB, free: 265.4 MB)
17/10/26 12:34:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 12:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[77] at collect at utils.scala:196)
17/10/26 12:34:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 12:34:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 12:34:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
17/10/26 12:34:23 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 12:34:23 INFO CodeGenerator: Code generated in 16.106808 ms
17/10/26 12:34:23 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_34_0]
17/10/26 12:34:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 1735 bytes result sent to driver
17/10/26 12:34:23 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.035 s
17/10/26 12:34:23 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 0.033198 s
17/10/26 12:34:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 35 ms on localhost (executor driver) (1/1)
17/10/26 12:34:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 12:34:23 INFO CodeGenerator: Code generated in 9.763335 ms
17/10/26 12:38:17 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:38:17 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:38:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:38:17 INFO MemoryStore: MemoryStore cleared
17/10/26 12:38:17 INFO BlockManager: BlockManager stopped
17/10/26 12:38:17 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:38:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:38:17 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:17 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:38:17 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:38:17 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
17/10/26 12:38:17 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:17 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
17/10/26 12:38:17 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:27 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:38:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:38:27 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:38:27 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:38:27 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:38:27 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:38:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:38:27 INFO Utils: Successfully started service 'sparkDriver' on port 51384.
17/10/26 12:38:27 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:38:27 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:38:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:38:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:38:27 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-a449b908-f043-4f76-9b37-2e6f503f7178
17/10/26 12:38:27 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:38:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:38:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:38:28 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508989108243
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51384/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51384/jars/org.joda_joda-convert-1.7.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51384/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51384/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51384/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51384/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51384/jars/commons-io_commons-io-2.4.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51384/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51384/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51384/jars/log4j_log4j-1.2.15.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51384/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51384/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51384/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51384/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51384/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51384/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51384/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51384/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51384/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51384/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51384/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51384/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51384/jars/org.tukaani_xz-1.5.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51384/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51384/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51384/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51384/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51384/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51384/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51384/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51384/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51384/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51384/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51384/jars/sparklyr-2.1-2.11.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:38:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51405.
17/10/26 12:38:28 INFO NettyBlockTransferService: Server created on 127.0.0.1:51405
17/10/26 12:38:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:38:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51405 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:39:14 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:39:14 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:39:14 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:39:15 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:39:15 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:39:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:39:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:39:16 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:39:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:39:18 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:39:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:39:18 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:39:19 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:39:19 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:39:19 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:39:19 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:39:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:39:19 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:39:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:39:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:19 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1_resources
17/10/26 12:39:19 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1
17/10/26 12:39:19 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1
17/10/26 12:39:20 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1/_tmp_space.db
17/10/26 12:39:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:39:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:20 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:39:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:39:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:39:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:39:48 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:39:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:39:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:39:48 INFO MemoryStore: MemoryStore cleared
17/10/26 12:39:48 INFO BlockManager: BlockManager stopped
17/10/26 12:39:48 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:39:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:39:48 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:39:48 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:39:48 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-3228be77-c84f-4535-be99-c09f14cd68cf
17/10/26 12:40:11 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:40:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:40:12 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:40:12 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:40:12 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:40:12 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:40:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:40:12 INFO Utils: Successfully started service 'sparkDriver' on port 51460.
17/10/26 12:40:12 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:40:12 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:40:12 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-62df241c-eb50-458c-a9d8-060e4a9e88f9
17/10/26 12:40:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:40:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:40:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:40:12 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508989212803
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51460/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51460/jars/org.joda_joda-convert-1.7.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51460/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51460/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51460/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51460/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51460/jars/commons-io_commons-io-2.4.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51460/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51460/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51460/jars/log4j_log4j-1.2.15.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51460/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51460/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51460/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51460/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51460/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51460/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51460/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51460/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51460/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51460/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51460/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51460/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51460/jars/org.tukaani_xz-1.5.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51460/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51460/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51460/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51460/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51460/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51460/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51460/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51460/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51460/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51460/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51460/jars/sparklyr-2.1-2.11.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:40:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51481.
17/10/26 12:40:12 INFO NettyBlockTransferService: Server created on 127.0.0.1:51481
17/10/26 12:40:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:40:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51481 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:13 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:40:13 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:40:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:40:14 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:40:14 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:40:14 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:40:14 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:40:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:40:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:40:17 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:40:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:40:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:40:18 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:40:18 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:40:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:40:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:18 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/7f784349-c07c-427b-8f4c-478ae4608fda_resources
17/10/26 12:40:18 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7f784349-c07c-427b-8f4c-478ae4608fda
17/10/26 12:40:18 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/7f784349-c07c-427b-8f4c-478ae4608fda
17/10/26 12:40:18 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7f784349-c07c-427b-8f4c-478ae4608fda/_tmp_space.db
17/10/26 12:40:18 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:40:18 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:40:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:59:08 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:59:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:59:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:59:08 INFO MemoryStore: MemoryStore cleared
17/10/26 12:59:08 INFO BlockManager: BlockManager stopped
17/10/26 12:59:08 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:59:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:59:08 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:59:08 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:59:08 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-7c33f421-546c-4166-be54-22d9ba35f7b3
17/10/26 13:20:58 INFO SparkContext: Running Spark version 2.1.0
17/10/26 13:20:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 13:20:59 INFO SecurityManager: Changing view acls to: scibr
17/10/26 13:20:59 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 13:20:59 INFO SecurityManager: Changing view acls groups to: 
17/10/26 13:20:59 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 13:20:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 13:20:59 INFO Utils: Successfully started service 'sparkDriver' on port 52852.
17/10/26 13:20:59 INFO SparkEnv: Registering MapOutputTracker
17/10/26 13:20:59 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 13:20:59 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 13:20:59 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 13:20:59 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-628b0374-b304-4405-b418-721f24db0ba9
17/10/26 13:20:59 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 13:20:59 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 13:20:59 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 13:20:59 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:52852/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508991659802
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:52852/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:52852/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:52852/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:52852/jars/org.joda_joda-convert-1.7.jar with timestamp 1508991659803
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:52852/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:52852/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:52852/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508991659804
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:52852/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:52852/jars/commons-io_commons-io-2.4.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:52852/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:52852/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:52852/jars/log4j_log4j-1.2.15.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:52852/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508991659805
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:52852/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:52852/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:52852/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:52852/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:52852/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508991659806
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:52852/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508991659807
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:52852/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:52852/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:52852/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:52852/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:52852/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:52852/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:52852/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:52852/jars/org.tukaani_xz-1.5.jar with timestamp 1508991659808
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:52852/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:52852/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:52852/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:52852/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:52852/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:52852/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:52852/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:52852/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:52852/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:52852/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:52852/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508991659809
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:52852/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:52852/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:52852/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:52852/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:52852/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:52852/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:52852/jars/sparklyr-2.1-2.11.jar with timestamp 1508991659810
17/10/26 13:20:59 INFO Executor: Starting executor ID driver on host localhost
17/10/26 13:20:59 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 52873.
17/10/26 13:20:59 INFO NettyBlockTransferService: Server created on 127.0.0.1:52873
17/10/26 13:20:59 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 13:20:59 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 52873, None)
17/10/26 13:20:59 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:52873 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 52873, None)
17/10/26 13:20:59 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 52873, None)
17/10/26 13:20:59 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 52873, None)
17/10/26 13:21:00 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 13:21:00 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 13:21:00 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 13:21:01 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 13:21:01 INFO ObjectStore: ObjectStore, initialize called
17/10/26 13:21:01 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 13:21:01 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 13:21:02 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 13:21:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:21:03 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:21:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:21:04 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:21:04 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 13:21:04 INFO ObjectStore: Initialized ObjectStore
17/10/26 13:21:04 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 13:21:04 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 13:21:05 INFO HiveMetaStore: Added admin role in metastore
17/10/26 13:21:05 INFO HiveMetaStore: Added public role in metastore
17/10/26 13:21:05 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 13:21:05 INFO HiveMetaStore: 0: get_all_databases
17/10/26 13:21:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 13:21:05 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 13:21:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 13:21:05 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:21:05 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/1b1518c3-87c5-4748-8818-2600772bfde1_resources
17/10/26 13:21:05 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1b1518c3-87c5-4748-8818-2600772bfde1
17/10/26 13:21:05 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/1b1518c3-87c5-4748-8818-2600772bfde1
17/10/26 13:21:05 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1b1518c3-87c5-4748-8818-2600772bfde1/_tmp_space.db
17/10/26 13:21:05 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 13:21:05 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:21:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:21:05 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 13:21:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 13:21:05 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 13:21:05 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:21:07 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:21:07 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:21:07 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:21:07 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:21:07 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:21:07 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:41:34 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 13:41:34 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 13:41:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 13:41:34 INFO MemoryStore: MemoryStore cleared
17/10/26 13:41:34 INFO BlockManager: BlockManager stopped
17/10/26 13:41:34 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 13:41:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 13:41:34 INFO SparkContext: Successfully stopped SparkContext
17/10/26 13:41:34 INFO ShutdownHookManager: Shutdown hook called
17/10/26 13:41:34 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-60c5f9a4-c05a-45a5-8203-d008ed167f6b
17/10/26 13:44:09 INFO SparkContext: Running Spark version 2.1.0
17/10/26 13:44:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 13:44:09 INFO SecurityManager: Changing view acls to: scibr
17/10/26 13:44:09 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 13:44:09 INFO SecurityManager: Changing view acls groups to: 
17/10/26 13:44:09 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 13:44:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 13:44:09 INFO Utils: Successfully started service 'sparkDriver' on port 53632.
17/10/26 13:44:09 INFO SparkEnv: Registering MapOutputTracker
17/10/26 13:44:09 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 13:44:09 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 13:44:09 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 13:44:09 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-0586139e-3212-4c2b-b156-0f5b0581f366
17/10/26 13:44:09 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 13:44:09 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 13:44:10 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 13:44:10 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:53632/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508993050178
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:53632/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508993050179
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:53632/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508993050179
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:53632/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508993050179
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508993050179
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:53632/jars/org.joda_joda-convert-1.7.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508993050180
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:53632/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:53632/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:53632/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:53632/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:53632/jars/commons-io_commons-io-2.4.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:53632/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508993050181
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:53632/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:53632/jars/log4j_log4j-1.2.15.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:53632/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:53632/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:53632/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:53632/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:53632/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:53632/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508993050182
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:53632/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508993050183
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:53632/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:53632/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:53632/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:53632/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:53632/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:53632/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:53632/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508993050184
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:53632/jars/org.tukaani_xz-1.5.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:53632/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:53632/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:53632/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:53632/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:53632/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:53632/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:53632/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:53632/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:53632/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508993050185
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:53632/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:53632/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:53632/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:53632/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:53632/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:53632/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:53632/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:53632/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:53632/jars/sparklyr-2.1-2.11.jar with timestamp 1508993050186
17/10/26 13:44:10 INFO Executor: Starting executor ID driver on host localhost
17/10/26 13:44:10 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53653.
17/10/26 13:44:10 INFO NettyBlockTransferService: Server created on 127.0.0.1:53653
17/10/26 13:44:10 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 13:44:10 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53653, None)
17/10/26 13:44:10 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53653 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53653, None)
17/10/26 13:44:10 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53653, None)
17/10/26 13:44:10 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53653, None)
17/10/26 13:44:57 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 13:44:57 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 13:44:57 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 13:44:58 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 13:44:58 INFO ObjectStore: ObjectStore, initialize called
17/10/26 13:44:58 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 13:44:58 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 13:44:59 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 13:45:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:45:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:45:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:45:01 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:45:01 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 13:45:01 INFO ObjectStore: Initialized ObjectStore
17/10/26 13:45:01 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 13:45:01 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 13:45:02 INFO HiveMetaStore: Added admin role in metastore
17/10/26 13:45:02 INFO HiveMetaStore: Added public role in metastore
17/10/26 13:45:02 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 13:45:02 INFO HiveMetaStore: 0: get_all_databases
17/10/26 13:45:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 13:45:02 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 13:45:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 13:45:02 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:45:02 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/d906ea0a-b644-4be6-8329-3c247d502b28_resources
17/10/26 13:45:02 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/d906ea0a-b644-4be6-8329-3c247d502b28
17/10/26 13:45:02 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/d906ea0a-b644-4be6-8329-3c247d502b28
17/10/26 13:45:02 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/d906ea0a-b644-4be6-8329-3c247d502b28/_tmp_space.db
17/10/26 13:45:02 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 13:45:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:45:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:45:02 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 13:45:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 13:45:02 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 13:45:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:45:05 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:45:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:45:05 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:45:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:45:05 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:45:05 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:48:23 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 13:48:23 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 13:48:23 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 13:48:23 INFO MemoryStore: MemoryStore cleared
17/10/26 13:48:23 INFO BlockManager: BlockManager stopped
17/10/26 13:48:23 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 13:48:23 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 13:48:23 INFO SparkContext: Successfully stopped SparkContext
17/10/26 13:48:23 INFO ShutdownHookManager: Shutdown hook called
17/10/26 13:48:23 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-b176ebf8-6c98-4b2c-9099-e0f3c3b383d7
17/10/26 13:48:36 INFO SparkContext: Running Spark version 2.1.0
17/10/26 13:48:36 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 13:48:36 INFO SecurityManager: Changing view acls to: scibr
17/10/26 13:48:36 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 13:48:36 INFO SecurityManager: Changing view acls groups to: 
17/10/26 13:48:36 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 13:48:36 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 13:48:36 INFO Utils: Successfully started service 'sparkDriver' on port 53860.
17/10/26 13:48:36 INFO SparkEnv: Registering MapOutputTracker
17/10/26 13:48:36 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 13:48:36 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 13:48:36 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 13:48:36 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-bb8d8132-58fd-492d-af83-72fe37f79430
17/10/26 13:48:36 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 13:48:36 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 13:48:37 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 13:48:37 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508993317242
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:53860/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:53860/jars/org.joda_joda-convert-1.7.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:53860/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508993317244
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:53860/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:53860/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:53860/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:53860/jars/commons-io_commons-io-2.4.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:53860/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:53860/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508993317245
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:53860/jars/log4j_log4j-1.2.15.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:53860/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:53860/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:53860/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:53860/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:53860/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:53860/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508993317246
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:53860/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508993317247
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:53860/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:53860/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:53860/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:53860/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:53860/jars/org.tukaani_xz-1.5.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:53860/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:53860/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:53860/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508993317248
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:53860/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:53860/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:53860/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508993317249
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:53860/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508993317250
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:53860/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508993317250
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508993317250
17/10/26 13:48:37 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:53860/jars/sparklyr-2.1-2.11.jar with timestamp 1508993317250
17/10/26 13:48:37 INFO Executor: Starting executor ID driver on host localhost
17/10/26 13:48:37 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53881.
17/10/26 13:48:37 INFO NettyBlockTransferService: Server created on 127.0.0.1:53881
17/10/26 13:48:37 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 13:48:37 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 53881, None)
17/10/26 13:48:37 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:53881 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 53881, None)
17/10/26 13:48:37 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 53881, None)
17/10/26 13:48:37 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 53881, None)
17/10/26 13:48:37 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 13:48:38 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 13:48:38 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 13:48:38 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 13:48:38 INFO ObjectStore: ObjectStore, initialize called
17/10/26 13:48:38 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 13:48:38 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 13:48:40 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 13:48:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:48:41 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:48:42 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:48:42 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:48:42 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 13:48:42 INFO ObjectStore: Initialized ObjectStore
17/10/26 13:48:42 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 13:48:42 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 13:48:42 INFO HiveMetaStore: Added admin role in metastore
17/10/26 13:48:42 INFO HiveMetaStore: Added public role in metastore
17/10/26 13:48:42 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 13:48:43 INFO HiveMetaStore: 0: get_all_databases
17/10/26 13:48:43 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 13:48:43 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 13:48:43 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 13:48:43 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 13:48:43 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/4af89dad-c665-4a79-919c-e2daaaa84168_resources
17/10/26 13:48:43 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/4af89dad-c665-4a79-919c-e2daaaa84168
17/10/26 13:48:43 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/4af89dad-c665-4a79-919c-e2daaaa84168
17/10/26 13:48:43 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/4af89dad-c665-4a79-919c-e2daaaa84168/_tmp_space.db
17/10/26 13:48:43 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 13:48:43 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:48:43 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:48:43 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 13:48:43 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 13:48:43 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 13:48:43 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:48:45 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:48:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:48:45 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:48:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:48:45 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:48:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:49:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:49:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:49:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:49:43 INFO CodeGenerator: Code generated in 258.814842 ms
17/10/26 13:49:43 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 13:49:43 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 13:49:43 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 13:49:43 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:49:43 INFO DAGScheduler: Missing parents: List()
17/10/26 13:49:43 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 13:49:43 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 13:49:43 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 13:49:43 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:53881 (size: 4.6 KB, free: 366.3 MB)
17/10/26 13:49:43 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:43 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 13:49:43 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 13:49:43 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 13:49:43 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 13:49:43 INFO Executor: Fetching spark://127.0.0.1:53860/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508993317244
17/10/26 13:49:43 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:53860 after 16 ms (0 ms spent in bootstraps)
17/10/26 13:49:43 INFO Utils: Fetching spark://127.0.0.1:53860/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8054362122247868787.tmp
17/10/26 13:49:43 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 13:49:43 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508993317248
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp7120818073392978169.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508993317247
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1245049580992552982.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508993317249
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5693339111865510712.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1490226424669364809.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508993317246
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3881895750089784783.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508993317246
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5938917292691025656.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508993317248
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5295618055308179730.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508993317249
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1901780702171583216.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/commons-io_commons-io-2.4.jar with timestamp 1508993317245
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8627145778015043804.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/commons-io_commons-io-2.4.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508993317245
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3768705853821702314.tmp
17/10/26 13:49:44 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 13:49:44 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508993317248
17/10/26 13:49:44 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp311025198866909099.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508993317247
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8292823595394218655.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508993317250
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6627489932660684091.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508993317246
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1611760395876917583.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508993317245
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2287829029870836331.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3039427411551189119.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2962143813133121925.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508993317249
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8181244714165862472.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp7194776171551228716.tmp
17/10/26 13:49:45 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 13:49:45 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508993317249
17/10/26 13:49:45 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp305936105475296185.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508993317245
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8301388452705095642.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508993317247
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3688668068900218472.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508993317245
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp9200763455600278980.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508993317243
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp4423159157321502477.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5674807587141498198.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508993317248
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1379075441547654641.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8259528872642973188.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508993317246
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp304222252820973817.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508993317246
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2751228668370935337.tmp
17/10/26 13:49:46 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 13:49:46 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:49:46 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp4025945896059341524.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp454155973938375292.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508993317243
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp9095083792763862811.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508993317248
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6260161393285820524.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508993317243
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp7431493653666450787.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508993317249
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5528316974777142709.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5336085313468065099.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508993317249
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1568353132634739564.tmp
17/10/26 13:49:47 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 13:49:47 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508993317246
17/10/26 13:49:47 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3628842263025422489.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2421000798768204735.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508993317248
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8018149278769916765.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508993317249
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5395052409439183656.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3606852896437375774.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508993317242
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8039391558985224621.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508993317246
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2459449395192720925.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508993317246
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2311187661870604715.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508993317243
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6281196332907656206.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508993317246
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3633316279419747143.tmp
17/10/26 13:49:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 13:49:48 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:49:48 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1230673795890722606.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5938139854762028900.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508993317247
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6536170021395071913.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508993317249
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8525413091286206092.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993317245
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp915002595989084646.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508993317245
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5853199712593556833.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/log4j_log4j-1.2.15.jar with timestamp 1508993317246
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp9122925800984550465.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/log4j_log4j-1.2.15.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp9150328316435260060.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp1739825587975883120.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508993317249
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3778903836674122888.tmp
17/10/26 13:49:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 13:49:49 INFO Executor: Fetching spark://127.0.0.1:53860/jars/sparklyr-2.1-2.11.jar with timestamp 1508993317250
17/10/26 13:49:49 INFO Utils: Fetching spark://127.0.0.1:53860/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5596422472516794844.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/sparklyr-2.1-2.11.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508993317248
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6820289810885860307.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508993317248
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2093285634884591452.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508993317249
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2600527685279550507.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508993317244
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp7006577677861901912.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508993317250
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp8469672850054274165.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508993317249
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp9099442046485090492.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508993317248
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp7507459038278145611.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508993317250
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp6672529453602865835.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.joda_joda-convert-1.7.jar with timestamp 1508993317244
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp2657308523319519245.tmp
17/10/26 13:49:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.joda_joda-convert-1.7.jar to class loader
17/10/26 13:49:50 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508993317247
17/10/26 13:49:50 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp5231199321040350987.tmp
17/10/26 13:49:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 13:49:51 INFO Executor: Fetching spark://127.0.0.1:53860/jars/org.tukaani_xz-1.5.jar with timestamp 1508993317248
17/10/26 13:49:51 INFO Utils: Fetching spark://127.0.0.1:53860/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548\userFiles-873b5b85-424d-4314-a5ce-daad6249b19e\fetchFileTemp3656146071254390099.tmp
17/10/26 13:49:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-b9a9a0ad-8ac3-45bd-91ef-fc49187f3548/userFiles-873b5b85-424d-4314-a5ce-daad6249b19e/org.tukaani_xz-1.5.jar to class loader
17/10/26 13:49:51 INFO CodeGenerator: Code generated in 17.576568 ms
17/10/26 13:49:51 INFO CodeGenerator: Code generated in 13.275569 ms
17/10/26 13:49:51 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1231 bytes result sent to driver
17/10/26 13:49:51 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7605 ms on localhost (executor driver) (1/1)
17/10/26 13:49:51 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 13:49:51 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 7.648 s
17/10/26 13:49:51 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 7.887657 s
17/10/26 13:49:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:53 INFO SparkSqlParser: Parsing command: loan
17/10/26 13:49:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:53 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 13:49:53 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 13:49:53 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 13:49:53 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 13:49:53 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 13:49:53 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 13:49:53 INFO CodeGenerator: Code generated in 6.143332 ms
17/10/26 13:49:53 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 13:49:53 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 13:49:53 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:53881 (size: 25.7 KB, free: 366.3 MB)
17/10/26 13:49:53 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 13:49:53 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 13:49:53 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 13:49:53 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 13:49:53 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:53881 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 13:49:54 INFO CodeGenerator: Code generated in 14.296293 ms
17/10/26 13:49:54 INFO CodeGenerator: Code generated in 10.797401 ms
17/10/26 13:49:54 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 13:49:54 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:54 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 13:49:54 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:54 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 13:49:54 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 13:49:54 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:49:54 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 13:49:54 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 13:49:54 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:53881 (size: 11.2 KB, free: 366.3 MB)
17/10/26 13:49:54 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:54 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:54 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 13:49:54 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:54 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:54 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:54 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:54 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 13:49:54 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 13:49:54 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 13:49:54 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 13:49:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 13:49:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 13:49:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 13:49:54 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 13:49:54 INFO CodeGenerator: Code generated in 64.807502 ms
17/10/26 13:49:55 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 13:49:57 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 13:49:57 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:53881 (size: 15.4 MB, free: 350.9 MB)
17/10/26 13:49:57 INFO CodeGenerator: Code generated in 9.038205 ms
17/10/26 13:49:57 INFO CodeGenerator: Code generated in 27.293716 ms
17/10/26 13:49:58 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3968 ms on localhost (executor driver) (1/4)
17/10/26 13:49:58 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:53881 (size: 18.2 MB, free: 332.6 MB)
17/10/26 13:49:58 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4315 ms on localhost (executor driver) (2/4)
17/10/26 13:49:58 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:53881 (size: 18.2 MB, free: 314.4 MB)
17/10/26 13:49:58 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:53881 (size: 18.2 MB, free: 296.2 MB)
17/10/26 13:49:58 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4384 ms on localhost (executor driver) (3/4)
17/10/26 13:49:58 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2983 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4389 ms on localhost (executor driver) (4/4)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 13:49:58 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.395 s
17/10/26 13:49:58 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:49:58 INFO DAGScheduler: running: Set()
17/10/26 13:49:58 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 13:49:58 INFO DAGScheduler: failed: Set()
17/10/26 13:49:58 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 296.2 MB)
17/10/26 13:49:58 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 13:49:58 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 13:49:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:49:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 6 ms
17/10/26 13:49:58 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 42 ms on localhost (executor driver) (1/1)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 13:49:58 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.043 s
17/10/26 13:49:58 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.508328 s
17/10/26 13:49:58 INFO CodeGenerator: Code generated in 7.07784 ms
17/10/26 13:49:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:58 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 13:49:58 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 13:49:58 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 13:49:58 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 13:49:58 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 13:49:58 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 13:49:58 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 13:49:58 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:53881 (size: 11.2 KB, free: 296.2 MB)
17/10/26 13:49:58 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:58 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 13:49:58 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 13:49:58 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 13:49:58 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 13:49:58 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 13:49:58 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 13:49:58 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 13:49:58 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 13:49:58 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 13:49:58 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 13:49:58 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 13:49:58 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 13:49:58 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 43 ms on localhost (executor driver) (1/4)
17/10/26 13:49:58 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2188 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 44 ms on localhost (executor driver) (2/4)
17/10/26 13:49:58 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/26 13:49:58 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 53 ms on localhost (executor driver) (3/4)
17/10/26 13:49:58 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2188 bytes result sent to driver
17/10/26 13:49:58 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.070 s
17/10/26 13:49:58 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:49:58 INFO DAGScheduler: running: Set()
17/10/26 13:49:58 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 13:49:58 INFO DAGScheduler: failed: Set()
17/10/26 13:49:58 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 13:49:58 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 65 ms on localhost (executor driver) (4/4)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 13:49:58 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 13:49:58 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 296.2 MB)
17/10/26 13:49:58 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:58 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 13:49:58 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 13:49:58 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 13:49:58 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:49:58 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 13:49:58 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 13:49:58 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/26 13:49:58 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.098763 s
17/10/26 13:49:58 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
17/10/26 13:49:58 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 13:49:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:58 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz13`
WHERE (0 = 1)
17/10/26 13:49:58 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:58 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:49:58 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:58 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:58 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:49:58 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:49:58 INFO CodeGenerator: Code generated in 9.708937 ms
17/10/26 13:49:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:59 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:49:59 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:59 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:49:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:49:59 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:49:59 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:49:59 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 13:49:59 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 13:49:59 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 13:49:59 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:49:59 INFO DAGScheduler: Missing parents: List()
17/10/26 13:49:59 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 13:49:59 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:53881 (size: 4.6 KB, free: 296.2 MB)
17/10/26 13:49:59 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 13:49:59 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 13:49:59 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 13:49:59 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 13:49:59 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 13:49:59 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.016 s
17/10/26 13:49:59 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.020538 s
17/10/26 13:49:59 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 14 ms on localhost (executor driver) (1/1)
17/10/26 13:49:59 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 13:49:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:59 INFO SparkSqlParser: Parsing command: payment
17/10/26 13:49:59 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:49:59 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 13:49:59 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 13:49:59 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 13:49:59 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 13:49:59 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 13:49:59 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.5 MB)
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 13:49:59 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:53881 (size: 25.7 KB, free: 296.1 MB)
17/10/26 13:49:59 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 13:49:59 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 13:49:59 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 13:49:59 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:59 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 13:49:59 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:59 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 13:49:59 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 13:49:59 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.4 MB)
17/10/26 13:49:59 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.4 MB)
17/10/26 13:49:59 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:53881 (size: 9.4 KB, free: 296.1 MB)
17/10/26 13:49:59 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 13:49:59 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:49:59 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 13:49:59 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:59 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:59 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:59 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 13:49:59 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 13:49:59 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 13:49:59 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 13:49:59 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 13:49:59 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 13:49:59 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 13:49:59 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 13:49:59 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 13:49:59 INFO CodeGenerator: Code generated in 17.101873 ms
17/10/26 13:50:00 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 13:50:00 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:53881 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 13:50:00 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 13:50:00 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 13:50:00 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 13:50:00 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:53881 in memory (size: 4.6 KB, free: 296.1 MB)
17/10/26 13:50:00 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 13:50:00 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 13:50:01 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 13:50:01 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:53881 (size: 5.1 MB, free: 291.0 MB)
17/10/26 13:50:01 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 13:50:01 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1901 ms on localhost (executor driver) (1/4)
17/10/26 13:50:02 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 283.3 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:53881 (size: 7.1 MB, free: 283.9 MB)
17/10/26 13:50:02 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2983 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2378 ms on localhost (executor driver) (2/4)
17/10/26 13:50:02 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:53881 (size: 7.1 MB, free: 276.8 MB)
17/10/26 13:50:02 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:53881 (size: 7.1 MB, free: 269.7 MB)
17/10/26 13:50:02 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2404 ms on localhost (executor driver) (3/4)
17/10/26 13:50:02 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2983 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2407 ms on localhost (executor driver) (4/4)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 13:50:02 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.410 s
17/10/26 13:50:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:02 INFO DAGScheduler: running: Set()
17/10/26 13:50:02 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 13:50:02 INFO DAGScheduler: failed: Set()
17/10/26 13:50:02 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 269.7 MB)
17/10/26 13:50:02 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 13:50:02 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 13:50:02 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 13:50:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:02 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1960 bytes result sent to driver
17/10/26 13:50:02 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/26 13:50:02 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.430323 s
17/10/26 13:50:02 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 7 ms on localhost (executor driver) (1/1)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 13:50:02 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 13:50:02 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 13:50:02 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 13:50:02 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 13:50:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 13:50:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 13:50:02 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:53881 (size: 9.4 KB, free: 269.7 MB)
17/10/26 13:50:02 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 13:50:02 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:02 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:02 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:02 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:02 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 13:50:02 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 13:50:02 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 13:50:02 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 13:50:02 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 13:50:02 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 13:50:02 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 13:50:02 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 13:50:02 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2185 bytes result sent to driver
17/10/26 13:50:02 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2109 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 33 ms on localhost (executor driver) (1/4)
17/10/26 13:50:02 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 39 ms on localhost (executor driver) (2/4)
17/10/26 13:50:02 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 43 ms on localhost (executor driver) (3/4)
17/10/26 13:50:02 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2109 bytes result sent to driver
17/10/26 13:50:02 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.049 s
17/10/26 13:50:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:02 INFO DAGScheduler: running: Set()
17/10/26 13:50:02 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 13:50:02 INFO DAGScheduler: failed: Set()
17/10/26 13:50:02 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 48 ms on localhost (executor driver) (4/4)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 13:50:02 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 269.7 MB)
17/10/26 13:50:02 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 13:50:02 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 13:50:02 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 13:50:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:02 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 13:50:02 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 13:50:02 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.006 s
17/10/26 13:50:02 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.071198 s
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz14`
WHERE (0 = 1)
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:50:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:50:02 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 13:50:02 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 13:50:02 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 13:50:02 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:50:02 INFO DAGScheduler: Missing parents: List()
17/10/26 13:50:02 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 13:50:02 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:53881 (size: 4.6 KB, free: 269.7 MB)
17/10/26 13:50:02 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 13:50:02 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 13:50:02 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 13:50:02 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 13:50:02 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.007 s
17/10/26 13:50:02 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.013359 s
17/10/26 13:50:02 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
17/10/26 13:50:02 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: cuv
17/10/26 13:50:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 13:50:02 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 13:50:02 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 13:50:02 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 13:50:02 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 13:50:02 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 13:50:02 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 13:50:03 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 13:50:03 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:53881 in memory (size: 9.4 KB, free: 269.7 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 13:50:03 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 13:50:03 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 13:50:03 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:53881 in memory (size: 4.6 KB, free: 269.7 MB)
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:53881 (size: 25.7 KB, free: 269.7 MB)
17/10/26 13:50:03 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 13:50:03 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 13:50:03 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 13:50:03 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 13:50:03 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:50:03 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 13:50:03 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:50:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 13:50:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 13:50:03 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.7 MB)
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:53881 (size: 19.5 KB, free: 269.6 MB)
17/10/26 13:50:03 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 13:50:03 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 13:50:03 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 13:50:03 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 13:50:03 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 13:50:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 13:50:03 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 13:50:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 13:50:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 13:50:03 INFO CodeGenerator: Code generated in 42.238675 ms
17/10/26 13:50:03 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 13:50:03 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:53881 (size: 198.6 KB, free: 269.4 MB)
17/10/26 13:50:03 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 184 ms on localhost (executor driver) (1/4)
17/10/26 13:50:03 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 13:50:03 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 267.2 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:53881 (size: 1296.0 KB, free: 268.2 MB)
17/10/26 13:50:03 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2983 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 563 ms on localhost (executor driver) (2/4)
17/10/26 13:50:03 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 265.8 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:53881 (size: 1444.5 KB, free: 266.8 MB)
17/10/26 13:50:03 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2983 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 595 ms on localhost (executor driver) (3/4)
17/10/26 13:50:03 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 264.4 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:53881 (size: 1374.8 KB, free: 265.4 MB)
17/10/26 13:50:03 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 646 ms on localhost (executor driver) (4/4)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 13:50:03 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.648 s
17/10/26 13:50:03 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:03 INFO DAGScheduler: running: Set()
17/10/26 13:50:03 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 13:50:03 INFO DAGScheduler: failed: Set()
17/10/26 13:50:03 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 265.4 MB)
17/10/26 13:50:03 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 13:50:03 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 13:50:03 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 13:50:03 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:03 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 13:50:03 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 13:50:03 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.663942 s
17/10/26 13:50:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:03 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 13:50:03 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 13:50:03 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 13:50:03 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 13:50:03 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 13:50:03 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 13:50:03 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 13:50:03 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:53881 (size: 19.5 KB, free: 265.4 MB)
17/10/26 13:50:03 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:03 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 13:50:03 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:03 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 13:50:03 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 13:50:03 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 13:50:03 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 13:50:03 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 13:50:03 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 13:50:03 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 13:50:03 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 13:50:03 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 13:50:03 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2098 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 25 ms on localhost (executor driver) (1/4)
17/10/26 13:50:03 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2019 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 27 ms on localhost (executor driver) (2/4)
17/10/26 13:50:03 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2109 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 30 ms on localhost (executor driver) (3/4)
17/10/26 13:50:03 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2019 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 37 ms on localhost (executor driver) (4/4)
17/10/26 13:50:03 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.037 s
17/10/26 13:50:03 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:03 INFO DAGScheduler: running: Set()
17/10/26 13:50:03 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 13:50:03 INFO DAGScheduler: failed: Set()
17/10/26 13:50:03 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 13:50:03 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 13:50:03 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 13:50:03 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 265.4 MB)
17/10/26 13:50:03 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 13:50:03 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 13:50:03 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 13:50:03 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:03 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:03 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 13:50:03 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
17/10/26 13:50:03 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 13:50:03 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 13:50:03 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.054499 s
17/10/26 13:50:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz15`
WHERE (0 = 1)
17/10/26 13:50:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:50:04 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:04 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:50:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:50:04 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 13:50:04 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 1 output partitions
17/10/26 13:50:04 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:58)
17/10/26 13:50:04 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:50:04 INFO DAGScheduler: Missing parents: List()
17/10/26 13:50:04 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[78] at map at utils.scala:55), which has no missing parents
17/10/26 13:50:04 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.7 KB, free 264.3 MB)
17/10/26 13:50:04 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 264.3 MB)
17/10/26 13:50:04 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:53881 (size: 4.6 KB, free: 265.4 MB)
17/10/26 13:50:04 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:04 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[78] at map at utils.scala:55)
17/10/26 13:50:04 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 13:50:04 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11983 bytes)
17/10/26 13:50:04 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 13:50:04 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1085 bytes result sent to driver
17/10/26 13:50:04 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 5 ms on localhost (executor driver) (1/1)
17/10/26 13:50:04 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 13:50:04 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:58) finished in 0.006 s
17/10/26 13:50:04 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.010150 s
17/10/26 13:50:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:43 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:53881 in memory (size: 4.6 KB, free: 265.4 MB)
17/10/26 13:50:43 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 13:50:43 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 13:50:43 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:53881 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 13:50:43 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 13:50:43 INFO ContextCleaner: Cleaned accumulator 1248
17/10/26 13:50:43 INFO ContextCleaner: Cleaned accumulator 1249
17/10/26 13:50:43 INFO SparkSqlParser: Parsing command: loan_payment
17/10/26 13:50:43 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:43 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan_payment`
17/10/26 13:50:43 INFO SparkSqlParser: Parsing command: `loan_payment`
17/10/26 13:50:43 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 13:50:43 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 13:50:43 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 26 more fields>
17/10/26 13:50:43 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 13:50:43 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 303.3 KB, free 264.1 MB)
17/10/26 13:50:43 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.7 KB, free 264.1 MB)
17/10/26 13:50:43 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:53881 (size: 25.7 KB, free: 265.4 MB)
17/10/26 13:50:43 INFO SparkContext: Created broadcast 19 from sql at <unknown>:0
17/10/26 13:50:43 INFO FileSourceScanExec: Planning scan with bin packing, max size: 46848432 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 13:50:44 INFO SparkContext: Starting job: sql at <unknown>:0
17/10/26 13:50:44 INFO DAGScheduler: Registering RDD 85 (sql at <unknown>:0)
17/10/26 13:50:44 INFO DAGScheduler: Got job 10 (sql at <unknown>:0) with 1 output partitions
17/10/26 13:50:44 INFO DAGScheduler: Final stage: ResultStage 17 (sql at <unknown>:0)
17/10/26 13:50:44 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/10/26 13:50:44 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/10/26 13:50:44 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[85] at sql at <unknown>:0), which has no missing parents
17/10/26 13:50:44 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 32.8 KB, free 264.1 MB)
17/10/26 13:50:44 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.1 KB, free 264.1 MB)
17/10/26 13:50:44 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:53881 (size: 13.1 KB, free: 265.4 MB)
17/10/26 13:50:44 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:44 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[85] at sql at <unknown>:0)
17/10/26 13:50:44 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
17/10/26 13:50:44 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 12203 bytes)
17/10/26 13:50:44 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 12203 bytes)
17/10/26 13:50:44 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 12203 bytes)
17/10/26 13:50:44 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 12203 bytes)
17/10/26 13:50:44 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
17/10/26 13:50:44 INFO Executor: Running task 1.0 in stage 16.0 (TID 35)
17/10/26 13:50:44 INFO Executor: Running task 2.0 in stage 16.0 (TID 36)
17/10/26 13:50:44 INFO Executor: Running task 3.0 in stage 16.0 (TID 37)
17/10/26 13:50:44 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_54b6b744ac900d9abf51a8fcca1ec9cbd112cca0489bcd4d3c5b8d3c8411711e.csv, range: 0-46848432, partition values: [empty row]
17/10/26 13:50:44 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_54b6b744ac900d9abf51a8fcca1ec9cbd112cca0489bcd4d3c5b8d3c8411711e.csv, range: 93696864-140545296, partition values: [empty row]
17/10/26 13:50:44 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_54b6b744ac900d9abf51a8fcca1ec9cbd112cca0489bcd4d3c5b8d3c8411711e.csv, range: 140545296-183199425, partition values: [empty row]
17/10/26 13:50:44 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_54b6b744ac900d9abf51a8fcca1ec9cbd112cca0489bcd4d3c5b8d3c8411711e.csv, range: 46848432-93696864, partition values: [empty row]
17/10/26 13:50:44 INFO CodeGenerator: Code generated in 30.102888 ms
17/10/26 13:50:44 INFO ContextCleaner: Cleaned accumulator 1302
17/10/26 13:50:46 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:53881 in memory (size: 9.4 KB, free: 265.4 MB)
17/10/26 13:50:46 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:53881 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 13:50:46 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 13:50:46 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 13:50:46 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:53881 in memory (size: 11.2 KB, free: 265.4 MB)
17/10/26 13:50:46 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 13:50:46 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 13:50:50 INFO MemoryStore: Block rdd_82_3 stored as values in memory (estimated size 15.0 MB, free 249.2 MB)
17/10/26 13:50:50 INFO BlockManagerInfo: Added rdd_82_3 in memory on 127.0.0.1:53881 (size: 15.0 MB, free: 250.4 MB)
17/10/26 13:50:50 INFO Executor: Finished task 3.0 in stage 16.0 (TID 37). 2893 bytes result sent to driver
17/10/26 13:50:50 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 37) in 6347 ms on localhost (executor driver) (1/4)
17/10/26 13:50:50 INFO MemoryStore: Block rdd_82_1 stored as values in memory (estimated size 15.8 MB, free 233.4 MB)
17/10/26 13:50:50 INFO BlockManagerInfo: Added rdd_82_1 in memory on 127.0.0.1:53881 (size: 15.8 MB, free: 234.6 MB)
17/10/26 13:50:50 INFO Executor: Finished task 1.0 in stage 16.0 (TID 35). 2893 bytes result sent to driver
17/10/26 13:50:50 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 35) in 6452 ms on localhost (executor driver) (2/4)
17/10/26 13:50:50 INFO MemoryStore: Block rdd_82_2 stored as values in memory (estimated size 16.2 MB, free 217.1 MB)
17/10/26 13:50:50 INFO BlockManagerInfo: Added rdd_82_2 in memory on 127.0.0.1:53881 (size: 16.2 MB, free: 218.4 MB)
17/10/26 13:50:50 INFO Executor: Finished task 2.0 in stage 16.0 (TID 36). 2893 bytes result sent to driver
17/10/26 13:50:50 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 36) in 6648 ms on localhost (executor driver) (3/4)
17/10/26 13:50:50 INFO MemoryStore: Block rdd_82_0 stored as values in memory (estimated size 16.2 MB, free 201.0 MB)
17/10/26 13:50:50 INFO BlockManagerInfo: Added rdd_82_0 in memory on 127.0.0.1:53881 (size: 16.2 MB, free: 202.2 MB)
17/10/26 13:50:50 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 2893 bytes result sent to driver
17/10/26 13:50:50 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 6940 ms on localhost (executor driver) (4/4)
17/10/26 13:50:50 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 13:50:50 INFO DAGScheduler: ShuffleMapStage 16 (sql at <unknown>:0) finished in 6.940 s
17/10/26 13:50:50 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:50 INFO DAGScheduler: running: Set()
17/10/26 13:50:50 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/10/26 13:50:50 INFO DAGScheduler: failed: Set()
17/10/26 13:50:50 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[88] at sql at <unknown>:0), which has no missing parents
17/10/26 13:50:50 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.0 KB, free 201.0 MB)
17/10/26 13:50:50 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 201.0 MB)
17/10/26 13:50:50 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 202.2 MB)
17/10/26 13:50:50 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:50 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[88] at sql at <unknown>:0)
17/10/26 13:50:50 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 13:50:50 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 38, localhost, executor driver, partition 0, ANY, 11480 bytes)
17/10/26 13:50:50 INFO Executor: Running task 0.0 in stage 17.0 (TID 38)
17/10/26 13:50:50 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:50 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:50 INFO Executor: Finished task 0.0 in stage 17.0 (TID 38). 1960 bytes result sent to driver
17/10/26 13:50:50 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 38) in 5 ms on localhost (executor driver) (1/1)
17/10/26 13:50:50 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 13:50:50 INFO DAGScheduler: ResultStage 17 (sql at <unknown>:0) finished in 0.006 s
17/10/26 13:50:50 INFO DAGScheduler: Job 10 finished: sql at <unknown>:0, took 6.955827 s
17/10/26 13:50:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:50 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan_payment`
17/10/26 13:50:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 13:50:51 INFO DAGScheduler: Registering RDD 92 (collect at utils.scala:196)
17/10/26 13:50:51 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 1 output partitions
17/10/26 13:50:51 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/10/26 13:50:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/10/26 13:50:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
17/10/26 13:50:51 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[92] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:51 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 32.8 KB, free 200.9 MB)
17/10/26 13:50:51 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.1 KB, free 200.9 MB)
17/10/26 13:50:51 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:53881 (size: 13.1 KB, free: 202.2 MB)
17/10/26 13:50:51 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[92] at collect at utils.scala:196)
17/10/26 13:50:51 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
17/10/26 13:50:51 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 12195 bytes)
17/10/26 13:50:51 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 12195 bytes)
17/10/26 13:50:51 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 12195 bytes)
17/10/26 13:50:51 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 12195 bytes)
17/10/26 13:50:51 INFO Executor: Running task 0.0 in stage 18.0 (TID 39)
17/10/26 13:50:51 INFO Executor: Running task 1.0 in stage 18.0 (TID 40)
17/10/26 13:50:51 INFO Executor: Running task 2.0 in stage 18.0 (TID 41)
17/10/26 13:50:51 INFO BlockManager: Found block rdd_82_1 locally
17/10/26 13:50:51 INFO Executor: Running task 3.0 in stage 18.0 (TID 42)
17/10/26 13:50:51 INFO BlockManager: Found block rdd_82_3 locally
17/10/26 13:50:51 INFO BlockManager: Found block rdd_82_0 locally
17/10/26 13:50:51 INFO BlockManager: Found block rdd_82_2 locally
17/10/26 13:50:51 INFO Executor: Finished task 2.0 in stage 18.0 (TID 41). 2019 bytes result sent to driver
17/10/26 13:50:51 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 41) in 37 ms on localhost (executor driver) (1/4)
17/10/26 13:50:51 INFO Executor: Finished task 1.0 in stage 18.0 (TID 40). 2098 bytes result sent to driver
17/10/26 13:50:51 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 40) in 39 ms on localhost (executor driver) (2/4)
17/10/26 13:50:51 INFO Executor: Finished task 0.0 in stage 18.0 (TID 39). 2185 bytes result sent to driver
17/10/26 13:50:51 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 39) in 45 ms on localhost (executor driver) (3/4)
17/10/26 13:50:51 INFO Executor: Finished task 3.0 in stage 18.0 (TID 42). 2098 bytes result sent to driver
17/10/26 13:50:51 INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:196) finished in 0.050 s
17/10/26 13:50:51 INFO DAGScheduler: looking for newly runnable stages
17/10/26 13:50:51 INFO DAGScheduler: running: Set()
17/10/26 13:50:51 INFO DAGScheduler: waiting: Set(ResultStage 19)
17/10/26 13:50:51 INFO DAGScheduler: failed: Set()
17/10/26 13:50:51 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[95] at collect at utils.scala:196), which has no missing parents
17/10/26 13:50:51 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.0 KB, free 200.9 MB)
17/10/26 13:50:51 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 200.9 MB)
17/10/26 13:50:51 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 42) in 49 ms on localhost (executor driver) (4/4)
17/10/26 13:50:51 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:53881 (size: 3.7 KB, free: 202.2 MB)
17/10/26 13:50:51 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/10/26 13:50:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[95] at collect at utils.scala:196)
17/10/26 13:50:51 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/10/26 13:50:51 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 13:50:51 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 43, localhost, executor driver, partition 0, ANY, 11472 bytes)
17/10/26 13:50:51 INFO Executor: Running task 0.0 in stage 19.0 (TID 43)
17/10/26 13:50:51 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 13:50:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 13:50:51 INFO Executor: Finished task 0.0 in stage 19.0 (TID 43). 1873 bytes result sent to driver
17/10/26 13:50:51 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 43) in 4 ms on localhost (executor driver) (1/1)
17/10/26 13:50:51 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.004 s
17/10/26 13:50:51 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 0.066244 s
17/10/26 13:50:51 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/10/26 13:50:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:51 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan_payment` AS `zzz16`
WHERE (0 = 1)
17/10/26 13:50:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:50:51 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 13:50:51 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:51 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:51 INFO HiveMetaStore: 0: get_database: default
17/10/26 13:50:51 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 13:50:51 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 13:50:51 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 13:51:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:51:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 13:51:20 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 13:51:20 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 13:51:20 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_1831219355
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 13:51:20 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 13:51:20 INFO DAGScheduler: Got job 12 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 13:51:20 INFO DAGScheduler: Final stage: ResultStage 20 (collect at SpreadRDDBuilder.scala:105)
17/10/26 13:51:20 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:51:20 INFO DAGScheduler: Missing parents: List()
17/10/26 13:51:20 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 13:51:20 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.1 KB, free 200.9 MB)
17/10/26 13:51:20 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1361.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:53881 (size: 1361.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/10/26 13:51:20 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 20 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 13:51:20 INFO TaskSchedulerImpl: Adding task set 20.0 with 11 tasks
17/10/26 13:51:20 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 46, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 47, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO Executor: Running task 0.0 in stage 20.0 (TID 44)
17/10/26 13:51:20 INFO Executor: Running task 1.0 in stage 20.0 (TID 45)
17/10/26 13:51:20 INFO Executor: Running task 2.0 in stage 20.0 (TID 46)
17/10/26 13:51:20 INFO Executor: Running task 3.0 in stage 20.0 (TID 47)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_3 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_0 stored as values in memory (estimated size 16.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_3 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_2 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_0 in memory on 127.0.0.1:53881 (size: 16.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_2 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_1 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_1 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 45:
[rdd_97_1]
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 44:
[rdd_97_0]
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 47:
[rdd_97_3]
17/10/26 13:51:20 INFO Executor: Finished task 1.0 in stage 20.0 (TID 45). 1714 bytes result sent to driver
17/10/26 13:51:20 INFO Executor: Finished task 0.0 in stage 20.0 (TID 44). 1627 bytes result sent to driver
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_97_2]
17/10/26 13:51:20 INFO Executor: Finished task 2.0 in stage 20.0 (TID 46). 1714 bytes result sent to driver
17/10/26 13:51:20 INFO Executor: Finished task 3.0 in stage 20.0 (TID 47). 1706 bytes result sent to driver
17/10/26 13:51:20 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 48, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 49, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO Executor: Running task 4.0 in stage 20.0 (TID 48)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 50, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 51, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO Executor: Running task 5.0 in stage 20.0 (TID 49)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 45) in 27 ms on localhost (executor driver) (1/11)
17/10/26 13:51:20 INFO Executor: Running task 6.0 in stage 20.0 (TID 50)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 46) in 27 ms on localhost (executor driver) (2/11)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 47) in 28 ms on localhost (executor driver) (3/11)
17/10/26 13:51:20 INFO Executor: Running task 7.0 in stage 20.0 (TID 51)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_4 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_4 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_5 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_5 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_6 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_6 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 44) in 36 ms on localhost (executor driver) (4/11)
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 49:
[rdd_97_5]
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 50:
[rdd_97_6]
17/10/26 13:51:20 INFO Executor: Finished task 5.0 in stage 20.0 (TID 49). 1717 bytes result sent to driver
17/10/26 13:51:20 INFO Executor: Finished task 6.0 in stage 20.0 (TID 50). 1627 bytes result sent to driver
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 48:
[rdd_97_4]
17/10/26 13:51:20 INFO Executor: Finished task 4.0 in stage 20.0 (TID 48). 1627 bytes result sent to driver
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_7 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_7 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 52, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO Executor: Running task 8.0 in stage 20.0 (TID 52)
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 51:
[rdd_97_7]
17/10/26 13:51:20 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 53, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO Executor: Finished task 7.0 in stage 20.0 (TID 51). 1627 bytes result sent to driver
17/10/26 13:51:20 INFO Executor: Running task 9.0 in stage 20.0 (TID 53)
17/10/26 13:51:20 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 54, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 49) in 11 ms on localhost (executor driver) (5/11)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 48) in 11 ms on localhost (executor driver) (6/11)
17/10/26 13:51:20 INFO Executor: Running task 10.0 in stage 20.0 (TID 54)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 51) in 9 ms on localhost (executor driver) (7/11)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 50) in 11 ms on localhost (executor driver) (8/11)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_8 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_9 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_8 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_9 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 52:
[rdd_97_8]
17/10/26 13:51:20 INFO Executor: Finished task 8.0 in stage 20.0 (TID 52). 1627 bytes result sent to driver
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 53:
[rdd_97_9]
17/10/26 13:51:20 INFO MemoryStore: Block rdd_97_10 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO Executor: Finished task 9.0 in stage 20.0 (TID 53). 1627 bytes result sent to driver
17/10/26 13:51:20 INFO BlockManagerInfo: Added rdd_97_10 in memory on 127.0.0.1:53881 (size: 24.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 52) in 5 ms on localhost (executor driver) (9/11)
17/10/26 13:51:20 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 53) in 5 ms on localhost (executor driver) (10/11)
17/10/26 13:51:20 WARN Executor: 1 block locks were not released by TID = 54:
[rdd_97_10]
17/10/26 13:51:20 INFO Executor: Finished task 10.0 in stage 20.0 (TID 54). 1627 bytes result sent to driver
17/10/26 13:51:20 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 54) in 5 ms on localhost (executor driver) (11/11)
17/10/26 13:51:20 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/10/26 13:51:20 INFO DAGScheduler: ResultStage 20 (collect at SpreadRDDBuilder.scala:105) finished in 0.047 s
17/10/26 13:51:20 INFO DAGScheduler: Job 12 finished: collect at SpreadRDDBuilder.scala:105, took 0.052104 s
17/10/26 13:51:20 INFO ParallelCollectionRDD: Removing RDD 97 from persistence list
17/10/26 13:51:20 INFO BlockManager: Removing RDD 97
17/10/26 13:51:20 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 13:51:20 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 13:51:20 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 13:51:20 INFO DAGScheduler: Got job 13 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 13:51:20 INFO DAGScheduler: Final stage: ResultStage 21 (collect at InternalBackendUtils.scala:163)
17/10/26 13:51:20 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:51:20 INFO DAGScheduler: Missing parents: List()
17/10/26 13:51:20 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[100] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 13:51:20 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.0 KB, free 200.9 MB)
17/10/26 13:51:20 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 1950.0 B, free 200.9 MB)
17/10/26 13:51:20 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:53881 (size: 1950.0 B, free: 202.2 MB)
17/10/26 13:51:20 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/10/26 13:51:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[100] at map at InternalBackendUtils.scala:100)
17/10/26 13:51:20 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/10/26 13:51:20 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 55, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 13:51:20 INFO Executor: Running task 0.0 in stage 21.0 (TID 55)
17/10/26 13:51:20 INFO Reflections: Reflections took 381 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 13:51:21 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 202.2 MB)
17/10/26 13:51:21 INFO BlockManager: Removing RDD 97
17/10/26 13:51:21 INFO ContextCleaner: Cleaned RDD 97
17/10/26 13:51:21 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:53881 in memory (size: 1361.0 B, free: 202.2 MB)
17/10/26 13:51:21 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:53881 in memory (size: 13.1 KB, free: 202.2 MB)
17/10/26 13:51:21 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:53881 in memory (size: 3.7 KB, free: 202.2 MB)
17/10/26 13:51:21 INFO ContextCleaner: Cleaned accumulator 1483
17/10/26 13:51:21 INFO Reflections: Reflections took 469 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 13:51:22 INFO Server: jetty-8.1.17.v20150415
17/10/26 13:51:22 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54323
17/10/26 13:51:23 INFO Executor: Finished task 0.0 in stage 21.0 (TID 55). 1534 bytes result sent to driver
17/10/26 13:51:23 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 55) in 3185 ms on localhost (executor driver) (1/1)
17/10/26 13:51:23 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/10/26 13:51:23 INFO DAGScheduler: ResultStage 21 (collect at InternalBackendUtils.scala:163) finished in 3.186 s
17/10/26 13:51:23 INFO DAGScheduler: Job 13 finished: collect at InternalBackendUtils.scala:163, took 3.190778 s
17/10/26 13:51:23 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 13:51:23 INFO DAGScheduler: Got job 14 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 13:51:23 INFO DAGScheduler: Final stage: ResultStage 22 (foreach at InternalBackendUtils.scala:175)
17/10/26 13:51:23 INFO DAGScheduler: Parents of final stage: List()
17/10/26 13:51:23 INFO DAGScheduler: Missing parents: List()
17/10/26 13:51:23 INFO DAGScheduler: Submitting ResultStage 22 (InvokeOnNodesRDD[99] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 13:51:23 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1672.0 B, free 201.0 MB)
17/10/26 13:51:23 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1161.0 B, free 201.0 MB)
17/10/26 13:51:23 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:53881 (size: 1161.0 B, free: 202.2 MB)
17/10/26 13:51:23 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/10/26 13:51:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (InvokeOnNodesRDD[99] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 13:51:23 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/10/26 13:51:23 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 56, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 13:51:23 INFO Executor: Running task 0.0 in stage 22.0 (TID 56)
17/10/26 13:51:23 INFO Executor: Finished task 0.0 in stage 22.0 (TID 56). 764 bytes result sent to driver
17/10/26 13:51:23 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 56) in 4 ms on localhost (executor driver) (1/1)
17/10/26 13:51:23 INFO DAGScheduler: ResultStage 22 (foreach at InternalBackendUtils.scala:175) finished in 0.004 s
17/10/26 13:51:23 INFO DAGScheduler: Job 14 finished: foreach at InternalBackendUtils.scala:175, took 0.008995 s
17/10/26 13:51:23 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/10/26 13:51:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 13:51:25 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:53881 in memory (size: 1161.0 B, free: 202.2 MB)
17/10/26 13:51:29 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:53881 in memory (size: 1950.0 B, free: 202.2 MB)
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1952
17/10/26 13:51:29 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:53881 in memory (size: 13.1 KB, free: 202.2 MB)
17/10/26 13:51:29 INFO ContextCleaner: Cleaned shuffle 6
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1314
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1313
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1312
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1311
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1310
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1309
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1308
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1307
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1306
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1305
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1304
17/10/26 13:51:29 INFO ContextCleaner: Cleaned accumulator 1303
17/10/26 13:51:35 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_1831219355
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54323)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54323 (CMD + click in Mac OSX)
    
17/10/26 21:24:57 INFO SparkContext: Running Spark version 2.1.0
17/10/26 21:24:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 21:24:59 INFO SecurityManager: Changing view acls to: scibr
17/10/26 21:24:59 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 21:24:59 INFO SecurityManager: Changing view acls groups to: 
17/10/26 21:24:59 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 21:24:59 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 21:25:00 INFO Utils: Successfully started service 'sparkDriver' on port 56932.
17/10/26 21:25:00 INFO SparkEnv: Registering MapOutputTracker
17/10/26 21:25:00 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 21:25:00 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 21:25:00 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 21:25:00 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-2295bbb7-f550-4c10-8156-a3fc3e607c79
17/10/26 21:25:00 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 21:25:00 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 21:25:00 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 21:25:01 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1509020701025
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1509020701026
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1509020701026
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:56932/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1509020701026
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1509020701026
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:56932/jars/org.joda_joda-convert-1.7.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:56932/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:56932/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:56932/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:56932/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:56932/jars/commons-io_commons-io-2.4.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:56932/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:56932/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:56932/jars/log4j_log4j-1.2.15.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:56932/jars/com.google.guava_guava-16.0.1.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:56932/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:56932/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:56932/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:56932/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:56932/jars/commons-lang_commons-lang-2.6.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1509020701029
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1509020701030
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:56932/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:56932/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:56932/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:56932/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:56932/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:56932/jars/org.tukaani_xz-1.5.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:56932/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:56932/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:56932/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1509020701031
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:56932/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:56932/jars/joda-time_joda-time-2.8.1.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:56932/jars/commons-codec_commons-codec-1.6.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:56932/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1509020701032
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:56932/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1509020701033
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1509020701033
17/10/26 21:25:01 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:56932/jars/sparklyr-2.1-2.11.jar with timestamp 1509020701033
17/10/26 21:25:01 INFO Executor: Starting executor ID driver on host localhost
17/10/26 21:25:01 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 56955.
17/10/26 21:25:01 INFO NettyBlockTransferService: Server created on 127.0.0.1:56955
17/10/26 21:25:01 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 21:25:01 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 56955, None)
17/10/26 21:25:01 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:56955 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 56955, None)
17/10/26 21:25:01 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 56955, None)
17/10/26 21:25:01 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 56955, None)
17/10/26 21:25:52 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 21:25:53 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 21:25:53 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 21:25:53 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 21:25:53 INFO ObjectStore: ObjectStore, initialize called
17/10/26 21:25:54 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 21:25:54 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 21:25:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 21:25:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 21:25:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 21:25:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 21:25:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 21:25:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 21:25:59 INFO ObjectStore: Initialized ObjectStore
17/10/26 21:26:00 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 21:26:00 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 21:26:00 INFO HiveMetaStore: Added admin role in metastore
17/10/26 21:26:00 INFO HiveMetaStore: Added public role in metastore
17/10/26 21:26:00 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 21:26:00 INFO HiveMetaStore: 0: get_all_databases
17/10/26 21:26:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 21:26:00 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 21:26:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 21:26:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 21:26:01 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/afdd9915-a16a-4a9f-96e2-ffcf9be49dc0_resources
17/10/26 21:26:01 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/afdd9915-a16a-4a9f-96e2-ffcf9be49dc0
17/10/26 21:26:01 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/afdd9915-a16a-4a9f-96e2-ffcf9be49dc0
17/10/26 21:26:01 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/afdd9915-a16a-4a9f-96e2-ffcf9be49dc0/_tmp_space.db
17/10/26 21:26:01 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 21:26:01 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:26:01 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:26:01 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 21:26:01 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 21:26:01 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 21:26:01 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:26:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:26:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:26:04 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:26:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:26:04 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:26:04 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:26:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:26:17 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:26:17 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:26:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:26:17 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:26:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:26:17 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:26:17 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:26:18 INFO CodeGenerator: Code generated in 443.382152 ms
17/10/26 21:26:18 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 21:26:19 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 21:26:19 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 21:26:19 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:26:19 INFO DAGScheduler: Missing parents: List()
17/10/26 21:26:19 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 21:26:20 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 21:26:20 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 21:26:20 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:56955 (size: 4.6 KB, free: 366.3 MB)
17/10/26 21:26:20 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 21:26:20 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 21:26:20 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 21:26:20 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 21:26:20 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 21:26:20 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1509020701031
17/10/26 21:26:20 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:56932 after 52 ms (0 ms spent in bootstraps)
17/10/26 21:26:20 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2354402142230519003.tmp
17/10/26 21:26:21 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 21:26:21 INFO Executor: Fetching spark://127.0.0.1:56932/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1509020701026
17/10/26 21:26:21 INFO Utils: Fetching spark://127.0.0.1:56932/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp588306713486368157.tmp
17/10/26 21:26:21 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 21:26:21 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.google.guava_guava-16.0.1.jar with timestamp 1509020701029
17/10/26 21:26:21 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8445128176677114766.tmp
17/10/26 21:26:22 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 21:26:22 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1509020701032
17/10/26 21:26:22 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3214293829743522302.tmp
17/10/26 21:26:22 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 21:26:22 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:22 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3513452631847861026.tmp
17/10/26 21:26:22 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 21:26:22 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:22 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8737859049454490293.tmp
17/10/26 21:26:22 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 21:26:22 INFO Executor: Fetching spark://127.0.0.1:56932/jars/commons-lang_commons-lang-2.6.jar with timestamp 1509020701029
17/10/26 21:26:22 INFO Utils: Fetching spark://127.0.0.1:56932/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp6641159079684253573.tmp
17/10/26 21:26:23 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 21:26:23 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:23 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp84817849829610898.tmp
17/10/26 21:26:23 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 21:26:23 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1509020701028
17/10/26 21:26:23 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2797415328654995472.tmp
17/10/26 21:26:23 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 21:26:23 INFO Executor: Fetching spark://127.0.0.1:56932/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1509020701029
17/10/26 21:26:23 INFO Utils: Fetching spark://127.0.0.1:56932/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp82105566847285943.tmp
17/10/26 21:26:24 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 21:26:24 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:24 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1729335588920619585.tmp
17/10/26 21:26:24 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 21:26:24 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:26:24 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7743730877850180598.tmp
17/10/26 21:26:24 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 21:26:24 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:24 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4829281642474169798.tmp
17/10/26 21:26:24 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 21:26:24 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1509020701032
17/10/26 21:26:24 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4307399510097914162.tmp
17/10/26 21:26:25 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 21:26:25 INFO Executor: Fetching spark://127.0.0.1:56932/jars/joda-time_joda-time-2.8.1.jar with timestamp 1509020701032
17/10/26 21:26:25 INFO Utils: Fetching spark://127.0.0.1:56932/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1451603382055811427.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/commons-codec_commons-codec-1.6.jar with timestamp 1509020701032
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7465042077581438114.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1509020701026
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp9016541606409920339.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2897586812927505418.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1509020701029
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8201549410535472212.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1509020701030
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8402540267533135799.tmp
17/10/26 21:26:26 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 21:26:26 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1509020701031
17/10/26 21:26:26 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8181472789168333863.tmp
17/10/26 21:26:27 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 21:26:27 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1509020701028
17/10/26 21:26:27 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1202447216351099376.tmp
17/10/26 21:26:27 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 21:26:27 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:27 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4367736257470822745.tmp
17/10/26 21:26:27 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 21:26:27 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1509020701033
17/10/26 21:26:27 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp6643079741931497543.tmp
17/10/26 21:26:27 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 21:26:27 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:27 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5883544943779080134.tmp
17/10/26 21:26:27 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 21:26:27 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1509020701031
17/10/26 21:26:27 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp195717310109828869.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1509020701031
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4729481538745528866.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1509020701031
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp9048441910448221811.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1509020701031
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4275047896526617010.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1509020701029
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1095784941175090010.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.joda_joda-convert-1.7.jar with timestamp 1509020701027
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp424057784978032629.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.joda_joda-convert-1.7.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1509020701029
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp9167252453576793710.tmp
17/10/26 21:26:28 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 21:26:28 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1509020701028
17/10/26 21:26:28 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5800793034254294124.tmp
17/10/26 21:26:29 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 21:26:29 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:29 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp559884920360416899.tmp
17/10/26 21:26:29 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 21:26:29 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1509020701031
17/10/26 21:26:29 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2706171421705743501.tmp
17/10/26 21:26:29 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 21:26:29 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1509020701033
17/10/26 21:26:29 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7388596578643687732.tmp
17/10/26 21:26:29 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 21:26:29 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1509020701032
17/10/26 21:26:29 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp6284891239403740155.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1509020701029
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1881478409511680980.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1509020701030
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7372571814218692632.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1509020701032
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1591009219511643544.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1509020701032
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1341864998220193820.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1509020701030
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp6357181374761926620.tmp
17/10/26 21:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 21:26:30 INFO Executor: Fetching spark://127.0.0.1:56932/jars/log4j_log4j-1.2.15.jar with timestamp 1509020701029
17/10/26 21:26:30 INFO Utils: Fetching spark://127.0.0.1:56932/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7533253446068278981.tmp
17/10/26 21:26:31 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/log4j_log4j-1.2.15.jar to class loader
17/10/26 21:26:31 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:31 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp474470579583346895.tmp
17/10/26 21:26:31 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 21:26:31 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:31 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5505113178852812366.tmp
17/10/26 21:26:31 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 21:26:31 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1509020701032
17/10/26 21:26:31 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3694327156988687054.tmp
17/10/26 21:26:31 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 21:26:31 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:31 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp429916400048042331.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1509020701027
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2816610054767383082.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1509020701032
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1786585544351745562.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.tukaani_xz-1.5.jar with timestamp 1509020701031
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp603778061162229507.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.tukaani_xz-1.5.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3826149944800820659.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1509020701030
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp6510083909301422215.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1509020701026
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3307808283484753706.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1509020701028
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7081592324706069072.tmp
17/10/26 21:26:32 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 21:26:32 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1509020701031
17/10/26 21:26:32 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5452205627372830703.tmp
17/10/26 21:26:33 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 21:26:33 INFO Executor: Fetching spark://127.0.0.1:56932/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1509020701032
17/10/26 21:26:33 INFO Utils: Fetching spark://127.0.0.1:56932/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp3810622370931049415.tmp
17/10/26 21:26:33 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 21:26:33 INFO Executor: Fetching spark://127.0.0.1:56932/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1509020701029
17/10/26 21:26:33 INFO Utils: Fetching spark://127.0.0.1:56932/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4435729669393064160.tmp
17/10/26 21:26:33 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 21:26:33 INFO Executor: Fetching spark://127.0.0.1:56932/jars/commons-io_commons-io-2.4.jar with timestamp 1509020701028
17/10/26 21:26:33 INFO Utils: Fetching spark://127.0.0.1:56932/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7510726409893983911.tmp
17/10/26 21:26:34 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/commons-io_commons-io-2.4.jar to class loader
17/10/26 21:26:34 INFO Executor: Fetching spark://127.0.0.1:56932/jars/sparklyr-2.1-2.11.jar with timestamp 1509020701033
17/10/26 21:26:34 INFO Utils: Fetching spark://127.0.0.1:56932/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7418843268978370362.tmp
17/10/26 21:26:34 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/sparklyr-2.1-2.11.jar to class loader
17/10/26 21:26:34 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1509020701032
17/10/26 21:26:34 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5244333951004730158.tmp
17/10/26 21:26:34 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 21:26:34 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1509020701026
17/10/26 21:26:34 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp377235632749774990.tmp
17/10/26 21:26:34 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 21:26:34 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:26:34 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7694283591923761707.tmp
17/10/26 21:26:34 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 21:26:34 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1509020701031
17/10/26 21:26:34 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8005914017454173277.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1509020701025
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp7883603691213525513.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1509020701029
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp1064126781954097307.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1509020701032
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp802321421089996357.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1509020701028
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp5677270857946035967.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1509020701028
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp4932414550765300765.tmp
17/10/26 21:26:35 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 21:26:35 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1509020701028
17/10/26 21:26:35 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp2148712023599037626.tmp
17/10/26 21:26:36 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 21:26:36 INFO Executor: Fetching spark://127.0.0.1:56932/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1509020701031
17/10/26 21:26:36 INFO Utils: Fetching spark://127.0.0.1:56932/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54\fetchFileTemp8636526298850455487.tmp
17/10/26 21:26:36 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-c131949e-05e3-4f37-8a76-43e8f2b23c40/userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 21:26:37 INFO CodeGenerator: Code generated in 23.19132 ms
17/10/26 21:26:37 INFO CodeGenerator: Code generated in 14.138746 ms
17/10/26 21:26:37 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1391 bytes result sent to driver
17/10/26 21:26:37 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 17280 ms on localhost (executor driver) (1/1)
17/10/26 21:26:37 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 21:26:37 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 17.355 s
17/10/26 21:26:37 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 19.029839 s
17/10/26 21:26:38 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 21:26:38 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 21:26:38 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:56955 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 21:27:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:12 INFO SparkSqlParser: Parsing command: loan
17/10/26 21:27:12 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:12 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 21:27:13 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 21:27:13 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 21:27:13 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 21:27:13 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 21:27:13 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 21:27:13 INFO CodeGenerator: Code generated in 7.692635 ms
17/10/26 21:27:14 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 21:27:14 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 21:27:14 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:56955 (size: 25.7 KB, free: 366.3 MB)
17/10/26 21:27:14 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:14 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 21:27:17 INFO CodeGenerator: Code generated in 13.878048 ms
17/10/26 21:27:17 INFO CodeGenerator: Code generated in 11.112496 ms
17/10/26 21:27:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:17 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:17 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 21:27:17 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 21:27:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 21:27:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 21:27:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 21:27:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:56955 (size: 11.2 KB, free: 366.3 MB)
17/10/26 21:27:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 21:27:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 21:27:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 21:27:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 21:27:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 21:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 21:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 21:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 21:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 21:27:17 INFO CodeGenerator: Code generated in 31.038937 ms
17/10/26 21:27:18 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 21:27:21 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 21:27:21 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:56955 (size: 15.4 MB, free: 350.9 MB)
17/10/26 21:27:21 INFO CodeGenerator: Code generated in 8.937108 ms
17/10/26 21:27:22 INFO CodeGenerator: Code generated in 71.136093 ms
17/10/26 21:27:22 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3070 bytes result sent to driver
17/10/26 21:27:22 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 4767 ms on localhost (executor driver) (1/4)
17/10/26 21:27:22 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 21:27:22 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:56955 (size: 18.2 MB, free: 332.6 MB)
17/10/26 21:27:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/26 21:27:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4845 ms on localhost (executor driver) (2/4)
17/10/26 21:27:22 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 21:27:22 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:56955 (size: 18.2 MB, free: 314.4 MB)
17/10/26 21:27:22 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2983 bytes result sent to driver
17/10/26 21:27:22 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4955 ms on localhost (executor driver) (3/4)
17/10/26 21:27:22 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 21:27:22 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:56955 (size: 18.2 MB, free: 296.2 MB)
17/10/26 21:27:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 21:27:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 5120 ms on localhost (executor driver) (4/4)
17/10/26 21:27:22 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 5.125 s
17/10/26 21:27:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 21:27:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:22 INFO DAGScheduler: running: Set()
17/10/26 21:27:22 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 21:27:22 INFO DAGScheduler: failed: Set()
17/10/26 21:27:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 21:27:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 21:27:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 296.2 MB)
17/10/26 21:27:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 21:27:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 21:27:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 21:27:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 14 ms
17/10/26 21:27:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2042 bytes result sent to driver
17/10/26 21:27:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 82 ms on localhost (executor driver) (1/1)
17/10/26 21:27:22 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.082 s
17/10/26 21:27:22 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 5.384671 s
17/10/26 21:27:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 21:27:22 INFO CodeGenerator: Code generated in 8.383382 ms
17/10/26 21:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 21:27:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 21:27:22 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 21:27:22 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 21:27:22 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 21:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 21:27:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 21:27:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 21:27:23 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 21:27:23 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:56955 (size: 11.2 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:23 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 21:27:23 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 21:27:23 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 21:27:23 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 21:27:23 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 21:27:23 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 21:27:23 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 21:27:23 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 21:27:23 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 21:27:23 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 21:27:23 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 21:27:23 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 21:27:23 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 21:27:23 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 21:27:23 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/26 21:27:23 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 51 ms on localhost (executor driver) (1/4)
17/10/26 21:27:23 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/26 21:27:23 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 51 ms on localhost (executor driver) (2/4)
17/10/26 21:27:23 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2019 bytes result sent to driver
17/10/26 21:27:23 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2019 bytes result sent to driver
17/10/26 21:27:23 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 63 ms on localhost (executor driver) (3/4)
17/10/26 21:27:23 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 62 ms on localhost (executor driver) (4/4)
17/10/26 21:27:23 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.068 s
17/10/26 21:27:23 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:23 INFO DAGScheduler: running: Set()
17/10/26 21:27:23 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 21:27:23 INFO DAGScheduler: failed: Set()
17/10/26 21:27:23 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:23 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 21:27:23 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 21:27:23 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 21:27:23 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 21:27:23 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 21:27:23 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 21:27:23 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 21:27:23 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:23 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 21:27:23 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 21:27:23 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.011 s
17/10/26 21:27:23 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 10 ms on localhost (executor driver) (1/1)
17/10/26 21:27:23 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.203005 s
17/10/26 21:27:23 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 21:27:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz1`
WHERE (0 = 1)
17/10/26 21:27:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:23 INFO CodeGenerator: Code generated in 8.733887 ms
17/10/26 21:27:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:23 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 21:27:23 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 21:27:23 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 21:27:23 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:27:23 INFO DAGScheduler: Missing parents: List()
17/10/26 21:27:23 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 21:27:23 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 21:27:23 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 21:27:23 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:56955 (size: 4.6 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 21:27:23 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 21:27:23 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 21:27:23 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 21:27:23 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 21:27:23 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.013 s
17/10/26 21:27:23 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.018880 s
17/10/26 21:27:23 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 10 ms on localhost (executor driver) (1/1)
17/10/26 21:27:23 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 21:27:23 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:56955 in memory (size: 11.2 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 21:27:23 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 21:27:23 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 21:27:23 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 21:27:23 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:56955 in memory (size: 4.6 KB, free: 296.2 MB)
17/10/26 21:27:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:39 INFO SparkSqlParser: Parsing command: payment
17/10/26 21:27:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:39 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 21:27:39 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 21:27:39 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 21:27:39 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 21:27:39 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 21:27:39 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 21:27:39 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.6 MB)
17/10/26 21:27:39 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 21:27:39 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:56955 (size: 25.7 KB, free: 296.2 MB)
17/10/26 21:27:39 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:39 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 21:27:39 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:39 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:39 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 21:27:39 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:39 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 21:27:39 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 21:27:39 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:39 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.5 MB)
17/10/26 21:27:39 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.5 MB)
17/10/26 21:27:39 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:56955 (size: 9.4 KB, free: 296.1 MB)
17/10/26 21:27:39 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:39 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:39 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 21:27:39 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:39 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:39 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:39 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 21:27:39 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 21:27:39 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 21:27:39 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 21:27:39 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 21:27:39 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 21:27:39 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 21:27:39 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 21:27:39 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 21:27:39 INFO CodeGenerator: Code generated in 26.961173 ms
17/10/26 21:27:40 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 21:27:41 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 21:27:41 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:56955 (size: 5.1 MB, free: 291.0 MB)
17/10/26 21:27:41 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 21:27:41 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 2028 ms on localhost (executor driver) (1/4)
17/10/26 21:27:42 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 283.3 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:56955 (size: 7.1 MB, free: 283.9 MB)
17/10/26 21:27:42 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2510 ms on localhost (executor driver) (2/4)
17/10/26 21:27:42 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:56955 (size: 7.1 MB, free: 276.8 MB)
17/10/26 21:27:42 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2544 ms on localhost (executor driver) (3/4)
17/10/26 21:27:42 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:56955 (size: 7.1 MB, free: 269.7 MB)
17/10/26 21:27:42 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2983 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2560 ms on localhost (executor driver) (4/4)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 21:27:42 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.560 s
17/10/26 21:27:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:42 INFO DAGScheduler: running: Set()
17/10/26 21:27:42 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 21:27:42 INFO DAGScheduler: failed: Set()
17/10/26 21:27:42 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 269.7 MB)
17/10/26 21:27:42 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 21:27:42 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 21:27:42 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 21:27:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:27:42 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:27:42 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 21:27:42 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.585368 s
17/10/26 21:27:42 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 21:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 21:27:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 21:27:42 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 21:27:42 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 21:27:42 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 21:27:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 21:27:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 21:27:42 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:56955 (size: 9.4 KB, free: 269.7 MB)
17/10/26 21:27:42 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:42 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 21:27:42 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:42 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:42 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:42 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:42 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 21:27:42 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 21:27:42 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 21:27:42 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 21:27:42 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 21:27:42 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 21:27:42 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 21:27:42 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2019 bytes result sent to driver
17/10/26 21:27:42 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 21:27:42 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 20 ms on localhost (executor driver) (1/4)
17/10/26 21:27:42 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 28 ms on localhost (executor driver) (2/4)
17/10/26 21:27:42 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2019 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 34 ms on localhost (executor driver) (3/4)
17/10/26 21:27:42 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2098 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 35 ms on localhost (executor driver) (4/4)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 21:27:42 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.040 s
17/10/26 21:27:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:42 INFO DAGScheduler: running: Set()
17/10/26 21:27:42 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 21:27:42 INFO DAGScheduler: failed: Set()
17/10/26 21:27:42 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 269.7 MB)
17/10/26 21:27:42 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 21:27:42 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 21:27:42 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 21:27:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:27:42 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 21:27:42 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 21:27:42 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.005 s
17/10/26 21:27:42 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.062285 s
17/10/26 21:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz2`
WHERE (0 = 1)
17/10/26 21:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:42 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 21:27:42 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 21:27:42 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 21:27:42 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:27:42 INFO DAGScheduler: Missing parents: List()
17/10/26 21:27:42 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 21:27:42 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 21:27:42 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:56955 (size: 4.6 KB, free: 269.7 MB)
17/10/26 21:27:42 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 21:27:42 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 21:27:42 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 21:27:42 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 21:27:42 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.006 s
17/10/26 21:27:42 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.012646 s
17/10/26 21:27:42 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
17/10/26 21:27:42 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 21:27:44 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:45 INFO SparkSqlParser: Parsing command: cuv
17/10/26 21:27:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 21:27:45 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 21:27:45 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 21:27:45 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 21:27:45 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 21:27:45 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 21:27:45 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 21:27:45 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:56955 (size: 25.7 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 21:27:45 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 21:27:45 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 21:27:45 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:45 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 21:27:45 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 21:27:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 21:27:45 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:45 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 21:27:45 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:56955 (size: 19.5 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:45 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 21:27:45 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 21:27:45 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 21:27:45 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 21:27:45 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 21:27:45 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 21:27:45 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 21:27:45 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 21:27:45 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 21:27:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 21:27:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 21:27:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 21:27:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 21:27:45 INFO CodeGenerator: Code generated in 57.281652 ms
17/10/26 21:27:45 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:56955 in memory (size: 9.4 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 21:27:45 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 21:27:45 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:56955 in memory (size: 4.6 KB, free: 269.6 MB)
17/10/26 21:27:45 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 21:27:45 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 21:27:45 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:56955 (size: 198.6 KB, free: 269.4 MB)
17/10/26 21:27:45 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2983 bytes result sent to driver
17/10/26 21:27:45 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 248 ms on localhost (executor driver) (1/4)
17/10/26 21:27:45 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 267.0 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:56955 (size: 1444.5 KB, free: 268.0 MB)
17/10/26 21:27:45 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2983 bytes result sent to driver
17/10/26 21:27:45 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 617 ms on localhost (executor driver) (2/4)
17/10/26 21:27:45 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 265.7 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:56955 (size: 1374.8 KB, free: 266.7 MB)
17/10/26 21:27:45 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 264.4 MB)
17/10/26 21:27:45 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:56955 (size: 1296.0 KB, free: 265.4 MB)
17/10/26 21:27:45 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2983 bytes result sent to driver
17/10/26 21:27:45 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 657 ms on localhost (executor driver) (3/4)
17/10/26 21:27:46 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 966 ms on localhost (executor driver) (4/4)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 21:27:46 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.967 s
17/10/26 21:27:46 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:46 INFO DAGScheduler: running: Set()
17/10/26 21:27:46 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 21:27:46 INFO DAGScheduler: failed: Set()
17/10/26 21:27:46 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 21:27:46 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 265.4 MB)
17/10/26 21:27:46 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 21:27:46 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 21:27:46 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 21:27:46 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:27:46 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:27:46 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.005 s
17/10/26 21:27:46 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 21:27:46 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.983647 s
17/10/26 21:27:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:46 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 21:27:46 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 21:27:46 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 21:27:46 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 21:27:46 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 21:27:46 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 21:27:46 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 21:27:46 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 21:27:46 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:56955 (size: 19.5 KB, free: 265.4 MB)
17/10/26 21:27:46 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:46 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 21:27:46 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:46 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:46 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:46 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 21:27:46 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 21:27:46 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 21:27:46 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 21:27:46 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 21:27:46 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 21:27:46 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 21:27:46 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 21:27:46 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 21:27:46 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 22 ms on localhost (executor driver) (1/4)
17/10/26 21:27:46 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2109 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 24 ms on localhost (executor driver) (2/4)
17/10/26 21:27:46 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2188 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 29 ms on localhost (executor driver) (3/4)
17/10/26 21:27:46 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2019 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 33 ms on localhost (executor driver) (4/4)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 21:27:46 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.034 s
17/10/26 21:27:46 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:27:46 INFO DAGScheduler: running: Set()
17/10/26 21:27:46 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 21:27:46 INFO DAGScheduler: failed: Set()
17/10/26 21:27:46 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 21:27:46 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 265.4 MB)
17/10/26 21:27:46 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 21:27:46 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 21:27:46 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 21:27:46 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:27:46 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:27:46 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 21:27:46 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 21:27:46 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.050065 s
17/10/26 21:27:46 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 4 ms on localhost (executor driver) (1/1)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 21:27:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:46 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz3`
WHERE (0 = 1)
17/10/26 21:27:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:46 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:27:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:27:46 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:27:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:27:46 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 21:27:46 INFO DAGScheduler: Got job 9 (collect at utils.scala:58) with 1 output partitions
17/10/26 21:27:46 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:58)
17/10/26 21:27:46 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:27:46 INFO DAGScheduler: Missing parents: List()
17/10/26 21:27:46 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[78] at map at utils.scala:55), which has no missing parents
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 8.7 KB, free 264.3 MB)
17/10/26 21:27:46 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 4.6 KB, free 264.3 MB)
17/10/26 21:27:46 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:56955 (size: 4.6 KB, free: 265.4 MB)
17/10/26 21:27:46 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 21:27:46 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[78] at map at utils.scala:55)
17/10/26 21:27:46 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 21:27:46 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11983 bytes)
17/10/26 21:27:46 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 21:27:46 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1085 bytes result sent to driver
17/10/26 21:27:46 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:27:46 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:58) finished in 0.005 s
17/10/26 21:27:46 INFO DAGScheduler: Job 9 finished: collect at utils.scala:58, took 0.009437 s
17/10/26 21:27:46 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 21:28:27 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:28 INFO SparkSqlParser: Parsing command: loan_payment
17/10/26 21:28:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:28 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan_payment`
17/10/26 21:28:28 INFO SparkSqlParser: Parsing command: `loan_payment`
17/10/26 21:28:28 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 21:28:28 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 21:28:28 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 26 more fields>
17/10/26 21:28:28 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 21:28:28 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 303.3 KB, free 264.0 MB)
17/10/26 21:28:28 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 25.7 KB, free 264.0 MB)
17/10/26 21:28:28 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:56955 (size: 25.7 KB, free: 265.4 MB)
17/10/26 21:28:28 INFO SparkContext: Created broadcast 19 from sql at <unknown>:0
17/10/26 21:28:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 46848432 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 21:28:28 INFO SparkContext: Starting job: sql at <unknown>:0
17/10/26 21:28:28 INFO DAGScheduler: Registering RDD 85 (sql at <unknown>:0)
17/10/26 21:28:28 INFO DAGScheduler: Got job 10 (sql at <unknown>:0) with 1 output partitions
17/10/26 21:28:28 INFO DAGScheduler: Final stage: ResultStage 17 (sql at <unknown>:0)
17/10/26 21:28:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 16)
17/10/26 21:28:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 16)
17/10/26 21:28:28 INFO DAGScheduler: Submitting ShuffleMapStage 16 (MapPartitionsRDD[85] at sql at <unknown>:0), which has no missing parents
17/10/26 21:28:28 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 32.8 KB, free 264.0 MB)
17/10/26 21:28:28 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 13.1 KB, free 263.9 MB)
17/10/26 21:28:28 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:56955 (size: 13.1 KB, free: 265.4 MB)
17/10/26 21:28:28 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 16 (MapPartitionsRDD[85] at sql at <unknown>:0)
17/10/26 21:28:28 INFO TaskSchedulerImpl: Adding task set 16.0 with 4 tasks
17/10/26 21:28:28 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 12203 bytes)
17/10/26 21:28:28 INFO TaskSetManager: Starting task 1.0 in stage 16.0 (TID 35, localhost, executor driver, partition 1, PROCESS_LOCAL, 12203 bytes)
17/10/26 21:28:28 INFO TaskSetManager: Starting task 2.0 in stage 16.0 (TID 36, localhost, executor driver, partition 2, PROCESS_LOCAL, 12203 bytes)
17/10/26 21:28:28 INFO TaskSetManager: Starting task 3.0 in stage 16.0 (TID 37, localhost, executor driver, partition 3, PROCESS_LOCAL, 12203 bytes)
17/10/26 21:28:28 INFO Executor: Running task 3.0 in stage 16.0 (TID 37)
17/10/26 21:28:28 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
17/10/26 21:28:28 INFO Executor: Running task 1.0 in stage 16.0 (TID 35)
17/10/26 21:28:28 INFO Executor: Running task 2.0 in stage 16.0 (TID 36)
17/10/26 21:28:28 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_d6d912388d578693cd8fbc0a7c12f020340a2114a51f6b37b71ae3bab7faf8f3.csv, range: 140545296-183199425, partition values: [empty row]
17/10/26 21:28:28 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_d6d912388d578693cd8fbc0a7c12f020340a2114a51f6b37b71ae3bab7faf8f3.csv, range: 93696864-140545296, partition values: [empty row]
17/10/26 21:28:28 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_d6d912388d578693cd8fbc0a7c12f020340a2114a51f6b37b71ae3bab7faf8f3.csv, range: 0-46848432, partition values: [empty row]
17/10/26 21:28:28 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpS4VNxm/spark_serialize_d6d912388d578693cd8fbc0a7c12f020340a2114a51f6b37b71ae3bab7faf8f3.csv, range: 46848432-93696864, partition values: [empty row]
17/10/26 21:28:28 INFO CodeGenerator: Code generated in 19.896675 ms
17/10/26 21:28:28 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:56955 in memory (size: 4.6 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 1302
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:56955 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 1248
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 1249
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:56955 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:56955 in memory (size: 9.4 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 21:28:29 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:56955 in memory (size: 11.2 KB, free: 265.4 MB)
17/10/26 21:28:29 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 21:28:29 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 21:28:34 INFO MemoryStore: Block rdd_82_3 stored as values in memory (estimated size 15.0 MB, free 249.2 MB)
17/10/26 21:28:34 INFO BlockManagerInfo: Added rdd_82_3 in memory on 127.0.0.1:56955 (size: 15.0 MB, free: 250.4 MB)
17/10/26 21:28:34 INFO Executor: Finished task 3.0 in stage 16.0 (TID 37). 2980 bytes result sent to driver
17/10/26 21:28:34 INFO TaskSetManager: Finished task 3.0 in stage 16.0 (TID 37) in 5886 ms on localhost (executor driver) (1/4)
17/10/26 21:28:35 INFO MemoryStore: Block rdd_82_0 stored as values in memory (estimated size 16.2 MB, free 233.0 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added rdd_82_0 in memory on 127.0.0.1:56955 (size: 16.2 MB, free: 234.2 MB)
17/10/26 21:28:35 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 2893 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 6375 ms on localhost (executor driver) (2/4)
17/10/26 21:28:35 INFO MemoryStore: Block rdd_82_1 stored as values in memory (estimated size 15.8 MB, free 217.2 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added rdd_82_1 in memory on 127.0.0.1:56955 (size: 15.8 MB, free: 218.4 MB)
17/10/26 21:28:35 INFO Executor: Finished task 1.0 in stage 16.0 (TID 35). 2893 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 1.0 in stage 16.0 (TID 35) in 6492 ms on localhost (executor driver) (3/4)
17/10/26 21:28:35 INFO MemoryStore: Block rdd_82_2 stored as values in memory (estimated size 16.2 MB, free 201.0 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added rdd_82_2 in memory on 127.0.0.1:56955 (size: 16.2 MB, free: 202.2 MB)
17/10/26 21:28:35 INFO Executor: Finished task 2.0 in stage 16.0 (TID 36). 2983 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 2.0 in stage 16.0 (TID 36) in 6617 ms on localhost (executor driver) (4/4)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 21:28:35 INFO DAGScheduler: ShuffleMapStage 16 (sql at <unknown>:0) finished in 6.618 s
17/10/26 21:28:35 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:28:35 INFO DAGScheduler: running: Set()
17/10/26 21:28:35 INFO DAGScheduler: waiting: Set(ResultStage 17)
17/10/26 21:28:35 INFO DAGScheduler: failed: Set()
17/10/26 21:28:35 INFO DAGScheduler: Submitting ResultStage 17 (MapPartitionsRDD[88] at sql at <unknown>:0), which has no missing parents
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 7.0 KB, free 201.0 MB)
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 3.7 KB, free 201.0 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 202.2 MB)
17/10/26 21:28:35 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (MapPartitionsRDD[88] at sql at <unknown>:0)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 21:28:35 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 38, localhost, executor driver, partition 0, ANY, 11480 bytes)
17/10/26 21:28:35 INFO Executor: Running task 0.0 in stage 17.0 (TID 38)
17/10/26 21:28:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:28:35 INFO Executor: Finished task 0.0 in stage 17.0 (TID 38). 1873 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 38) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 21:28:35 INFO DAGScheduler: ResultStage 17 (sql at <unknown>:0) finished in 0.006 s
17/10/26 21:28:35 INFO DAGScheduler: Job 10 finished: sql at <unknown>:0, took 6.633346 s
17/10/26 21:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:35 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan_payment`
17/10/26 21:28:35 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 21:28:35 INFO DAGScheduler: Registering RDD 92 (collect at utils.scala:196)
17/10/26 21:28:35 INFO DAGScheduler: Got job 11 (collect at utils.scala:196) with 1 output partitions
17/10/26 21:28:35 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/10/26 21:28:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 18)
17/10/26 21:28:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 18)
17/10/26 21:28:35 INFO DAGScheduler: Submitting ShuffleMapStage 18 (MapPartitionsRDD[92] at collect at utils.scala:196), which has no missing parents
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 32.8 KB, free 200.9 MB)
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 13.1 KB, free 200.9 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:56955 (size: 13.1 KB, free: 202.2 MB)
17/10/26 21:28:35 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 18 (MapPartitionsRDD[92] at collect at utils.scala:196)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Adding task set 18.0 with 4 tasks
17/10/26 21:28:35 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 39, localhost, executor driver, partition 0, PROCESS_LOCAL, 12195 bytes)
17/10/26 21:28:35 INFO TaskSetManager: Starting task 1.0 in stage 18.0 (TID 40, localhost, executor driver, partition 1, PROCESS_LOCAL, 12195 bytes)
17/10/26 21:28:35 INFO TaskSetManager: Starting task 2.0 in stage 18.0 (TID 41, localhost, executor driver, partition 2, PROCESS_LOCAL, 12195 bytes)
17/10/26 21:28:35 INFO TaskSetManager: Starting task 3.0 in stage 18.0 (TID 42, localhost, executor driver, partition 3, PROCESS_LOCAL, 12195 bytes)
17/10/26 21:28:35 INFO Executor: Running task 1.0 in stage 18.0 (TID 40)
17/10/26 21:28:35 INFO Executor: Running task 0.0 in stage 18.0 (TID 39)
17/10/26 21:28:35 INFO Executor: Running task 2.0 in stage 18.0 (TID 41)
17/10/26 21:28:35 INFO Executor: Running task 3.0 in stage 18.0 (TID 42)
17/10/26 21:28:35 INFO BlockManager: Found block rdd_82_1 locally
17/10/26 21:28:35 INFO BlockManager: Found block rdd_82_3 locally
17/10/26 21:28:35 INFO BlockManager: Found block rdd_82_2 locally
17/10/26 21:28:35 INFO BlockManager: Found block rdd_82_0 locally
17/10/26 21:28:35 INFO Executor: Finished task 2.0 in stage 18.0 (TID 41). 2098 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 2.0 in stage 18.0 (TID 41) in 24 ms on localhost (executor driver) (1/4)
17/10/26 21:28:35 INFO Executor: Finished task 3.0 in stage 18.0 (TID 42). 2019 bytes result sent to driver
17/10/26 21:28:35 INFO Executor: Finished task 1.0 in stage 18.0 (TID 40). 2106 bytes result sent to driver
17/10/26 21:28:35 INFO TaskSetManager: Finished task 3.0 in stage 18.0 (TID 42) in 31 ms on localhost (executor driver) (2/4)
17/10/26 21:28:35 INFO TaskSetManager: Finished task 1.0 in stage 18.0 (TID 40) in 32 ms on localhost (executor driver) (3/4)
17/10/26 21:28:35 INFO Executor: Finished task 0.0 in stage 18.0 (TID 39). 2109 bytes result sent to driver
17/10/26 21:28:35 INFO DAGScheduler: ShuffleMapStage 18 (collect at utils.scala:196) finished in 0.182 s
17/10/26 21:28:35 INFO DAGScheduler: looking for newly runnable stages
17/10/26 21:28:35 INFO DAGScheduler: running: Set()
17/10/26 21:28:35 INFO DAGScheduler: waiting: Set(ResultStage 19)
17/10/26 21:28:35 INFO DAGScheduler: failed: Set()
17/10/26 21:28:35 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[95] at collect at utils.scala:196), which has no missing parents
17/10/26 21:28:35 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 39) in 181 ms on localhost (executor driver) (4/4)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_23 stored as values in memory (estimated size 7.0 KB, free 200.9 MB)
17/10/26 21:28:35 INFO MemoryStore: Block broadcast_23_piece0 stored as bytes in memory (estimated size 3.7 KB, free 200.9 MB)
17/10/26 21:28:35 INFO BlockManagerInfo: Added broadcast_23_piece0 in memory on 127.0.0.1:56955 (size: 3.7 KB, free: 202.2 MB)
17/10/26 21:28:35 INFO SparkContext: Created broadcast 23 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:35 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[95] at collect at utils.scala:196)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/10/26 21:28:35 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 43, localhost, executor driver, partition 0, ANY, 11472 bytes)
17/10/26 21:28:35 INFO Executor: Running task 0.0 in stage 19.0 (TID 43)
17/10/26 21:28:35 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 21:28:35 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 21:28:35 INFO Executor: Finished task 0.0 in stage 19.0 (TID 43). 1952 bytes result sent to driver
17/10/26 21:28:35 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.005 s
17/10/26 21:28:35 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 43) in 5 ms on localhost (executor driver) (1/1)
17/10/26 21:28:35 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/10/26 21:28:35 INFO DAGScheduler: Job 11 finished: collect at utils.scala:196, took 0.197281 s
17/10/26 21:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:35 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan_payment` AS `zzz4`
WHERE (0 = 1)
17/10/26 21:28:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:35 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 21:28:35 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:28:35 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:28:35 INFO HiveMetaStore: 0: get_database: default
17/10/26 21:28:35 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 21:28:35 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 21:28:35 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 21:28:55 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:28:55 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 21:28:55 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 21:28:55 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 21:28:55 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_731444172
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 21:28:55 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 21:28:55 INFO DAGScheduler: Got job 12 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 21:28:55 INFO DAGScheduler: Final stage: ResultStage 20 (collect at SpreadRDDBuilder.scala:105)
17/10/26 21:28:55 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:28:55 INFO DAGScheduler: Missing parents: List()
17/10/26 21:28:55 INFO DAGScheduler: Submitting ResultStage 20 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 21:28:55 INFO MemoryStore: Block broadcast_24 stored as values in memory (estimated size 2.1 KB, free 200.9 MB)
17/10/26 21:28:55 INFO MemoryStore: Block broadcast_24_piece0 stored as bytes in memory (estimated size 1361.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added broadcast_24_piece0 in memory on 127.0.0.1:56955 (size: 1361.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO SparkContext: Created broadcast 24 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:55 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 20 (MapPartitionsRDD[98] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 21:28:55 INFO TaskSchedulerImpl: Adding task set 20.0 with 11 tasks
17/10/26 21:28:55 INFO TaskSetManager: Starting task 0.0 in stage 20.0 (TID 44, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 1.0 in stage 20.0 (TID 45, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 2.0 in stage 20.0 (TID 46, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 3.0 in stage 20.0 (TID 47, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO Executor: Running task 0.0 in stage 20.0 (TID 44)
17/10/26 21:28:55 INFO Executor: Running task 1.0 in stage 20.0 (TID 45)
17/10/26 21:28:55 INFO Executor: Running task 3.0 in stage 20.0 (TID 47)
17/10/26 21:28:55 INFO Executor: Running task 2.0 in stage 20.0 (TID 46)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_1 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_3 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_2 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_1 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_3 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_2 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_0 stored as values in memory (estimated size 16.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_0 in memory on 127.0.0.1:56955 (size: 16.0 B, free: 202.2 MB)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 47:
[rdd_97_3]
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_97_2]
17/10/26 21:28:55 INFO Executor: Finished task 2.0 in stage 20.0 (TID 46). 1627 bytes result sent to driver
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 45:
[rdd_97_1]
17/10/26 21:28:55 INFO Executor: Finished task 3.0 in stage 20.0 (TID 47). 1627 bytes result sent to driver
17/10/26 21:28:55 INFO Executor: Finished task 1.0 in stage 20.0 (TID 45). 1706 bytes result sent to driver
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 44:
[rdd_97_0]
17/10/26 21:28:55 INFO Executor: Finished task 0.0 in stage 20.0 (TID 44). 1627 bytes result sent to driver
17/10/26 21:28:55 INFO TaskSetManager: Starting task 4.0 in stage 20.0 (TID 48, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO Executor: Running task 4.0 in stage 20.0 (TID 48)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 5.0 in stage 20.0 (TID 49, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO Executor: Running task 5.0 in stage 20.0 (TID 49)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 6.0 in stage 20.0 (TID 50, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 7.0 in stage 20.0 (TID 51, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 1.0 in stage 20.0 (TID 45) in 55 ms on localhost (executor driver) (1/11)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 0.0 in stage 20.0 (TID 44) in 78 ms on localhost (executor driver) (2/11)
17/10/26 21:28:55 INFO Executor: Running task 6.0 in stage 20.0 (TID 50)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 2.0 in stage 20.0 (TID 46) in 56 ms on localhost (executor driver) (3/11)
17/10/26 21:28:55 INFO Executor: Running task 7.0 in stage 20.0 (TID 51)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 3.0 in stage 20.0 (TID 47) in 57 ms on localhost (executor driver) (4/11)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_4 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_4 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_5 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_6 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_5 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_6 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 48:
[rdd_97_4]
17/10/26 21:28:55 INFO Executor: Finished task 4.0 in stage 20.0 (TID 48). 1627 bytes result sent to driver
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 49:
[rdd_97_5]
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_7 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 50:
[rdd_97_6]
17/10/26 21:28:55 INFO Executor: Finished task 6.0 in stage 20.0 (TID 50). 1627 bytes result sent to driver
17/10/26 21:28:55 INFO TaskSetManager: Starting task 8.0 in stage 20.0 (TID 52, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO Executor: Finished task 5.0 in stage 20.0 (TID 49). 1706 bytes result sent to driver
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_7 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 9.0 in stage 20.0 (TID 53, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Starting task 10.0 in stage 20.0 (TID 54, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 6.0 in stage 20.0 (TID 50) in 19 ms on localhost (executor driver) (5/11)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 51:
[rdd_97_7]
17/10/26 21:28:55 INFO Executor: Running task 9.0 in stage 20.0 (TID 53)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 4.0 in stage 20.0 (TID 48) in 22 ms on localhost (executor driver) (6/11)
17/10/26 21:28:55 INFO Executor: Running task 10.0 in stage 20.0 (TID 54)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 5.0 in stage 20.0 (TID 49) in 24 ms on localhost (executor driver) (7/11)
17/10/26 21:28:55 INFO Executor: Running task 8.0 in stage 20.0 (TID 52)
17/10/26 21:28:55 INFO Executor: Finished task 7.0 in stage 20.0 (TID 51). 1627 bytes result sent to driver
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_9 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_10 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_9 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_10 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 7.0 in stage 20.0 (TID 51) in 30 ms on localhost (executor driver) (8/11)
17/10/26 21:28:55 INFO MemoryStore: Block rdd_97_8 stored as values in memory (estimated size 24.0 B, free 200.9 MB)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 53:
[rdd_97_9]
17/10/26 21:28:55 INFO Executor: Finished task 9.0 in stage 20.0 (TID 53). 1627 bytes result sent to driver
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 54:
[rdd_97_10]
17/10/26 21:28:55 INFO Executor: Finished task 10.0 in stage 20.0 (TID 54). 1627 bytes result sent to driver
17/10/26 21:28:55 INFO BlockManagerInfo: Added rdd_97_8 in memory on 127.0.0.1:56955 (size: 24.0 B, free: 202.2 MB)
17/10/26 21:28:55 WARN Executor: 1 block locks were not released by TID = 52:
[rdd_97_8]
17/10/26 21:28:55 INFO TaskSetManager: Finished task 9.0 in stage 20.0 (TID 53) in 19 ms on localhost (executor driver) (9/11)
17/10/26 21:28:55 INFO TaskSetManager: Finished task 10.0 in stage 20.0 (TID 54) in 17 ms on localhost (executor driver) (10/11)
17/10/26 21:28:55 INFO Executor: Finished task 8.0 in stage 20.0 (TID 52). 1717 bytes result sent to driver
17/10/26 21:28:55 INFO TaskSetManager: Finished task 8.0 in stage 20.0 (TID 52) in 22 ms on localhost (executor driver) (11/11)
17/10/26 21:28:55 INFO TaskSchedulerImpl: Removed TaskSet 20.0, whose tasks have all completed, from pool 
17/10/26 21:28:55 INFO DAGScheduler: ResultStage 20 (collect at SpreadRDDBuilder.scala:105) finished in 0.114 s
17/10/26 21:28:55 INFO DAGScheduler: Job 12 finished: collect at SpreadRDDBuilder.scala:105, took 0.117842 s
17/10/26 21:28:55 INFO ParallelCollectionRDD: Removing RDD 97 from persistence list
17/10/26 21:28:55 INFO BlockManager: Removing RDD 97
17/10/26 21:28:55 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 21:28:55 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 21:28:56 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 21:28:56 INFO DAGScheduler: Got job 13 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 21:28:56 INFO DAGScheduler: Final stage: ResultStage 21 (collect at InternalBackendUtils.scala:163)
17/10/26 21:28:56 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:28:56 INFO DAGScheduler: Missing parents: List()
17/10/26 21:28:56 INFO DAGScheduler: Submitting ResultStage 21 (MapPartitionsRDD[100] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 21:28:56 INFO MemoryStore: Block broadcast_25 stored as values in memory (estimated size 3.0 KB, free 200.9 MB)
17/10/26 21:28:56 INFO MemoryStore: Block broadcast_25_piece0 stored as bytes in memory (estimated size 1949.0 B, free 200.9 MB)
17/10/26 21:28:56 INFO BlockManagerInfo: Added broadcast_25_piece0 in memory on 127.0.0.1:56955 (size: 1949.0 B, free: 202.2 MB)
17/10/26 21:28:56 INFO SparkContext: Created broadcast 25 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:56 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 21 (MapPartitionsRDD[100] at map at InternalBackendUtils.scala:100)
17/10/26 21:28:56 INFO TaskSchedulerImpl: Adding task set 21.0 with 1 tasks
17/10/26 21:28:56 INFO TaskSetManager: Starting task 0.0 in stage 21.0 (TID 55, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 21:28:56 INFO Executor: Running task 0.0 in stage 21.0 (TID 55)
17/10/26 21:28:57 INFO Reflections: Reflections took 988 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 21:28:57 INFO BlockManagerInfo: Removed broadcast_23_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 202.2 MB)
17/10/26 21:28:57 INFO BlockManager: Removing RDD 97
17/10/26 21:28:57 INFO ContextCleaner: Cleaned RDD 97
17/10/26 21:28:57 INFO BlockManagerInfo: Removed broadcast_24_piece0 on 127.0.0.1:56955 in memory (size: 1361.0 B, free: 202.2 MB)
17/10/26 21:28:57 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:56955 in memory (size: 3.7 KB, free: 202.2 MB)
17/10/26 21:28:57 INFO ContextCleaner: Cleaned accumulator 1483
17/10/26 21:28:57 INFO BlockManagerInfo: Removed broadcast_22_piece0 on 127.0.0.1:56955 in memory (size: 13.1 KB, free: 202.2 MB)
17/10/26 21:28:57 INFO Reflections: Reflections took 143 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 21:28:58 INFO Server: jetty-8.1.17.v20150415
17/10/26 21:28:58 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54323
17/10/26 21:28:59 INFO Executor: Finished task 0.0 in stage 21.0 (TID 55). 1444 bytes result sent to driver
17/10/26 21:28:59 INFO TaskSetManager: Finished task 0.0 in stage 21.0 (TID 55) in 3091 ms on localhost (executor driver) (1/1)
17/10/26 21:28:59 INFO TaskSchedulerImpl: Removed TaskSet 21.0, whose tasks have all completed, from pool 
17/10/26 21:28:59 INFO DAGScheduler: ResultStage 21 (collect at InternalBackendUtils.scala:163) finished in 3.091 s
17/10/26 21:28:59 INFO DAGScheduler: Job 13 finished: collect at InternalBackendUtils.scala:163, took 3.096282 s
17/10/26 21:28:59 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 21:28:59 INFO DAGScheduler: Got job 14 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 21:28:59 INFO DAGScheduler: Final stage: ResultStage 22 (foreach at InternalBackendUtils.scala:175)
17/10/26 21:28:59 INFO DAGScheduler: Parents of final stage: List()
17/10/26 21:28:59 INFO DAGScheduler: Missing parents: List()
17/10/26 21:28:59 INFO DAGScheduler: Submitting ResultStage 22 (InvokeOnNodesRDD[99] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 21:28:59 INFO MemoryStore: Block broadcast_26 stored as values in memory (estimated size 1672.0 B, free 201.0 MB)
17/10/26 21:28:59 INFO MemoryStore: Block broadcast_26_piece0 stored as bytes in memory (estimated size 1161.0 B, free 201.0 MB)
17/10/26 21:28:59 INFO BlockManagerInfo: Added broadcast_26_piece0 in memory on 127.0.0.1:56955 (size: 1161.0 B, free: 202.2 MB)
17/10/26 21:28:59 INFO SparkContext: Created broadcast 26 from broadcast at DAGScheduler.scala:996
17/10/26 21:28:59 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 22 (InvokeOnNodesRDD[99] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 21:28:59 INFO TaskSchedulerImpl: Adding task set 22.0 with 1 tasks
17/10/26 21:28:59 INFO TaskSetManager: Starting task 0.0 in stage 22.0 (TID 56, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 21:28:59 INFO Executor: Running task 0.0 in stage 22.0 (TID 56)
17/10/26 21:28:59 INFO Executor: Finished task 0.0 in stage 22.0 (TID 56). 764 bytes result sent to driver
17/10/26 21:28:59 INFO TaskSetManager: Finished task 0.0 in stage 22.0 (TID 56) in 4 ms on localhost (executor driver) (1/1)
17/10/26 21:28:59 INFO TaskSchedulerImpl: Removed TaskSet 22.0, whose tasks have all completed, from pool 
17/10/26 21:28:59 INFO DAGScheduler: ResultStage 22 (foreach at InternalBackendUtils.scala:175) finished in 0.005 s
17/10/26 21:28:59 INFO DAGScheduler: Job 14 finished: foreach at InternalBackendUtils.scala:175, took 0.008129 s
17/10/26 21:29:00 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 21:29:01 INFO BlockManagerInfo: Removed broadcast_26_piece0 on 127.0.0.1:56955 in memory (size: 1161.0 B, free: 202.2 MB)
17/10/26 21:29:04 INFO BlockManagerInfo: Removed broadcast_25_piece0 on 127.0.0.1:56955 in memory (size: 1949.0 B, free: 202.2 MB)
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1952
17/10/26 21:29:04 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:56955 in memory (size: 13.1 KB, free: 202.2 MB)
17/10/26 21:29:04 INFO ContextCleaner: Cleaned shuffle 6
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1314
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1313
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1312
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1311
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1310
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1309
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1308
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1307
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1306
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1305
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1304
17/10/26 21:29:04 INFO ContextCleaner: Cleaned accumulator 1303
17/10/26 21:29:13 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_731444172
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54323)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54323 (CMD + click in Mac OSX)
    
17/10/26 21:32:44 INFO ContextHandler: stopped o.e.j.s.ServletContextHandler{/,null}
17/10/26 21:32:44 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 21:32:44 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 21:32:44 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 21:32:45 INFO MemoryStore: MemoryStore cleared
17/10/26 21:32:45 INFO BlockManager: BlockManager stopped
17/10/26 21:32:45 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 21:32:45 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 21:32:45 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 21:32:45 INFO SparkContext: Successfully stopped SparkContext
17/10/26 21:32:45 INFO ShutdownHookManager: Shutdown hook called
17/10/26 21:32:45 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54
17/10/26 21:32:45 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\userFiles-cc5e456d-cd59-4749-aa4c-01ff95beed54
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 21:32:45 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40
17/10/26 21:32:45 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 21:32:45 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\repl-f3badd47-ae30-4fca-abcd-660620780a2a
17/10/26 21:32:45 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-c131949e-05e3-4f37-8a76-43e8f2b23c40\repl-b9da38a1-bc1f-4e36-b7bf-c0eb6f1857e1
