17/10/26 11:12:19 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:12:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:12:19 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:12:19 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:12:20 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:12:20 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:12:20 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:12:20 INFO Utils: Successfully started service 'sparkDriver' on port 64462.
17/10/26 11:12:20 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:12:20 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:12:20 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-7e94fa26-ff15-476c-a22d-4bf96915d5df
17/10/26 11:12:20 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:12:20 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:12:20 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:12:20 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:12:20 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64462/jars/sparklyr-2.1-2.11.jar with timestamp 1508983940590
17/10/26 11:12:20 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:12:20 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64483.
17/10/26 11:12:20 INFO NettyBlockTransferService: Server created on 127.0.0.1:64483
17/10/26 11:12:20 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:12:20 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64483 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:20 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64483, None)
17/10/26 11:12:22 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:12:22 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:12:22 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:12:24 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:12:24 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:12:25 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:12:25 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:12:28 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:12:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:29 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:30 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:12:30 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:12:30 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:12:30 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:12:31 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:12:31 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:12:32 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:12:32 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:12:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:12:32 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:12:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:12:32 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:12:32 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/870b007d-2d62-45e0-8217-faf8f9f71e31_resources
17/10/26 11:12:32 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/870b007d-2d62-45e0-8217-faf8f9f71e31
17/10/26 11:12:33 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/870b007d-2d62-45e0-8217-faf8f9f71e31
17/10/26 11:12:33 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/870b007d-2d62-45e0-8217-faf8f9f71e31/_tmp_space.db
17/10/26 11:12:33 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:12:33 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:33 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:33 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:12:33 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:12:33 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:12:33 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:12:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:12:39 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:12:39 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:12:39 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:13:08 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:13:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:13:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:13:09 INFO MemoryStore: MemoryStore cleared
17/10/26 11:13:09 INFO BlockManager: BlockManager stopped
17/10/26 11:13:09 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:13:09 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:13:09 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:13:09 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:13:09 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-fcc72061-2071-4fc4-9f02-c40dff673499
17/10/26 11:13:39 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:13:39 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:13:39 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:13:39 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:13:39 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:13:39 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:13:39 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:13:39 INFO Utils: Successfully started service 'sparkDriver' on port 64593.
17/10/26 11:13:39 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:13:40 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:13:40 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-b32c2790-5e80-4bc2-a702-e1a36981fd49
17/10/26 11:13:40 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:13:40 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:13:40 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:13:40 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:13:40 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar with timestamp 1508984020397
17/10/26 11:13:40 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:13:40 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 64615.
17/10/26 11:13:40 INFO NettyBlockTransferService: Server created on 127.0.0.1:64615
17/10/26 11:13:40 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:13:40 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:64615 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:40 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 64615, None)
17/10/26 11:13:41 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:13:41 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:13:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:13:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:13:41 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:13:41 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:13:41 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:13:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:44 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:13:44 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:13:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:13:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:13:45 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:13:45 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:13:45 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:13:45 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:13:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:13:45 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:13:45 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:13:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:13:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/0952b4da-6c2f-4425-be18-443d5516be6f_resources
17/10/26 11:13:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0952b4da-6c2f-4425-be18-443d5516be6f
17/10/26 11:13:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/0952b4da-6c2f-4425-be18-443d5516be6f
17/10/26 11:13:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/0952b4da-6c2f-4425-be18-443d5516be6f/_tmp_space.db
17/10/26 11:13:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:13:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:46 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:13:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:13:46 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:13:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:13:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:13:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:13:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:13:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:26:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:26 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:26:26 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:26:26 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:26:27 INFO CodeGenerator: Code generated in 401.853725 ms
17/10/26 11:26:28 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:26:28 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:26:28 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:26:28 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:26:28 INFO DAGScheduler: Missing parents: List()
17/10/26 11:26:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/26 11:26:29 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:26:29 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:26:29 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:26:29 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:26:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/26 11:26:29 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:26:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 6042 bytes)
17/10/26 11:26:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:26:29 INFO Executor: Fetching spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar with timestamp 1508984020397
17/10/26 11:26:29 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:64593 after 50 ms (0 ms spent in bootstraps)
17/10/26 11:26:29 INFO Utils: Fetching spark://127.0.0.1:64593/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58\fetchFileTemp4993423065593793364.tmp
17/10/26 11:26:30 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-6104894c-0bb7-412c-a699-2dc0f02f4499/userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:26:30 INFO CodeGenerator: Code generated in 12.634089 ms
17/10/26 11:26:30 INFO CodeGenerator: Code generated in 13.814413 ms
17/10/26 11:26:30 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 11:26:30 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 1496 ms on localhost (executor driver) (1/1)
17/10/26 11:26:30 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:26:30 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 1.594 s
17/10/26 11:26:31 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 2.428761 s
17/10/26 11:26:53 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:26:54 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:26:54 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:26:54 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:26:54 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:26:54 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:26:54 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:26:54 INFO CodeGenerator: Code generated in 8.718491 ms
17/10/26 11:26:55 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 293.3 KB, free 366.0 MB)
17/10/26 11:26:55 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 23.9 KB, free 366.0 MB)
17/10/26 11:26:55 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 366.3 MB)
17/10/26 11:26:55 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:26:56 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:26:57 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 41.231806 ms
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 11.004214 ms
17/10/26 11:26:57 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:26:57 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:26:57 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:26:57 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:26:57 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:26:57 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:26:57 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 366.0 MB)
17/10/26 11:26:57 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:64615 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:26:57 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:26:57 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:26:57 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:26:57 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:26:57 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:26:57 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:26:57 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:26:57 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:26:57 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_e7ab0fa94b4f75fe98dd67e8d02cc427126ed5742d342b06ceab9d2ed6f9c871.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:26:57 INFO CodeGenerator: Code generated in 25.195306 ms
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:27:01 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 15.4 MB, free 350.6 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:64615 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 4.869607 ms
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 75.236436 ms
17/10/26 11:27:02 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 3070 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 5241 ms on localhost (executor driver) (1/4)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:27:02 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 5303 ms on localhost (executor driver) (2/4)
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2980 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 5316 ms on localhost (executor driver) (3/4)
17/10/26 11:27:02 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:64615 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:27:02 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 11:27:02 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 5.353 s
17/10/26 11:27:02 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 5347 ms on localhost (executor driver) (4/4)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:02 INFO DAGScheduler: running: Set()
17/10/26 11:27:02 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:27:02 INFO DAGScheduler: failed: Set()
17/10/26 11:27:02 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 2039 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 93 ms on localhost (executor driver) (1/1)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.094 s
17/10/26 11:27:02 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 5.608583 s
17/10/26 11:27:02 INFO CodeGenerator: Code generated in 6.887962 ms
17/10/26 11:27:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:02 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:27:02 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:02 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/26 11:27:02 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:02 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:27:02 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:27:02 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:27:02 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:64615 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:27:02 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 6668 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:27:02 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:27:02 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_2 locally
17/10/26 11:27:02 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_3 locally
17/10/26 11:27:02 INFO BlockManager: Found block rdd_11_1 locally
17/10/26 11:27:02 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/26 11:27:02 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 49 ms on localhost (executor driver) (1/4)
17/10/26 11:27:02 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 47 ms on localhost (executor driver) (2/4)
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 55 ms on localhost (executor driver) (3/4)
17/10/26 11:27:02 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2019 bytes result sent to driver
17/10/26 11:27:02 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 58 ms on localhost (executor driver) (4/4)
17/10/26 11:27:02 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.061 s
17/10/26 11:27:02 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:02 INFO DAGScheduler: running: Set()
17/10/26 11:27:02 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:27:02 INFO DAGScheduler: failed: Set()
17/10/26 11:27:02 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:27:02 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:27:02 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:27:02 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:27:02 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:02 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/26 11:27:02 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:27:02 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 5945 bytes)
17/10/26 11:27:02 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:02 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:27:02 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 11:27:02 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:27:02 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.096795 s
17/10/26 11:27:02 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz1`
WHERE (0 = 1)
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 INFO CodeGenerator: Code generated in 8.664606 ms
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:03 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:03 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:03 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:27:03 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:27:03 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:27:03 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:27:03 INFO DAGScheduler: Missing parents: List()
17/10/26 11:27:03 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:55), which has no missing parents
17/10/26 11:27:03 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:27:03 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:27:03 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:27:03 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:03 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at map at utils.scala:55)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:27:03 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 6353 bytes)
17/10/26 11:27:03 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:27:03 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 11:27:03 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.012 s
17/10/26 11:27:03 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.017988 s
17/10/26 11:27:03 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 11:27:03 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:27:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:27:16 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:27:16 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:27:16 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:27:16 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:27:16 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:27:16 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 293.3 KB, free 295.5 MB)
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 23.9 KB, free 295.5 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:27:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:17 INFO DAGScheduler: Registering RDD 40 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:27:17 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:27:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:27:17 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.5 MB)
17/10/26 11:27:17 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.5 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:64615 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:17 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:27:17 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 6676 bytes)
17/10/26 11:27:17 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:27:17 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:27:17 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:27:17 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:27:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_48eccca020941d1ba366877fbda4654a125d9d8bd8a60ac45812cdcdac4100d2.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:27:17 INFO CodeGenerator: Code generated in 21.190927 ms
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:64615 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:27:17 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:27:17 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:27:18 INFO MemoryStore: Block rdd_37_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:27:18 INFO BlockManagerInfo: Added rdd_37_3 in memory on 127.0.0.1:64615 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:27:18 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/26 11:27:18 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1626 ms on localhost (executor driver) (1/4)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_1 stored as values in memory (estimated size 7.1 MB, free 283.3 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_1 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 284.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_2 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_2 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:27:19 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2132 ms on localhost (executor driver) (2/4)
17/10/26 11:27:19 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2134 ms on localhost (executor driver) (3/4)
17/10/26 11:27:19 INFO MemoryStore: Block rdd_37_0 stored as values in memory (estimated size 7.1 MB, free 269.1 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added rdd_37_0 in memory on 127.0.0.1:64615 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2980 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2182 ms on localhost (executor driver) (4/4)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.184 s
17/10/26 11:27:19 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:19 INFO DAGScheduler: running: Set()
17/10/26 11:27:19 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:27:19 INFO DAGScheduler: failed: Set()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.1 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.1 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[43] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 5953 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.207284 s
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:27:19 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:19 INFO DAGScheduler: Registering RDD 47 (collect at utils.scala:196)
17/10/26 11:27:19 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:19 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:27:19 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:27:19 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:27:19 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.3 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:64615 (size: 9.3 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 6669 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:27:19 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:27:19 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:27:19 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_2 locally
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_1 locally
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_0 locally
17/10/26 11:27:19 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/26 11:27:19 INFO BlockManager: Found block rdd_37_3 locally
17/10/26 11:27:19 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 32 ms on localhost (executor driver) (1/4)
17/10/26 11:27:19 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2019 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 38 ms on localhost (executor driver) (2/4)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2098 bytes result sent to driver
17/10/26 11:27:19 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2109 bytes result sent to driver
17/10/26 11:27:19 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 47 ms on localhost (executor driver) (3/4)
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 51 ms on localhost (executor driver) (4/4)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.052 s
17/10/26 11:27:19 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:19 INFO DAGScheduler: running: Set()
17/10/26 11:27:19 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:27:19 INFO DAGScheduler: failed: Set()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[50] at collect at utils.scala:196)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 5946 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:19 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.006 s
17/10/26 11:27:19 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.070712 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz2`
WHERE (0 = 1)
17/10/26 11:27:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:19 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:19 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:19 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:27:19 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:27:19 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:27:19 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:27:19 INFO DAGScheduler: Missing parents: List()
17/10/26 11:27:19 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[56] at map at utils.scala:55), which has no missing parents
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:27:19 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:27:19 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:64615 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:27:19 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:19 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[56] at map at utils.scala:55)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:27:19 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 6408 bytes)
17/10/26 11:27:19 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:27:19 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 11:27:19 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.007 s
17/10/26 11:27:19 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.014412 s
17/10/26 11:27:19 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:27:19 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:27:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:27:21 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:27:21 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:27:21 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:27:21 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:27:21 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:27:21 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:27:21 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 293.3 KB, free 268.7 MB)
17/10/26 11:27:21 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 23.9 KB, free 268.7 MB)
17/10/26 11:27:21 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:64615 (size: 23.9 KB, free: 269.6 MB)
17/10/26 11:27:21 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:21 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:27:22 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:27:22 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:27:22 INFO DAGScheduler: Registering RDD 63 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:27:22 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:27:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:27:22 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.4 KB, free 268.6 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:64615 (size: 19.4 KB, free: 269.6 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[63] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 6677 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:27:22 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:27:22 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:27:22 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:27:22 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d8732fa0a52687a9b4b6b9a4ba4f23bf3c803804a84070a952ed641b1ccf0bf.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:27:22 INFO CodeGenerator: Code generated in 39.167265 ms
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_3 in memory on 127.0.0.1:64615 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2910 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 250 ms on localhost (executor driver) (1/4)
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:64615 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:64615 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:27:22 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:27:22 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:64615 in memory (size: 9.3 KB, free: 269.5 MB)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_1 stored as values in memory (estimated size 1374.8 KB, free 267.1 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_1 in memory on 127.0.0.1:64615 (size: 1374.8 KB, free: 268.1 MB)
17/10/26 11:27:22 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 647 ms on localhost (executor driver) (2/4)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_0 stored as values in memory (estimated size 1296.0 KB, free 265.9 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_0 in memory on 127.0.0.1:64615 (size: 1296.0 KB, free: 266.8 MB)
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 678 ms on localhost (executor driver) (3/4)
17/10/26 11:27:22 INFO MemoryStore: Block rdd_60_2 stored as values in memory (estimated size 1444.5 KB, free 264.5 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added rdd_60_2 in memory on 127.0.0.1:64615 (size: 1444.5 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 697 ms on localhost (executor driver) (4/4)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.700 s
17/10/26 11:27:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:22 INFO DAGScheduler: running: Set()
17/10/26 11:27:22 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:27:22 INFO DAGScheduler: failed: Set()
17/10/26 11:27:22 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[66] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.5 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.5 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[66] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 5954 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 11:27:22 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.717888 s
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:27:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:27:22 INFO DAGScheduler: Registering RDD 70 (collect at utils.scala:196)
17/10/26 11:27:22 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:27:22 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:27:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:27:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:27:22 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[70] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.4 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:64615 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[70] at collect at utils.scala:196)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 6670 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:27:22 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:27:22 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:27:22 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_0 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_3 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_1 locally
17/10/26 11:27:22 INFO BlockManager: Found block rdd_60_2 locally
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 31 ms on localhost (executor driver) (1/4)
17/10/26 11:27:22 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2019 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 33 ms on localhost (executor driver) (2/4)
17/10/26 11:27:22 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2188 bytes result sent to driver
17/10/26 11:27:22 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 37 ms on localhost (executor driver) (3/4)
17/10/26 11:27:22 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2098 bytes result sent to driver
17/10/26 11:27:22 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.046 s
17/10/26 11:27:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:27:22 INFO DAGScheduler: running: Set()
17/10/26 11:27:22 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:27:22 INFO DAGScheduler: failed: Set()
17/10/26 11:27:22 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 44 ms on localhost (executor driver) (4/4)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[73] at collect at utils.scala:196), which has no missing parents
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:27:22 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:27:22 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:64615 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:27:22 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:27:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[73] at collect at utils.scala:196)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:27:22 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 5947 bytes)
17/10/26 11:27:22 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:27:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:27:22 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1960 bytes result sent to driver
17/10/26 11:27:22 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:27:22 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.067163 s
17/10/26 11:27:22 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:27:22 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz3`
WHERE (0 = 1)
17/10/26 11:27:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:23 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:27:23 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:27:23 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
17/10/26 11:27:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:27:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
17/10/26 11:28:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:28:24 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:28:24 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:28:24 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:28:24 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/10/26 11:28:24 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:28:24 INFO DAGScheduler: Missing parents: List()
17/10/26 11:28:24 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
17/10/26 11:28:24 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 23.0 KB, free 264.3 MB)
17/10/26 11:28:24 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.3 MB)
17/10/26 11:28:24 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:64615 (size: 9.8 KB, free: 265.4 MB)
17/10/26 11:28:24 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:28:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[77] at collect at utils.scala:196)
17/10/26 11:28:24 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 11:28:24 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 6595 bytes)
17/10/26 11:28:24 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:28:24 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 11:28:24 INFO CodeGenerator: Code generated in 62.006541 ms
17/10/26 11:28:24 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_11_0]
17/10/26 11:28:24 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 2860 bytes result sent to driver
17/10/26 11:28:24 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 108 ms on localhost (executor driver) (1/1)
17/10/26 11:28:24 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:28:24 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0.109 s
17/10/26 11:28:24 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.115748 s
17/10/26 11:28:24 INFO CodeGenerator: Code generated in 17.369242 ms
17/10/26 11:29:41 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:29:41 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:29:41 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:29:41 INFO MemoryStore: MemoryStore cleared
17/10/26 11:29:41 INFO BlockManager: BlockManager stopped
17/10/26 11:29:41 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:29:41 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:29:41 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:29:41 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:29:41 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:29:41 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
17/10/26 11:29:41 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:29:41 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
17/10/26 11:29:41 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-6104894c-0bb7-412c-a699-2dc0f02f4499\userFiles-2734546f-d212-4653-b72e-f2dd1c3c7e58
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:30:32 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:30:32 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:30:32 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:30:32 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:30:32 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:30:32 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:30:32 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:30:32 INFO Utils: Successfully started service 'sparkDriver' on port 65262.
17/10/26 11:30:32 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:30:32 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:30:32 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:30:32 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:30:32 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-69af9806-99d1-4263-90ce-9620b1bdbc06
17/10/26 11:30:32 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:30:32 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:30:33 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:30:33 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985033145
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985033148
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985033149
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985033151
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985033152
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:33 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar with timestamp 1508985033154
17/10/26 11:30:33 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:30:33 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 65283.
17/10/26 11:30:33 INFO NettyBlockTransferService: Server created on 127.0.0.1:65283
17/10/26 11:30:33 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:30:33 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:65283 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:33 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 65283, None)
17/10/26 11:30:41 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:30:41 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:30:41 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:30:41 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:30:41 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:30:42 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:30:42 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:30:43 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:30:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:44 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:45 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:30:45 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:30:45 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:30:45 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:30:45 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:30:45 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:30:46 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:30:46 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:30:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/6f028488-7bbf-4664-8d80-842b7c2b6b34_resources
17/10/26 11:30:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/6f028488-7bbf-4664-8d80-842b7c2b6b34
17/10/26 11:30:46 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/6f028488-7bbf-4664-8d80-842b7c2b6b34
17/10/26 11:30:46 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/6f028488-7bbf-4664-8d80-842b7c2b6b34/_tmp_space.db
17/10/26 11:30:46 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:46 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:30:46 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:30:46 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:30:46 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:30:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:30:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:30:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:30:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:30:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:30:53 INFO CodeGenerator: Code generated in 271.205681 ms
17/10/26 11:30:53 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:30:53 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:30:53 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:30:53 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:30:53 INFO DAGScheduler: Missing parents: List()
17/10/26 11:30:53 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 11:30:53 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:30:53 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:30:53 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:30:53 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:30:53 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 11:30:53 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:30:53 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 11:30:53 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:30:53 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:53 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:65262 after 18 ms (0 ms spent in bootstraps)
17/10/26 11:30:53 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2742840931220966368.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4459510818799516931.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985033150
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp806323082261986288.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985033149
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5727980669263494518.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6363069439010329908.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985033151
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6456646630038532034.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985033152
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5827752843724667175.tmp
17/10/26 11:30:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 11:30:54 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:54 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2374141353783570734.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985033150
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5459187579081402625.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8318711755761403145.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-io_commons-io-2.4.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3976337685721216165.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8079391995626263115.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7872495369477527078.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7049418588962961197.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9177074596825187002.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985033148
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1575936606421766094.tmp
17/10/26 11:30:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 11:30:55 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985033149
17/10/26 11:30:55 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3109802348462174428.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985033151
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5098455962150965998.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2435543965608014044.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4451874115972699900.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985033151
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2092075019770869602.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985033152
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9102851984076533288.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7673749527030128392.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar with timestamp 1508985033154
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3696092973937146954.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7649542475055932380.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985033153
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2738266663623783929.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar with timestamp 1508985033152
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6910144874801542968.tmp
17/10/26 11:30:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.tukaani_xz-1.5.jar to class loader
17/10/26 11:30:56 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:30:56 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2655093586842437800.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985033151
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4348555572459277080.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6686947476830474629.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2147881421688984089.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3702793189969396276.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985033153
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp598645522178341403.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6456419726235665463.tmp
17/10/26 11:30:57 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 11:30:57 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:57 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5278909898596820882.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985033152
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3784038837263464794.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1080052153816943820.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985033150
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4032381652221548810.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5264299048380423706.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985033151
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp9223159889164206347.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985033153
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2392405958270334718.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985033147
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6484109447926852383.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985033152
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp791593056402977457.tmp
17/10/26 11:30:58 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 11:30:58 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985033149
17/10/26 11:30:58 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2445228675130561356.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985033153
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1876369035523055284.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985033145
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7995274885593316670.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985033147
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6427445503060559425.tmp
17/10/26 11:30:59 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.joda_joda-convert-1.7.jar to class loader
17/10/26 11:30:59 INFO Executor: Fetching spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985033149
17/10/26 11:30:59 INFO Utils: Fetching spark://127.0.0.1:65262/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2054029196635337288.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985033152
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5849724063797702355.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985033150
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1783111062550501170.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985033148
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp3455182515077089237.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985033149
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2844829993012792331.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985033153
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8874064892466738527.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985033152
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7266062966894123961.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985033151
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5631392224240216564.tmp
17/10/26 11:31:00 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:31:00 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985033150
17/10/26 11:31:00 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2903732657095302908.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp6529625397537245116.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985033148
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1686645793607711125.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985033148
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp669141001862117894.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985033152
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2166702723214688091.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7349055150038510692.tmp
17/10/26 11:31:01 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 11:31:01 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985033153
17/10/26 11:31:01 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8708210806227670694.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985033153
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp2890084703183649163.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985033148
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp8165379553186466694.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985033153
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4039885743655703438.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985033146
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp1228569479435347302.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985033147
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp7962072925868012878.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985033152
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp325251362956542388.tmp
17/10/26 11:31:02 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 11:31:02 INFO Executor: Fetching spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985033149
17/10/26 11:31:02 INFO Utils: Fetching spark://127.0.0.1:65262/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp5860663511604687017.tmp
17/10/26 11:31:03 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 11:31:03 INFO Executor: Fetching spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar with timestamp 1508985033149
17/10/26 11:31:03 INFO Utils: Fetching spark://127.0.0.1:65262/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95\fetchFileTemp4429527471070616632.tmp
17/10/26 11:31:03 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d/userFiles-3f123505-a808-402a-b520-68627452ba95/log4j_log4j-1.2.15.jar to class loader
17/10/26 11:31:03 INFO CodeGenerator: Code generated in 17.035672 ms
17/10/26 11:31:03 INFO CodeGenerator: Code generated in 16.152481 ms
17/10/26 11:31:03 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 11:31:03 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 9596 ms on localhost (executor driver) (1/1)
17/10/26 11:31:03 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:31:03 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 9.636 s
17/10/26 11:31:03 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 9.816381 s
17/10/26 11:31:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:31:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:31:26 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:31:26 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:26 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:26 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:31:26 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:26 INFO CodeGenerator: Code generated in 6.430202 ms
17/10/26 11:31:26 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 11:31:26 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 11:31:26 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 366.3 MB)
17/10/26 11:31:26 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:26 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:31:26 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:31:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:26 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 12.906076 ms
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 10.011203 ms
17/10/26 11:31:27 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:27 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:27 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:31:27 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:31:27 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:27 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:31:27 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 11:31:27 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:65283 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:31:27 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:27 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:27 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:31:27 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:27 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:31:27 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:31:27 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:31:27 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:31:27 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_93820afa9c93065835521d9e25f565215a406f3bf1e63cc4fb5e183a7f049a57.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:31:27 INFO CodeGenerator: Code generated in 25.697199 ms
17/10/26 11:31:28 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:31:30 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 11:31:30 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:65283 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:31:30 INFO CodeGenerator: Code generated in 5.044603 ms
17/10/26 11:31:30 INFO CodeGenerator: Code generated in 44.516187 ms
17/10/26 11:31:31 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3897 ms on localhost (executor driver) (1/4)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2983 bytes result sent to driver
17/10/26 11:31:31 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4171 ms on localhost (executor driver) (2/4)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4166 ms on localhost (executor driver) (3/4)
17/10/26 11:31:31 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:65283 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:31:31 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.358 s
17/10/26 11:31:31 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:31 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4352 ms on localhost (executor driver) (4/4)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO DAGScheduler: running: Set()
17/10/26 11:31:31 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:31:31 INFO DAGScheduler: failed: Set()
17/10/26 11:31:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 7 ms
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.045 s
17/10/26 11:31:31 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.467621 s
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 43 ms on localhost (executor driver) (1/1)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO CodeGenerator: Code generated in 7.207676 ms
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:31 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:31:31 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:31 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 11:31:31 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:31 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:31:31 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:31:31 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:31:31 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:65283 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:31:31 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:31:31 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:31:31 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:31:31 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 11:31:31 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2019 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 51 ms on localhost (executor driver) (1/4)
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/26 11:31:31 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2188 bytes result sent to driver
17/10/26 11:31:31 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 63 ms on localhost (executor driver) (2/4)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 68 ms on localhost (executor driver) (3/4)
17/10/26 11:31:31 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2109 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.078 s
17/10/26 11:31:31 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:31 INFO DAGScheduler: running: Set()
17/10/26 11:31:31 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:31:31 INFO DAGScheduler: failed: Set()
17/10/26 11:31:31 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:31:31 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 72 ms on localhost (executor driver) (4/4)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:31:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 11:31:31 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:31:31 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:31:31 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:31 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:31:31 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 11:31:31 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/26 11:31:31 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:31 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.107258 s
17/10/26 11:31:31 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:31 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz4`
WHERE (0 = 1)
17/10/26 11:31:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:32 INFO CodeGenerator: Code generated in 8.774941 ms
17/10/26 11:31:32 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:32 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:32 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:32 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:32 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:31:32 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:31:32 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:31:32 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:31:32 INFO DAGScheduler: Missing parents: List()
17/10/26 11:31:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 11:31:32 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:31:32 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:31:32 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:31:32 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 11:31:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:31:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 11:31:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:31:32 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1069 bytes result sent to driver
17/10/26 11:31:32 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.017 s
17/10/26 11:31:32 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.023656 s
17/10/26 11:31:32 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 16 ms on localhost (executor driver) (1/1)
17/10/26 11:31:32 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:65283 in memory (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:31:45 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:31:45 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:31:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:31:45 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:31:45 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:45 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:45 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:31:45 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.6 MB)
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 296.2 MB)
17/10/26 11:31:45 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:45 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:45 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:45 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:45 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:31:45 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:31:45 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.5 MB)
17/10/26 11:31:45 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.5 MB)
17/10/26 11:31:45 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:65283 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:31:45 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:45 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:45 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:31:45 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:31:45 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:31:45 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:31:45 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:31:45 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:31:45 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_4bbbe317e10aa22bbd6d1f44ff060863c7323967ba4a1d02492ef4405a955478.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:31:45 INFO CodeGenerator: Code generated in 22.687372 ms
17/10/26 11:31:46 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:31:47 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:31:47 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:65283 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:31:47 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2983 bytes result sent to driver
17/10/26 11:31:47 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1907 ms on localhost (executor driver) (1/4)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 283.9 MB)
17/10/26 11:31:48 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2388 ms on localhost (executor driver) (2/4)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 276.1 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:31:48 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:65283 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2426 ms on localhost (executor driver) (3/4)
17/10/26 11:31:48 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2980 bytes result sent to driver
17/10/26 11:31:48 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.431 s
17/10/26 11:31:48 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:48 INFO DAGScheduler: running: Set()
17/10/26 11:31:48 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:31:48 INFO DAGScheduler: failed: Set()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:48 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2429 ms on localhost (executor driver) (4/4)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1960 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 11:31:48 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.455388 s
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:31:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:48 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 11:31:48 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:48 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:31:48 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:31:48 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:31:48 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:65283 (size: 9.4 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:31:48 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:31:48 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:31:48 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 11:31:48 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2188 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 37 ms on localhost (executor driver) (1/4)
17/10/26 11:31:48 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2098 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 41 ms on localhost (executor driver) (2/4)
17/10/26 11:31:48 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2188 bytes result sent to driver
17/10/26 11:31:48 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 49 ms on localhost (executor driver) (3/4)
17/10/26 11:31:48 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 50 ms on localhost (executor driver) (4/4)
17/10/26 11:31:48 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.054 s
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:48 INFO DAGScheduler: running: Set()
17/10/26 11:31:48 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:31:48 INFO DAGScheduler: failed: Set()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:48 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:31:48 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.076117 s
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz5`
WHERE (0 = 1)
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:48 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:48 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:48 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:31:48 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:31:48 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:31:48 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:31:48 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:31:48 INFO DAGScheduler: Missing parents: List()
17/10/26 11:31:48 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:31:48 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:31:48 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:65283 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:31:48 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:31:48 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 11:31:48 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:31:48 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1169 bytes result sent to driver
17/10/26 11:31:48 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:31:48 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:31:48 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.008 s
17/10/26 11:31:48 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.014947 s
17/10/26 11:31:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:31:50 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:31:50 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:31:51 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:31:51 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:31:51 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:31:51 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:65283 (size: 25.7 KB, free: 269.6 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:51 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:31:51 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:31:51 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:31:51 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:31:51 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:31:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:31:51 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:65283 (size: 19.5 KB, free: 269.6 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:31:51 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:31:51 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:31:51 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:31:51 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_ada139bd645346e8e1684faf062379bfcb52b9cf1f4baa69201e4a49aa323162.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:31:51 INFO CodeGenerator: Code generated in 48.321964 ms
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:65283 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:65283 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:31:51 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:31:51 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:65283 in memory (size: 9.4 KB, free: 269.4 MB)
17/10/26 11:31:51 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 326 ms on localhost (executor driver) (1/4)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 267.2 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:65283 (size: 1296.0 KB, free: 268.2 MB)
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 575 ms on localhost (executor driver) (2/4)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 265.8 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:65283 (size: 1444.5 KB, free: 266.8 MB)
17/10/26 11:31:51 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 264.4 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:65283 (size: 1374.8 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 608 ms on localhost (executor driver) (3/4)
17/10/26 11:31:51 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:31:51 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.619 s
17/10/26 11:31:51 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:51 INFO DAGScheduler: running: Set()
17/10/26 11:31:51 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:31:51 INFO DAGScheduler: failed: Set()
17/10/26 11:31:51 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:31:51 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 617 ms on localhost (executor driver) (4/4)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:31:51 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:51 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:31:51 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.007 s
17/10/26 11:31:51 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.640584 s
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:31:51 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:51 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:31:51 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:31:51 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 11:31:51 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:31:51 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:31:51 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:31:51 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:31:51 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 11:31:51 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 11:31:51 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:65283 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:31:51 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:51 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 11:31:51 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:31:51 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:31:51 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:31:51 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:31:51 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 11:31:51 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 11:31:51 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 11:31:51 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2188 bytes result sent to driver
17/10/26 11:31:51 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 21 ms on localhost (executor driver) (1/4)
17/10/26 11:31:52 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2109 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 198 ms on localhost (executor driver) (2/4)
17/10/26 11:31:52 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2109 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 202 ms on localhost (executor driver) (3/4)
17/10/26 11:31:52 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 11:31:52 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.209 s
17/10/26 11:31:52 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:31:52 INFO DAGScheduler: running: Set()
17/10/26 11:31:52 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:31:52 INFO DAGScheduler: failed: Set()
17/10/26 11:31:52 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 11:31:52 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 207 ms on localhost (executor driver) (4/4)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:31:52 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 11:31:52 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 11:31:52 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:65283 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:31:52 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:31:52 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:31:52 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:31:52 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:31:52 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:31:52 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:31:52 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1960 bytes result sent to driver
17/10/26 11:31:52 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:31:52 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:31:52 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.007 s
17/10/26 11:31:52 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.227617 s
17/10/26 11:31:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:52 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz6`
WHERE (0 = 1)
17/10/26 11:31:52 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:31:52 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:31:52 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:31:52 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:32:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:32:26 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:32:26 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 11:32:26 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 11:32:26 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_246708450
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 11:32:26 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 11:32:26 INFO DAGScheduler: Got job 9 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 11:32:26 INFO DAGScheduler: Final stage: ResultStage 15 (collect at SpreadRDDBuilder.scala:105)
17/10/26 11:32:26 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:26 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:26 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.1 KB, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1361.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:65283 (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:26 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Adding task set 15.0 with 11 tasks
17/10/26 11:32:26 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:32:26 INFO Executor: Running task 1.0 in stage 15.0 (TID 34)
17/10/26 11:32:26 INFO Executor: Running task 2.0 in stage 15.0 (TID 35)
17/10/26 11:32:26 INFO Executor: Running task 3.0 in stage 15.0 (TID 36)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_2 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 16.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_3 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_2 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:65283 (size: 16.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_3 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_73_2]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_73_0]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_73_3]
17/10/26 11:32:26 INFO Executor: Finished task 3.0 in stage 15.0 (TID 36). 1627 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 2.0 in stage 15.0 (TID 35). 1627 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_73_1]
17/10/26 11:32:26 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1717 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 1.0 in stage 15.0 (TID 34). 1717 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 37, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 4.0 in stage 15.0 (TID 37)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 38, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 39, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 40, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 35) in 38 ms on localhost (executor driver) (1/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 53 ms on localhost (executor driver) (2/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 34) in 38 ms on localhost (executor driver) (3/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 36) in 38 ms on localhost (executor driver) (4/11)
17/10/26 11:32:26 INFO Executor: Running task 5.0 in stage 15.0 (TID 38)
17/10/26 11:32:26 INFO Executor: Running task 6.0 in stage 15.0 (TID 39)
17/10/26 11:32:26 INFO Executor: Running task 7.0 in stage 15.0 (TID 40)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_4 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_6 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_7 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_5 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_4 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_73_4]
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_6 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_7 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_5 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO Executor: Finished task 4.0 in stage 15.0 (TID 37). 1548 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_73_6]
17/10/26 11:32:26 INFO Executor: Finished task 6.0 in stage 15.0 (TID 39). 1461 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 40:
[rdd_73_7]
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_73_5]
17/10/26 11:32:26 INFO Executor: Finished task 7.0 in stage 15.0 (TID 40). 1461 bytes result sent to driver
17/10/26 11:32:26 INFO Executor: Finished task 5.0 in stage 15.0 (TID 38). 1461 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 41, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 42, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 43, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:32:26 INFO Executor: Running task 8.0 in stage 15.0 (TID 41)
17/10/26 11:32:26 INFO Executor: Running task 9.0 in stage 15.0 (TID 42)
17/10/26 11:32:26 INFO Executor: Running task 10.0 in stage 15.0 (TID 43)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 40) in 15 ms on localhost (executor driver) (5/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 38) in 15 ms on localhost (executor driver) (6/11)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_8 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 39) in 15 ms on localhost (executor driver) (7/11)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_9 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block rdd_73_10 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_8 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_9 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added rdd_73_10 in memory on 127.0.0.1:65283 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 37) in 31 ms on localhost (executor driver) (8/11)
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 41:
[rdd_73_8]
17/10/26 11:32:26 INFO Executor: Finished task 8.0 in stage 15.0 (TID 41). 1540 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 42:
[rdd_73_9]
17/10/26 11:32:26 INFO Executor: Finished task 9.0 in stage 15.0 (TID 42). 1619 bytes result sent to driver
17/10/26 11:32:26 WARN Executor: 1 block locks were not released by TID = 43:
[rdd_73_10]
17/10/26 11:32:26 INFO Executor: Finished task 10.0 in stage 15.0 (TID 43). 1540 bytes result sent to driver
17/10/26 11:32:26 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 41) in 16 ms on localhost (executor driver) (9/11)
17/10/26 11:32:26 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 42) in 16 ms on localhost (executor driver) (10/11)
17/10/26 11:32:26 INFO DAGScheduler: ResultStage 15 (collect at SpreadRDDBuilder.scala:105) finished in 0.069 s
17/10/26 11:32:26 INFO DAGScheduler: Job 9 finished: collect at SpreadRDDBuilder.scala:105, took 0.073755 s
17/10/26 11:32:26 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 43) in 16 ms on localhost (executor driver) (11/11)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:32:26 INFO ParallelCollectionRDD: Removing RDD 73 from persistence list
17/10/26 11:32:26 INFO BlockManager: Removing RDD 73
17/10/26 11:32:26 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 11:32:26 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 11:32:26 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 11:32:26 INFO DAGScheduler: Got job 10 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 11:32:26 INFO DAGScheduler: Final stage: ResultStage 16 (collect at InternalBackendUtils.scala:163)
17/10/26 11:32:26 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:26 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:26 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.0 KB, free 264.3 MB)
17/10/26 11:32:26 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1948.0 B, free 264.3 MB)
17/10/26 11:32:26 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:65283 (size: 1948.0 B, free: 265.4 MB)
17/10/26 11:32:26 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:26 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100)
17/10/26 11:32:26 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 11:32:26 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 44, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:32:26 INFO Executor: Running task 0.0 in stage 16.0 (TID 44)
17/10/26 11:32:27 INFO Reflections: Reflections took 262 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 11:32:27 INFO Reflections: Reflections took 125 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:65283 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO BlockManager: Removing RDD 73
17/10/26 11:32:28 INFO ContextCleaner: Cleaned RDD 73
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:65283 in memory (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:32:28 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:65283 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:32:28 INFO Server: jetty-8.1.17.v20150415
17/10/26 11:32:29 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/10/26 11:32:29 INFO Executor: Finished task 0.0 in stage 16.0 (TID 44). 1523 bytes result sent to driver
17/10/26 11:32:29 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 44) in 2633 ms on localhost (executor driver) (1/1)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 11:32:29 INFO DAGScheduler: ResultStage 16 (collect at InternalBackendUtils.scala:163) finished in 2.634 s
17/10/26 11:32:29 INFO DAGScheduler: Job 10 finished: collect at InternalBackendUtils.scala:163, took 2.638711 s
17/10/26 11:32:29 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 11:32:29 INFO DAGScheduler: Got job 11 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 11:32:29 INFO DAGScheduler: Final stage: ResultStage 17 (foreach at InternalBackendUtils.scala:175)
17/10/26 11:32:29 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:32:29 INFO DAGScheduler: Missing parents: List()
17/10/26 11:32:29 INFO DAGScheduler: Submitting ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 11:32:29 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1672.0 B, free 264.4 MB)
17/10/26 11:32:29 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1161.0 B, free 264.4 MB)
17/10/26 11:32:29 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:65283 (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:32:29 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 11:32:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 11:32:29 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 45, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:32:29 INFO Executor: Running task 0.0 in stage 17.0 (TID 45)
17/10/26 11:32:29 INFO Executor: Finished task 0.0 in stage 17.0 (TID 45). 843 bytes result sent to driver
17/10/26 11:32:29 INFO DAGScheduler: ResultStage 17 (foreach at InternalBackendUtils.scala:175) finished in 0.006 s
17/10/26 11:32:29 INFO DAGScheduler: Job 11 finished: foreach at InternalBackendUtils.scala:175, took 0.010409 s
17/10/26 11:32:29 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 45) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:32:29 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 11:32:31 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:32:31 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:65283 in memory (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:65283 in memory (size: 1948.0 B, free: 265.4 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 1536
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:65283 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:65283 in memory (size: 9.4 KB, free: 265.5 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 11:32:36 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:65283 in memory (size: 11.2 KB, free: 265.5 MB)
17/10/26 11:32:36 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 11:32:36 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 11:32:44 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_246708450
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)
    
17/10/26 11:33:06 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:06 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:33:18 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:18 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
17/10/26 11:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:33:25 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:33:25 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:33:25 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/10/26 11:33:25 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:33:25 INFO DAGScheduler: Missing parents: List()
17/10/26 11:33:25 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/10/26 11:33:25 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 23.0 KB, free 264.6 MB)
17/10/26 11:33:25 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:33:25 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:65283 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:33:25 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 11:33:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/10/26 11:33:25 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/10/26 11:33:25 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:33:25 INFO Executor: Running task 0.0 in stage 18.0 (TID 46)
17/10/26 11:33:25 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:33:25 INFO CodeGenerator: Code generated in 22.407174 ms
17/10/26 11:33:25 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_10_0]
17/10/26 11:33:25 INFO Executor: Finished task 0.0 in stage 18.0 (TID 46). 2860 bytes result sent to driver
17/10/26 11:33:25 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.040 s
17/10/26 11:33:25 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.046536 s
17/10/26 11:33:25 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 46) in 40 ms on localhost (executor driver) (1/1)
17/10/26 11:33:25 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 11:33:25 INFO CodeGenerator: Code generated in 15.539739 ms
17/10/26 11:34:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:34:39 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 100
17/10/26 11:34:39 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:34:39 INFO DAGScheduler: Got job 13 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:34:39 INFO DAGScheduler: Final stage: ResultStage 19 (collect at utils.scala:196)
17/10/26 11:34:39 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:34:39 INFO DAGScheduler: Missing parents: List()
17/10/26 11:34:39 INFO DAGScheduler: Submitting ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:196), which has no missing parents
17/10/26 11:34:39 INFO MemoryStore: Block broadcast_22 stored as values in memory (estimated size 23.0 KB, free 264.5 MB)
17/10/26 11:34:39 INFO MemoryStore: Block broadcast_22_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:34:39 INFO BlockManagerInfo: Added broadcast_22_piece0 in memory on 127.0.0.1:65283 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:34:39 INFO SparkContext: Created broadcast 22 from broadcast at DAGScheduler.scala:996
17/10/26 11:34:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 19 (MapPartitionsRDD[80] at collect at utils.scala:196)
17/10/26 11:34:39 INFO TaskSchedulerImpl: Adding task set 19.0 with 1 tasks
17/10/26 11:34:39 INFO TaskSetManager: Starting task 0.0 in stage 19.0 (TID 47, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:34:39 INFO Executor: Running task 0.0 in stage 19.0 (TID 47)
17/10/26 11:34:39 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:34:39 WARN Executor: 1 block locks were not released by TID = 47:
[rdd_10_0]
17/10/26 11:34:39 INFO Executor: Finished task 0.0 in stage 19.0 (TID 47). 11361 bytes result sent to driver
17/10/26 11:34:39 INFO DAGScheduler: ResultStage 19 (collect at utils.scala:196) finished in 0.016 s
17/10/26 11:34:39 INFO DAGScheduler: Job 13 finished: collect at utils.scala:196, took 0.026791 s
17/10/26 11:34:39 INFO TaskSetManager: Finished task 0.0 in stage 19.0 (TID 47) in 16 ms on localhost (executor driver) (1/1)
17/10/26 11:34:39 INFO TaskSchedulerImpl: Removed TaskSet 19.0, whose tasks have all completed, from pool 
17/10/26 11:34:39 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:34:39 INFO SparkSqlParser: Parsing command: SELECT `apr`, `applicationDate`, `originatedDate`, `nPaidOff`, `isFunded`, `loanAmount`, `originallyScheduledPaymentAmount`, `leadCost`, `hasCF`, FACTOR(`loanId`) AS `loanId`, FACTOR(`anon_ssn`) AS `anon_ssn`, FACTOR(`payFrequency`) AS `payFrequency`, FACTOR(`originated`) AS `originated`, FACTOR(`approved`) AS `approved`, FACTOR(`loanStatus`) AS `loanStatus`, FACTOR(`state`) AS `state`, FACTOR(`leadType`) AS `leadType`, FACTOR(`fpStatus`) AS `fpStatus`, FACTOR(`clarityFraudId`) AS `clarityFraudId`
FROM `loan`
LIMIT 10
17/10/26 11:35:30 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:35:30 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:35:30 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:35:30 INFO MemoryStore: MemoryStore cleared
17/10/26 11:35:30 INFO BlockManager: BlockManager stopped
17/10/26 11:35:30 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:35:30 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:35:30 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:35:30 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
17/10/26 11:35:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
17/10/26 11:35:30 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\userFiles-3f123505-a808-402a-b520-68627452ba95
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\repl-e5ba46c8-6c57-4796-833d-55a6329d7062
17/10/26 11:35:30 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-d67087b0-21c9-4ede-b76a-fd1abdb8731d\repl-b5bf31ce-4847-40e9-8a85-1bba88865fa2
17/10/26 11:35:48 INFO SparkContext: Running Spark version 2.1.0
17/10/26 11:35:48 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 11:35:48 INFO SecurityManager: Changing view acls to: scibr
17/10/26 11:35:48 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 11:35:48 INFO SecurityManager: Changing view acls groups to: 
17/10/26 11:35:48 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 11:35:48 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 11:35:48 INFO Utils: Successfully started service 'sparkDriver' on port 49242.
17/10/26 11:35:48 INFO SparkEnv: Registering MapOutputTracker
17/10/26 11:35:48 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 11:35:48 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 11:35:48 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 11:35:48 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-ea5b5713-d783-4f39-8f26-8f9e9931e145
17/10/26 11:35:48 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 11:35:48 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 11:35:49 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 11:35:49 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985349260
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985349261
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985349264
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985349267
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985349268
17/10/26 11:35:49 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar with timestamp 1508985349269
17/10/26 11:35:49 INFO Executor: Starting executor ID driver on host localhost
17/10/26 11:35:49 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 49263.
17/10/26 11:35:49 INFO NettyBlockTransferService: Server created on 127.0.0.1:49263
17/10/26 11:35:49 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 11:35:49 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:49263 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 49263, None)
17/10/26 11:35:49 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 11:35:49 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 11:35:49 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 11:35:50 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 11:35:50 INFO ObjectStore: ObjectStore, initialize called
17/10/26 11:35:50 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 11:35:50 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 11:35:52 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 11:35:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:53 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:54 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 11:35:54 INFO ObjectStore: Initialized ObjectStore
17/10/26 11:35:54 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 11:35:54 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 11:35:54 INFO HiveMetaStore: Added admin role in metastore
17/10/26 11:35:54 INFO HiveMetaStore: Added public role in metastore
17/10/26 11:35:54 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 11:35:54 INFO HiveMetaStore: 0: get_all_databases
17/10/26 11:35:54 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 11:35:54 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 11:35:54 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 11:35:54 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 11:35:55 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/bd805857-a126-4cf3-94a1-b53e4eb0d016_resources
17/10/26 11:35:55 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/bd805857-a126-4cf3-94a1-b53e4eb0d016
17/10/26 11:35:55 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/bd805857-a126-4cf3-94a1-b53e4eb0d016
17/10/26 11:35:55 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/bd805857-a126-4cf3-94a1-b53e4eb0d016/_tmp_space.db
17/10/26 11:35:55 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 11:35:55 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:55 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 11:35:55 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 11:35:55 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 11:35:55 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:35:57 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:35:57 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:36:47 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:36:47 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:36:47 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:36:47 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:36:47 INFO CodeGenerator: Code generated in 279.58701 ms
17/10/26 11:36:47 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:36:47 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:36:47 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 11:36:47 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:36:47 INFO DAGScheduler: Missing parents: List()
17/10/26 11:36:47 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55), which has no missing parents
17/10/26 11:36:47 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 11:36:48 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 11:36:48 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:36:48 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 11:36:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[6] at map at utils.scala:55)
17/10/26 11:36:48 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 11:36:48 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11566 bytes)
17/10/26 11:36:48 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508985349264
17/10/26 11:36:48 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:49242 after 18 ms (0 ms spent in bootstraps)
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7099022872101261667.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4457851290711550382.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508985349267
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7515862775347599857.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5632011647670701909.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar with timestamp 1508985349262
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp743374830407151821.tmp
17/10/26 11:36:48 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.joda_joda-convert-1.7.jar to class loader
17/10/26 11:36:48 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:48 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6784425471332003603.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8616551078329832098.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3863287528581176774.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9106857532424174059.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1307445188569078265.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2107255762906542912.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508985349268
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6274637415954319902.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4406831319122227075.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508985349263
17/10/26 11:36:49 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp661950053945877469.tmp
17/10/26 11:36:49 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 11:36:49 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2096553949258846015.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508985349268
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6897285019073145497.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3979239866090984231.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1321599625916174287.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3765435435511429518.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508985349267
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8391801606041843348.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508985349266
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4931854523593092098.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508985349261
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5179374036203545670.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508985349263
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8125149525095666075.tmp
17/10/26 11:36:50 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 11:36:50 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:50 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7371063743848336896.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508985349264
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5512116028498334268.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508985349265
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3630785145735074832.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3610690887356858877.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508985349267
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8462889245972438742.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508985349264
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp408867795018716190.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508985349268
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7128698782397883924.tmp
17/10/26 11:36:51 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 11:36:51 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:51 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5830406160074661861.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar with timestamp 1508985349263
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2219992831800262421.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/commons-io_commons-io-2.4.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3649391203784980779.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508985349267
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5976320340013746917.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508985349263
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp8846458398390179708.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5641350498847306355.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508985349266
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp698508405393785301.tmp
17/10/26 11:36:52 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 11:36:52 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508985349267
17/10/26 11:36:52 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7708425362127576715.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508985349266
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3038090721154960156.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1704537831351666054.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp282826203984250379.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508985349267
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3906729287021557439.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508985349265
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3909037709063139488.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar with timestamp 1508985349264
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp6885180444758383485.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/log4j_log4j-1.2.15.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508985349268
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2382092932818638506.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2266533419428265896.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508985349266
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7378871615393046043.tmp
17/10/26 11:36:53 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 11:36:53 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar with timestamp 1508985349267
17/10/26 11:36:53 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2849212555980497024.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.tukaani_xz-1.5.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508985349267
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1665514356797007770.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508985349264
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5535078285700964506.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508985349261
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7063538184059139430.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508985349265
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5460527104822557397.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508985349264
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9028176571213731959.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508985349268
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3303635742964503710.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508985349267
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3916785233869192865.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508985349265
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3295705801780887345.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp886431032940629911.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508985349266
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp855244860050280782.tmp
17/10/26 11:36:54 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 11:36:54 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508985349263
17/10/26 11:36:54 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7966509415253378523.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508985349268
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp975262726344299547.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508985349263
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3077059031547778890.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508985349263
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp2055683495743836947.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar with timestamp 1508985349269
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp9164242362767592591.tmp
17/10/26 11:36:55 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/sparklyr-2.1-2.11.jar to class loader
17/10/26 11:36:55 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508985349262
17/10/26 11:36:55 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp5765335591335327926.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508985349267
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7954983538827032523.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508985349266
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7850567985955856972.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508985349264
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp7558686923174303078.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508985349268
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp1255309679213821782.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508985349264
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp4000971753579703565.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 11:36:56 INFO Executor: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508985349260
17/10/26 11:36:56 INFO Utils: Fetching spark://127.0.0.1:49242/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6\fetchFileTemp3558362053931360892.tmp
17/10/26 11:36:56 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-f15da984-5cf8-4424-925b-f16cfd757068/userFiles-a4535feb-3b20-4cec-987f-528475eb68a6/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 11:36:56 INFO CodeGenerator: Code generated in 14.509265 ms
17/10/26 11:36:56 INFO CodeGenerator: Code generated in 15.437103 ms
17/10/26 11:36:56 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1304 bytes result sent to driver
17/10/26 11:36:56 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 8600 ms on localhost (executor driver) (1/1)
17/10/26 11:36:56 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 11:36:56 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 8.619 s
17/10/26 11:36:56 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 8.993098 s
17/10/26 11:37:16 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: loan
17/10/26 11:37:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 11:37:17 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 11:37:17 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:17 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:17 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 11:37:17 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 6.614435 ms
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 11:37:17 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:17 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:17 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 11:37:17 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 13.544991 ms
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 10.325272 ms
17/10/26 11:37:17 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:17 INFO DAGScheduler: Registering RDD 13 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:17 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 11:37:17 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 11:37:17 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 11:37:17 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 11:37:17 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:49263 (size: 11.2 KB, free: 366.3 MB)
17/10/26 11:37:17 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:17 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[13] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:17 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 11:37:17 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:17 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 11:37:17 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 11:37:17 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 11:37:17 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 11:37:17 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 11:37:17 INFO CodeGenerator: Code generated in 22.147503 ms
17/10/26 11:37:18 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 11:37:21 INFO MemoryStore: Block rdd_10_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 11:37:21 INFO BlockManagerInfo: Added rdd_10_3 in memory on 127.0.0.1:49263 (size: 15.4 MB, free: 350.9 MB)
17/10/26 11:37:21 INFO CodeGenerator: Code generated in 6.474848 ms
17/10/26 11:37:21 INFO CodeGenerator: Code generated in 40.852563 ms
17/10/26 11:37:21 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 11:37:21 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 3882 ms on localhost (executor driver) (1/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_0 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 332.6 MB)
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2893 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4151 ms on localhost (executor driver) (2/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_1 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_1 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 314.4 MB)
17/10/26 11:37:22 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2893 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4181 ms on localhost (executor driver) (3/4)
17/10/26 11:37:22 INFO MemoryStore: Block rdd_10_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added rdd_10_2 in memory on 127.0.0.1:49263 (size: 18.2 MB, free: 296.2 MB)
17/10/26 11:37:22 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2983 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.271 s
17/10/26 11:37:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:22 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4266 ms on localhost (executor driver) (4/4)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO DAGScheduler: running: Set()
17/10/26 11:37:22 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 11:37:22 INFO DAGScheduler: failed: Set()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[16] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.045 s
17/10/26 11:37:22 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.383105 s
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 44 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO CodeGenerator: Code generated in 7.392936 ms
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 11:37:22 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:22 INFO DAGScheduler: Registering RDD 20 (collect at utils.scala:196)
17/10/26 11:37:22 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:22 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 11:37:22 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 11:37:22 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 11:37:22 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:49263 (size: 11.2 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[20] at collect at utils.scala:196)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 11:37:22 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 11:37:22 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 11:37:22 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_1 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_2 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_3 locally
17/10/26 11:37:22 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:37:22 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2109 bytes result sent to driver
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2019 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 49 ms on localhost (executor driver) (1/4)
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 53 ms on localhost (executor driver) (2/4)
17/10/26 11:37:22 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2098 bytes result sent to driver
17/10/26 11:37:22 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2188 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 60 ms on localhost (executor driver) (3/4)
17/10/26 11:37:22 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.065 s
17/10/26 11:37:22 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:22 INFO DAGScheduler: running: Set()
17/10/26 11:37:22 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 11:37:22 INFO DAGScheduler: failed: Set()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:22 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 56 ms on localhost (executor driver) (4/4)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[23] at collect at utils.scala:196)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:22 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1952 bytes result sent to driver
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 7 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.007 s
17/10/26 11:37:22 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.091469 s
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz7`
WHERE (0 = 1)
17/10/26 11:37:22 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:22 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:22 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:37:22 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:37:22 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 11:37:22 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:22 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:22 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55), which has no missing parents
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 11:37:22 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 11:37:22 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 296.2 MB)
17/10/26 11:37:22 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:22 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at map at utils.scala:55)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 11:37:22 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 11:37:22 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 11:37:22 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1156 bytes result sent to driver
17/10/26 11:37:22 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.012 s
17/10/26 11:37:22 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.016744 s
17/10/26 11:37:22 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 11:37:22 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 11:37:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: payment
17/10/26 11:37:35 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 11:37:35 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 11:37:35 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:35 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:35 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 11:37:35 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.5 MB)
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 11:37:35 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 296.1 MB)
17/10/26 11:37:35 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:35 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:35 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:35 INFO DAGScheduler: Registering RDD 36 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:35 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 11:37:35 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 11:37:35 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.4 MB)
17/10/26 11:37:35 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.4 MB)
17/10/26 11:37:35 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:49263 (size: 9.4 KB, free: 296.1 MB)
17/10/26 11:37:35 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:35 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[36] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:35 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 11:37:35 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 11:37:35 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 11:37:35 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 11:37:35 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 11:37:35 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 11:37:35 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 11:37:35 INFO CodeGenerator: Code generated in 29.552755 ms
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:49263 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 11:37:36 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 11:37:37 INFO MemoryStore: Block rdd_33_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 11:37:37 INFO BlockManagerInfo: Added rdd_33_3 in memory on 127.0.0.1:49263 (size: 5.1 MB, free: 291.0 MB)
17/10/26 11:37:37 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 11:37:37 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1997 ms on localhost (executor driver) (1/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_2 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 283.9 MB)
17/10/26 11:37:38 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2665 ms on localhost (executor driver) (2/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_1 stored as values in memory (estimated size 7.1 MB, free 276.2 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_1 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 276.8 MB)
17/10/26 11:37:38 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2738 ms on localhost (executor driver) (3/4)
17/10/26 11:37:38 INFO MemoryStore: Block rdd_33_0 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added rdd_33_0 in memory on 127.0.0.1:49263 (size: 7.1 MB, free: 269.7 MB)
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2983 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2784 ms on localhost (executor driver) (4/4)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.786 s
17/10/26 11:37:38 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:38 INFO DAGScheduler: running: Set()
17/10/26 11:37:38 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 11:37:38 INFO DAGScheduler: failed: Set()
17/10/26 11:37:38 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[39] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1952 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:37:38 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.006 s
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.808552 s
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 11:37:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:38 INFO DAGScheduler: Registering RDD 43 (collect at utils.scala:196)
17/10/26 11:37:38 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:38 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 11:37:38 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 11:37:38 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 11:37:38 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:49263 (size: 9.4 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[43] at collect at utils.scala:196)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 11:37:38 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 11:37:38 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 11:37:38 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_2 locally
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_0 locally
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_3 locally
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2109 bytes result sent to driver
17/10/26 11:37:38 INFO BlockManager: Found block rdd_33_1 locally
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 35 ms on localhost (executor driver) (1/4)
17/10/26 11:37:38 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2188 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 38 ms on localhost (executor driver) (2/4)
17/10/26 11:37:38 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 44 ms on localhost (executor driver) (3/4)
17/10/26 11:37:38 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2019 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 48 ms on localhost (executor driver) (4/4)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.053 s
17/10/26 11:37:38 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:38 INFO DAGScheduler: running: Set()
17/10/26 11:37:38 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 11:37:38 INFO DAGScheduler: failed: Set()
17/10/26 11:37:38 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 11:37:38 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 11:37:38 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 269.7 MB)
17/10/26 11:37:38 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[46] at collect at utils.scala:196)
17/10/26 11:37:38 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 11:37:38 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 11:37:38 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:38 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:38 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 11:37:38 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/10/26 11:37:38 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 11:37:38 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.079526 s
17/10/26 11:37:38 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz8`
WHERE (0 = 1)
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:38 INFO CodeGenerator: Code generated in 9.032047 ms
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:38 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:38 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:38 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:39 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 11:37:39 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 11:37:39 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 11:37:39 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:39 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:39 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55), which has no missing parents
17/10/26 11:37:39 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 11:37:39 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 11:37:39 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:49263 (size: 4.6 KB, free: 269.7 MB)
17/10/26 11:37:39 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:39 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[54] at map at utils.scala:55)
17/10/26 11:37:39 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 11:37:39 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 11:37:39 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 11:37:39 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 11:37:39 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.007 s
17/10/26 11:37:39 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.013646 s
17/10/26 11:37:39 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 6 ms on localhost (executor driver) (1/1)
17/10/26 11:37:39 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 11:37:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: cuv
17/10/26 11:37:41 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 11:37:41 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 11:37:41 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 11:37:41 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 11:37:41 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 11:37:41 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.7 MB)
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:49263 (size: 25.7 KB, free: 269.6 MB)
17/10/26 11:37:41 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:41 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 11:37:41 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 11:37:41 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 11:37:41 INFO DAGScheduler: Registering RDD 61 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 11:37:41 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 11:37:41 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 11:37:41 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.6 MB)
17/10/26 11:37:41 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:49263 (size: 19.5 KB, free: 269.6 MB)
17/10/26 11:37:41 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:41 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[61] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:41 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 11:37:41 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 11:37:41 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 11:37:41 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 11:37:41 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 11:37:41 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 11:37:41 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 11:37:41 INFO CodeGenerator: Code generated in 71.766797 ms
17/10/26 11:37:41 INFO MemoryStore: Block rdd_58_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Added rdd_58_3 in memory on 127.0.0.1:49263 (size: 198.6 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/26 11:37:41 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 270 ms on localhost (executor driver) (1/4)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:49263 in memory (size: 9.4 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 269.4 MB)
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 11:37:41 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 11:37:41 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:49263 in memory (size: 4.6 KB, free: 269.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_1 stored as values in memory (estimated size 1374.8 KB, free 267.1 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_1 in memory on 127.0.0.1:49263 (size: 1374.8 KB, free: 268.1 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_2 stored as values in memory (estimated size 1444.5 KB, free 265.7 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_2 in memory on 127.0.0.1:49263 (size: 1444.5 KB, free: 266.7 MB)
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 616 ms on localhost (executor driver) (2/4)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_58_0 stored as values in memory (estimated size 1296.0 KB, free 264.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_58_0 in memory on 127.0.0.1:49263 (size: 1296.0 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 634 ms on localhost (executor driver) (3/4)
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2983 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 645 ms on localhost (executor driver) (4/4)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.645 s
17/10/26 11:37:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:42 INFO DAGScheduler: running: Set()
17/10/26 11:37:42 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 11:37:42 INFO DAGScheduler: failed: Set()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[64] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 8 ms on localhost (executor driver) (1/1)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 11:37:42 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.672190 s
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:37:42 INFO DAGScheduler: Registering RDD 68 (collect at utils.scala:196)
17/10/26 11:37:42 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 11:37:42 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:49263 (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[68] at collect at utils.scala:196)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 11:37:42 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 11:37:42 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 11:37:42 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_1 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_2 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_3 locally
17/10/26 11:37:42 INFO BlockManager: Found block rdd_58_0 locally
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 16 ms on localhost (executor driver) (1/4)
17/10/26 11:37:42 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 19 ms on localhost (executor driver) (2/4)
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2098 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 25 ms on localhost (executor driver) (3/4)
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2019 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 28 ms on localhost (executor driver) (4/4)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.029 s
17/10/26 11:37:42 INFO DAGScheduler: looking for newly runnable stages
17/10/26 11:37:42 INFO DAGScheduler: running: Set()
17/10/26 11:37:42 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 11:37:42 INFO DAGScheduler: failed: Set()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:49263 (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[71] at collect at utils.scala:196)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 11:37:42 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 11:37:42 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.046518 s
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz9`
WHERE (0 = 1)
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_database: default
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 11:37:42 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 11:37:42 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 11:37:42 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:42 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:37:42 WARN InternalH2OBackend: Increasing 'spark.locality.wait' to value 30000
17/10/26 11:37:42 WARN InternalH2OBackend: Due to non-deterministic behavior of Spark broadcast-based joins
We recommend to disable them by
configuring `spark.sql.autoBroadcastJoinThreshold` variable to value `-1`:
sqlContext.sql("SET spark.sql.autoBroadcastJoinThreshold=-1")
17/10/26 11:37:42 INFO InternalH2OBackend: Starting H2O services: Sparkling Water configuration:
  backend cluster mode : internal
  workers              : None
  cloudName            : sparkling-water-scibr_1934800255
  flatfile             : true
  clientBasePort       : 54321
  nodeBasePort         : 54321
  cloudTimeout         : 60000
  h2oNodeLog           : INFO
  h2oClientLog         : WARN
  nthreads             : -1
  drddMulFactor        : 10
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at SpreadRDDBuilder.scala:105
17/10/26 11:37:42 INFO DAGScheduler: Got job 9 (collect at SpreadRDDBuilder.scala:105) with 11 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 15 (collect at SpreadRDDBuilder.scala:105)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 2.1 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 1361.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:49263 (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 11 missing tasks from ResultStage 15 (MapPartitionsRDD[74] at mapPartitionsWithIndex at SpreadRDDBuilder.scala:102)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 15.0 with 11 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 1.0 in stage 15.0 (TID 34, localhost, executor driver, partition 1, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 2.0 in stage 15.0 (TID 35, localhost, executor driver, partition 2, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 3.0 in stage 15.0 (TID 36, localhost, executor driver, partition 3, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 11:37:42 INFO Executor: Running task 1.0 in stage 15.0 (TID 34)
17/10/26 11:37:42 INFO Executor: Running task 2.0 in stage 15.0 (TID 35)
17/10/26 11:37:42 INFO Executor: Running task 3.0 in stage 15.0 (TID 36)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_1 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_0 stored as values in memory (estimated size 16.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_0 in memory on 127.0.0.1:49263 (size: 16.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_2 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_1 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_2 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_3 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_3 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 36:
[rdd_73_3]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 35:
[rdd_73_2]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_73_0]
17/10/26 11:37:42 INFO Executor: Finished task 2.0 in stage 15.0 (TID 35). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 1706 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_73_1]
17/10/26 11:37:42 INFO Executor: Finished task 3.0 in stage 15.0 (TID 36). 1714 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 1.0 in stage 15.0 (TID 34). 1706 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 4.0 in stage 15.0 (TID 37, localhost, executor driver, partition 4, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 2.0 in stage 15.0 (TID 35) in 26 ms on localhost (executor driver) (1/11)
17/10/26 11:37:42 INFO Executor: Running task 4.0 in stage 15.0 (TID 37)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 5.0 in stage 15.0 (TID 38, localhost, executor driver, partition 5, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 6.0 in stage 15.0 (TID 39, localhost, executor driver, partition 6, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 5.0 in stage 15.0 (TID 38)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 7.0 in stage 15.0 (TID 40, localhost, executor driver, partition 7, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO Executor: Running task 6.0 in stage 15.0 (TID 39)
17/10/26 11:37:42 INFO Executor: Running task 7.0 in stage 15.0 (TID 40)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 3.0 in stage 15.0 (TID 36) in 30 ms on localhost (executor driver) (2/11)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_4 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 1.0 in stage 15.0 (TID 34) in 34 ms on localhost (executor driver) (3/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 43 ms on localhost (executor driver) (4/11)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_4 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_5 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_6 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_5 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_6 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 37:
[rdd_73_4]
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 38:
[rdd_73_5]
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_7 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_7 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO Executor: Finished task 5.0 in stage 15.0 (TID 38). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 39:
[rdd_73_6]
17/10/26 11:37:42 INFO Executor: Finished task 6.0 in stage 15.0 (TID 39). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO Executor: Finished task 4.0 in stage 15.0 (TID 37). 1714 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 8.0 in stage 15.0 (TID 41, localhost, executor driver, partition 8, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Starting task 9.0 in stage 15.0 (TID 42, localhost, executor driver, partition 9, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 40:
[rdd_73_7]
17/10/26 11:37:42 INFO Executor: Finished task 7.0 in stage 15.0 (TID 40). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Starting task 10.0 in stage 15.0 (TID 43, localhost, executor driver, partition 10, PROCESS_LOCAL, 11541 bytes)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 5.0 in stage 15.0 (TID 38) in 15 ms on localhost (executor driver) (5/11)
17/10/26 11:37:42 INFO Executor: Running task 8.0 in stage 15.0 (TID 41)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 6.0 in stage 15.0 (TID 39) in 13 ms on localhost (executor driver) (6/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 4.0 in stage 15.0 (TID 37) in 17 ms on localhost (executor driver) (7/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 7.0 in stage 15.0 (TID 40) in 14 ms on localhost (executor driver) (8/11)
17/10/26 11:37:42 INFO Executor: Running task 9.0 in stage 15.0 (TID 42)
17/10/26 11:37:42 INFO Executor: Running task 10.0 in stage 15.0 (TID 43)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_10 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_8 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block rdd_73_9 stored as values in memory (estimated size 24.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_10 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_8 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 43:
[rdd_73_10]
17/10/26 11:37:42 INFO Executor: Finished task 10.0 in stage 15.0 (TID 43). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 41:
[rdd_73_8]
17/10/26 11:37:42 INFO BlockManagerInfo: Added rdd_73_9 in memory on 127.0.0.1:49263 (size: 24.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 10.0 in stage 15.0 (TID 43) in 15 ms on localhost (executor driver) (9/11)
17/10/26 11:37:42 INFO Executor: Finished task 8.0 in stage 15.0 (TID 41). 1627 bytes result sent to driver
17/10/26 11:37:42 WARN Executor: 1 block locks were not released by TID = 42:
[rdd_73_9]
17/10/26 11:37:42 INFO Executor: Finished task 9.0 in stage 15.0 (TID 42). 1627 bytes result sent to driver
17/10/26 11:37:42 INFO TaskSetManager: Finished task 8.0 in stage 15.0 (TID 41) in 19 ms on localhost (executor driver) (10/11)
17/10/26 11:37:42 INFO TaskSetManager: Finished task 9.0 in stage 15.0 (TID 42) in 19 ms on localhost (executor driver) (11/11)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 11:37:42 INFO DAGScheduler: ResultStage 15 (collect at SpreadRDDBuilder.scala:105) finished in 0.066 s
17/10/26 11:37:42 INFO DAGScheduler: Job 9 finished: collect at SpreadRDDBuilder.scala:105, took 0.070397 s
17/10/26 11:37:42 INFO ParallelCollectionRDD: Removing RDD 73 from persistence list
17/10/26 11:37:42 INFO BlockManager: Removing RDD 73
17/10/26 11:37:42 INFO SpreadRDDBuilder: Detected 1 spark executors for 1 H2O workers!
17/10/26 11:37:42 INFO InternalH2OBackend: Launching H2O on following 1 nodes: (driver,127.0.0.1,-1)
17/10/26 11:37:42 INFO SparkContext: Starting job: collect at InternalBackendUtils.scala:163
17/10/26 11:37:42 INFO DAGScheduler: Got job 10 (collect at InternalBackendUtils.scala:163) with 1 output partitions
17/10/26 11:37:42 INFO DAGScheduler: Final stage: ResultStage 16 (collect at InternalBackendUtils.scala:163)
17/10/26 11:37:42 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:42 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:42 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100), which has no missing parents
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.0 KB, free 264.3 MB)
17/10/26 11:37:42 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 1949.0 B, free 264.3 MB)
17/10/26 11:37:42 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:49263 (size: 1949.0 B, free: 265.4 MB)
17/10/26 11:37:42 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:42 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[76] at map at InternalBackendUtils.scala:100)
17/10/26 11:37:42 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 11:37:42 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 44, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:37:42 INFO Executor: Running task 0.0 in stage 16.0 (TID 44)
17/10/26 11:37:43 INFO Reflections: Reflections took 316 ms to scan 18 urls, producing 209 keys and 1323 values 
17/10/26 11:37:43 INFO Reflections: Reflections took 136 ms to scan 10 urls, producing 135 keys and 696 values 
17/10/26 11:37:44 INFO Server: jetty-8.1.17.v20150415
17/10/26 11:37:44 INFO AbstractConnector: Started SocketConnector@0.0.0.0:54321
17/10/26 11:37:45 INFO Executor: Finished task 0.0 in stage 16.0 (TID 44). 1371 bytes result sent to driver
17/10/26 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 44) in 2368 ms on localhost (executor driver) (1/1)
17/10/26 11:37:45 INFO DAGScheduler: ResultStage 16 (collect at InternalBackendUtils.scala:163) finished in 2.372 s
17/10/26 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 11:37:45 INFO DAGScheduler: Job 10 finished: collect at InternalBackendUtils.scala:163, took 2.386869 s
17/10/26 11:37:45 INFO SparkContext: Starting job: foreach at InternalBackendUtils.scala:175
17/10/26 11:37:45 INFO DAGScheduler: Got job 11 (foreach at InternalBackendUtils.scala:175) with 1 output partitions
17/10/26 11:37:45 INFO DAGScheduler: Final stage: ResultStage 17 (foreach at InternalBackendUtils.scala:175)
17/10/26 11:37:45 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:37:45 INFO DAGScheduler: Missing parents: List()
17/10/26 11:37:45 INFO DAGScheduler: Submitting ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27), which has no missing parents
17/10/26 11:37:45 INFO MemoryStore: Block broadcast_20 stored as values in memory (estimated size 1672.0 B, free 264.3 MB)
17/10/26 11:37:45 INFO MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 1161.0 B, free 264.3 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Added broadcast_20_piece0 in memory on 127.0.0.1:49263 (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO SparkContext: Created broadcast 20 from broadcast at DAGScheduler.scala:996
17/10/26 11:37:45 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 17 (InvokeOnNodesRDD[75] at RDD at InvokeOnNodesRDD.scala:27)
17/10/26 11:37:45 INFO TaskSchedulerImpl: Adding task set 17.0 with 1 tasks
17/10/26 11:37:45 INFO TaskSetManager: Starting task 0.0 in stage 17.0 (TID 45, localhost, executor driver, partition 0, ANY, 11533 bytes)
17/10/26 11:37:45 INFO Executor: Running task 0.0 in stage 17.0 (TID 45)
17/10/26 11:37:45 INFO Executor: Finished task 0.0 in stage 17.0 (TID 45). 764 bytes result sent to driver
17/10/26 11:37:45 INFO TaskSetManager: Finished task 0.0 in stage 17.0 (TID 45) in 5 ms on localhost (executor driver) (1/1)
17/10/26 11:37:45 INFO TaskSchedulerImpl: Removed TaskSet 17.0, whose tasks have all completed, from pool 
17/10/26 11:37:45 INFO DAGScheduler: ResultStage 17 (foreach at InternalBackendUtils.scala:175) finished in 0.006 s
17/10/26 11:37:45 INFO DAGScheduler: Job 11 finished: foreach at InternalBackendUtils.scala:175, took 0.009284 s
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_17_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManager: Removing RDD 73
17/10/26 11:37:45 INFO ContextCleaner: Cleaned RDD 73
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_18_piece0 on 127.0.0.1:49263 in memory (size: 1361.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_19_piece0 on 127.0.0.1:49263 in memory (size: 1949.0 B, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_15_piece0 on 127.0.0.1:49263 in memory (size: 3.7 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO ContextCleaner: Cleaned accumulator 1067
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_16_piece0 on 127.0.0.1:49263 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:45 INFO BlockManagerInfo: Removed broadcast_20_piece0 on 127.0.0.1:49263 in memory (size: 1161.0 B, free: 265.4 MB)
17/10/26 11:37:45 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 1536
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_14_piece0 on 127.0.0.1:49263 in memory (size: 19.5 KB, free: 265.4 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 4
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 898
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 897
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 896
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 895
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 894
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 893
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 892
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 891
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 890
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 889
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 888
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 887
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 127.0.0.1:49263 in memory (size: 9.4 KB, free: 265.5 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 2
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 482
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 481
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 480
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 479
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 478
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 477
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 476
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 475
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 474
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 473
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 472
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 471
17/10/26 11:37:52 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 127.0.0.1:49263 in memory (size: 11.2 KB, free: 265.5 MB)
17/10/26 11:37:52 INFO ContextCleaner: Cleaned shuffle 0
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 66
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 65
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 64
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 63
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 62
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 61
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 60
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 59
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 58
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 57
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 56
17/10/26 11:37:52 INFO ContextCleaner: Cleaned accumulator 55
17/10/26 11:37:53 INFO H2OContext: Sparkling Water started, status of context: 
Sparkling Water Context:
 * H2O name: sparkling-water-scibr_1934800255
 * cluster size: 1
 * list of used nodes:
  (executorId, host, port)
  ------------------------
  (driver,127.0.0.1,54321)
  ------------------------

  Open H2O Flow in browser: http://127.0.0.1:54321 (CMD + click in Mac OSX)
    
17/10/26 11:38:17 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:38:17 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
17/10/26 11:38:48 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 11:38:48 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 11:38:48 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 11:38:48 INFO DAGScheduler: Got job 12 (collect at utils.scala:196) with 1 output partitions
17/10/26 11:38:48 INFO DAGScheduler: Final stage: ResultStage 18 (collect at utils.scala:196)
17/10/26 11:38:48 INFO DAGScheduler: Parents of final stage: List()
17/10/26 11:38:48 INFO DAGScheduler: Missing parents: List()
17/10/26 11:38:48 INFO DAGScheduler: Submitting ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196), which has no missing parents
17/10/26 11:38:48 INFO MemoryStore: Block broadcast_21 stored as values in memory (estimated size 23.0 KB, free 264.6 MB)
17/10/26 11:38:48 INFO MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 9.8 KB, free 264.5 MB)
17/10/26 11:38:48 INFO BlockManagerInfo: Added broadcast_21_piece0 in memory on 127.0.0.1:49263 (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:38:48 INFO SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:996
17/10/26 11:38:48 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 18 (MapPartitionsRDD[78] at collect at utils.scala:196)
17/10/26 11:38:48 INFO TaskSchedulerImpl: Adding task set 18.0 with 1 tasks
17/10/26 11:38:48 INFO TaskSetManager: Starting task 0.0 in stage 18.0 (TID 46, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 11:38:48 INFO Executor: Running task 0.0 in stage 18.0 (TID 46)
17/10/26 11:38:48 INFO BlockManager: Found block rdd_10_0 locally
17/10/26 11:38:48 INFO CodeGenerator: Code generated in 24.343932 ms
17/10/26 11:38:48 WARN Executor: 1 block locks were not released by TID = 46:
[rdd_10_0]
17/10/26 11:38:48 INFO Executor: Finished task 0.0 in stage 18.0 (TID 46). 2773 bytes result sent to driver
17/10/26 11:38:48 INFO DAGScheduler: ResultStage 18 (collect at utils.scala:196) finished in 0.047 s
17/10/26 11:38:48 INFO TaskSetManager: Finished task 0.0 in stage 18.0 (TID 46) in 47 ms on localhost (executor driver) (1/1)
17/10/26 11:38:48 INFO DAGScheduler: Job 12 finished: collect at utils.scala:196, took 0.063806 s
17/10/26 11:38:48 INFO TaskSchedulerImpl: Removed TaskSet 18.0, whose tasks have all completed, from pool 
17/10/26 11:38:48 INFO CodeGenerator: Code generated in 16.5502 ms
17/10/26 11:47:01 INFO BlockManagerInfo: Removed broadcast_21_piece0 on 127.0.0.1:49263 in memory (size: 9.8 KB, free: 265.5 MB)
17/10/26 11:49:15 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 11:49:15 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 11:49:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 11:49:15 INFO MemoryStore: MemoryStore cleared
17/10/26 11:49:15 INFO BlockManager: BlockManager stopped
17/10/26 11:49:15 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 11:49:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 11:49:15 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:49:15 INFO SparkContext: Successfully stopped SparkContext
17/10/26 11:49:15 INFO ShutdownHookManager: Shutdown hook called
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\repl-2379c083-58b0-42da-b3fa-b5cfbb633655
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
17/10/26 11:49:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\userFiles-a4535feb-3b20-4cec-987f-528475eb68a6
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068\repl-93efbd9d-cdeb-44fc-9c63-d9dceff563f1
17/10/26 11:49:15 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
17/10/26 11:49:15 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-f15da984-5cf8-4424-925b-f16cfd757068
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:31:53 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:31:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:31:54 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:31:54 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:31:54 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:31:54 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:31:54 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:31:54 INFO Utils: Successfully started service 'sparkDriver' on port 51014.
17/10/26 12:31:54 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:31:54 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:31:54 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-fe7dce3f-ca96-4aaf-af65-1cff15df6ffa
17/10/26 12:31:54 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:31:54 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:31:54 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:31:54 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar with timestamp 1508988714625
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar with timestamp 1508988714641
17/10/26 12:31:54 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:31:54 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51035.
17/10/26 12:31:54 INFO NettyBlockTransferService: Server created on 127.0.0.1:51035
17/10/26 12:31:54 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:31:54 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51035 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:54 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51035, None)
17/10/26 12:31:55 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:31:55 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:31:55 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:31:56 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:31:56 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:31:56 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:31:56 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:31:57 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:31:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:58 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:31:59 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:31:59 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:31:59 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:31:59 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:31:59 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:31:59 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:31:59 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:32:00 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:32:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/1f954c31-031c-4df1-b1ca-f1d4ddc996dc_resources
17/10/26 12:32:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1f954c31-031c-4df1-b1ca-f1d4ddc996dc
17/10/26 12:32:00 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/1f954c31-031c-4df1-b1ca-f1d4ddc996dc
17/10/26 12:32:00 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/1f954c31-031c-4df1-b1ca-f1d4ddc996dc/_tmp_space.db
17/10/26 12:32:00 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:00 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:32:00 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:32:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:32:00 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:32:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:02 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:32:02 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:32:02 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:32:02 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:02 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 12:32:03 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:03 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:03 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:08 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:32:08 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan`
LIMIT 10
17/10/26 12:32:08 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:32:08 INFO HiveMetaStore: 0: get_table : db=default tbl=loan
17/10/26 12:32:08 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_table : db=default tbl=loan	
17/10/26 12:33:09 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:09 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:09 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:09 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:09 INFO CodeGenerator: Code generated in 261.525995 ms
17/10/26 12:33:09 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:09 INFO DAGScheduler: Got job 0 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:09 INFO DAGScheduler: Final stage: ResultStage 0 (collect at utils.scala:58)
17/10/26 12:33:09 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:09 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:09 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:09 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 8.7 KB, free 366.3 MB)
17/10/26 12:33:09 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 4.6 KB, free 366.3 MB)
17/10/26 12:33:09 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 366.3 MB)
17/10/26 12:33:09 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:09 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[7] at map at utils.scala:55)
17/10/26 12:33:09 INFO TaskSchedulerImpl: Adding task set 0.0 with 1 tasks
17/10/26 12:33:09 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, localhost, executor driver, partition 0, PROCESS_LOCAL, 11567 bytes)
17/10/26 12:33:09 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
17/10/26 12:33:09 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:09 INFO TransportClientFactory: Successfully created connection to /127.0.0.1:51014 after 21 ms (0 ms spent in bootstraps)
17/10/26 12:33:09 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-spatial-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4538265892678357967.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-spatial-4.0.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.slf4j_slf4j-api-1.7.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1236513025519203811.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.slf4j_slf4j-api-1.7.7.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/no.priv.garshol.duke_duke-1.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1377536444527190445.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/no.priv.garshol.duke_duke-1.2.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-io_commons-io-2.4.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8179681095297755683.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-io_commons-io-2.4.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp109868044853850270.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.mapdb_mapdb-0.9.9.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4376044935354290871.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.mapdb_mapdb-0.9.9.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp291389613042413397.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2881234852237317599.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-core_2.11-2.1.0.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp296472265752173695.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508988714625
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-math3-3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5278027317843363465.tmp
17/10/26 12:33:10 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.commons_commons-math3-3.3.jar to class loader
17/10/26 12:33:10 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:10 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3565714841969790146.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.guava_guava-16.0.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4035740928405504691.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.guava_guava-16.0.1.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-lang_commons-lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7214555985962094543.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-lang_commons-lang-2.6.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.thoughtworks.paranamer_paranamer-2.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1385207066554943384.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.thoughtworks.paranamer_paranamer-2.7.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9156682542284577715.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4548688767074081013.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-persist-s3-3.10.3.2.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7434995111638416445.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6338910772806519009.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_reflections-0.9.11-h2o-custom.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2216319545242161809.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.code.findbugs_jsr305-3.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1833434471663862358.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.code.findbugs_jsr305-3.0.0.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508988714641
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpclient-4.3.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4196724794493333014.tmp
17/10/26 12:33:11 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.httpcomponents_httpclient-4.3.6.jar to class loader
17/10/26 12:33:11 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:11 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7237494339960419907.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-scala_2.11-3.10.3.2.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-queries-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8528740447917964528.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-queries-4.0.0.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/log4j_log4j-1.2.15.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4620540613676473195.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/log4j_log4j-1.2.15.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.spatial4j_spatial4j-0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3227663094409964617.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.spatial4j_spatial4j-0.3.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9201625664266906999.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.xerial.snappy_snappy-java-1.1.1.3.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5256630960774460734.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2102617087062889560.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5075814489828172971.tmp
17/10/26 12:33:12 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar to class loader
17/10/26 12:33:12 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:12 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5999499322108443416.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-s3-1.10.47.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp1853662851787099237.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.directory.studio_org.apache.commons.lang-2.6.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3358259015777395391.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-algos-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4983555126268866886.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-algos-3.10.3.2.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.httpcomponents_httpcore-4.3.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6074303159581067209.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.httpcomponents_httpcore-4.3.3.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.avro_avro-1.8.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7152040242858127353.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.avro_avro-1.8.0.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5049634319436791711.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2427702402906067174.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-app-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2937106626256919957.tmp
17/10/26 12:33:13 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-app-3.10.3.2.jar to class loader
17/10/26 12:33:13 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:13 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6884348441972350913.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp757294185447395660.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-kms-1.10.47.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/joda-time_joda-time-2.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3043354224595078081.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/joda-time_joda-time-2.8.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/net.sf.opencsv_opencsv-2.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2859253994937853049.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/net.sf.opencsv_opencsv-2.3.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.commons_commons-compress-1.8.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp9002984649002133946.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.commons_commons-compress-1.8.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8915385531346784278.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar with timestamp 1508988714625
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.joda_joda-convert-1.7.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7920565673104483939.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.joda_joda-convert-1.7.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.tukaani_xz-1.5.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7585864083323856940.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.tukaani_xz-1.5.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.google.code.gson_gson-2.3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2280057554288917348.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.google.code.gson_gson-2.3.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/net.java.dev.jets3t_jets3t-0.6.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8140688235026206902.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/net.java.dev.jets3t_jets3t-0.6.1.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508988714625
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/gov.nist.math_jama-1.0.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3442801396414298015.tmp
17/10/26 12:33:14 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/gov.nist.math_jama-1.0.3.jar to class loader
17/10/26 12:33:14 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:14 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6795398039267343543.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-analyzers-common-4.0.0.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2484551595630329114.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.amazonaws_aws-java-sdk-core-1.10.47.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7791571876825715756.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp8644539675530123879.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.javassist_javassist-3.18.2-GA.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4270781903518583397.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.javassist_javassist-3.18.2-GA.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-logging_commons-logging-1.1.3.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3775787846042486786.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-logging_commons-logging-1.1.3.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp7805517981652153091.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-web-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2374144562178352733.tmp
17/10/26 12:33:15 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-web-3.10.3.2.jar to class loader
17/10/26 12:33:15 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508988714641
17/10/26 12:33:15 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5142273720018394959.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.codehaus.jackson_jackson-core-asl-1.9.13.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2534457644108962218.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-genmodel-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/sparklyr-2.1-2.11.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6200938923437399476.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/sparklyr-2.1-2.11.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_deepwater-backend-api-1.0.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp978319024549181825.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_deepwater-backend-api-1.0.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp2065538873526141800.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-core-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp81212568038217726.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-core-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3449236676076474705.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/org.apache.lucene_lucene-core-4.0.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5628138313220619796.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/org.apache.lucene_lucene-core-4.0.0.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508988714641
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-httpclient_commons-httpclient-3.1.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp3935675755332170313.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-httpclient_commons-httpclient-3.1.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5321257166640436909.tmp
17/10/26 12:33:16 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-avro-parser-3.10.3.2.jar to class loader
17/10/26 12:33:16 INFO Executor: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508988714625
17/10/26 12:33:16 INFO Utils: Fetching spark://127.0.0.1:51014/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp6111133669641660252.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar to class loader
17/10/26 12:33:17 INFO Executor: Fetching spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508988714641
17/10/26 12:33:17 INFO Utils: Fetching spark://127.0.0.1:51014/jars/com.github.rwl_jtransforms-2.4.0.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp5434003446556536773.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/com.github.rwl_jtransforms-2.4.0.jar to class loader
17/10/26 12:33:17 INFO Executor: Fetching spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508988714641
17/10/26 12:33:17 INFO Utils: Fetching spark://127.0.0.1:51014/jars/commons-codec_commons-codec-1.6.jar to C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0\fetchFileTemp4303909923351482728.tmp
17/10/26 12:33:17 INFO Executor: Adding file:/C:/Users/scibr/AppData/Local/Temp/spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579/userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0/commons-codec_commons-codec-1.6.jar to class loader
17/10/26 12:33:17 INFO CodeGenerator: Code generated in 14.02174 ms
17/10/26 12:33:17 INFO CodeGenerator: Code generated in 13.213475 ms
17/10/26 12:33:17 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1318 bytes result sent to driver
17/10/26 12:33:17 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 7827 ms on localhost (executor driver) (1/1)
17/10/26 12:33:17 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool 
17/10/26 12:33:17 INFO DAGScheduler: ResultStage 0 (collect at utils.scala:58) finished in 7.847 s
17/10/26 12:33:17 INFO DAGScheduler: Job 0 finished: collect at utils.scala:58, took 8.049218 s
17/10/26 12:33:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: loan
17/10/26 12:33:19 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: CACHE TABLE `loan`
17/10/26 12:33:19 INFO SparkSqlParser: Parsing command: `loan`
17/10/26 12:33:19 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:19 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:19 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, anon_ssn: string, payFrequency: string, apr: double, applicationDate: double ... 17 more fields>
17/10/26 12:33:19 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:19 INFO CodeGenerator: Code generated in 6.776088 ms
17/10/26 12:33:19 INFO ContextCleaner: Cleaned accumulator 0
17/10/26 12:33:19 INFO ContextCleaner: Cleaned accumulator 1
17/10/26 12:33:19 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 303.3 KB, free 366.0 MB)
17/10/26 12:33:19 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 25.7 KB, free 366.0 MB)
17/10/26 12:33:19 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 366.3 MB)
17/10/26 12:33:19 INFO SparkContext: Created broadcast 1 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:19 INFO FileSourceScanExec: Planning scan with bin packing, max size: 26961036 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:19 INFO BlockManagerInfo: Removed broadcast_0_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 366.3 MB)
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 13.290964 ms
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 10.703488 ms
17/10/26 12:33:20 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:20 INFO DAGScheduler: Registering RDD 14 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO DAGScheduler: Got job 1 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:20 INFO DAGScheduler: Final stage: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 1)
17/10/26 12:33:20 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 1)
17/10/26 12:33:20 INFO DAGScheduler: Submitting ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:20 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 26.9 KB, free 366.0 MB)
17/10/26 12:33:20 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 11.2 KB, free 365.9 MB)
17/10/26 12:33:20 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 127.0.0.1:51035 (size: 11.2 KB, free: 366.3 MB)
17/10/26 12:33:20 INFO SparkContext: Created broadcast 2 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:20 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 1 (MapPartitionsRDD[14] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:20 INFO TaskSchedulerImpl: Adding task set 1.0 with 4 tasks
17/10/26 12:33:20 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 1.0 in stage 1.0 (TID 2, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 2.0 in stage 1.0 (TID 3, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO TaskSetManager: Starting task 3.0 in stage 1.0 (TID 4, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:20 INFO Executor: Running task 0.0 in stage 1.0 (TID 1)
17/10/26 12:33:20 INFO Executor: Running task 1.0 in stage 1.0 (TID 2)
17/10/26 12:33:20 INFO Executor: Running task 3.0 in stage 1.0 (TID 4)
17/10/26 12:33:20 INFO Executor: Running task 2.0 in stage 1.0 (TID 3)
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 53922072-80883108, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 26961036-53922072, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 0-26961036, partition values: [empty row]
17/10/26 12:33:20 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_0d459fa54295ad7e6cced03e5ff393c5337b4ba16a975e0244f149ff04275639.csv, range: 80883108-103649842, partition values: [empty row]
17/10/26 12:33:20 INFO CodeGenerator: Code generated in 53.225442 ms
17/10/26 12:33:21 INFO ContextCleaner: Cleaned accumulator 54
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_3 stored as values in memory (estimated size 15.4 MB, free 350.5 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_3 in memory on 127.0.0.1:51035 (size: 15.4 MB, free: 350.9 MB)
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 5.743047 ms
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 25.002861 ms
17/10/26 12:33:24 INFO Executor: Finished task 3.0 in stage 1.0 (TID 4). 2980 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 3.0 in stage 1.0 (TID 4) in 4117 ms on localhost (executor driver) (1/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_0 stored as values in memory (estimated size 18.2 MB, free 332.3 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_0 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 332.6 MB)
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 1.0 (TID 1). 2893 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 4359 ms on localhost (executor driver) (2/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_1 stored as values in memory (estimated size 18.2 MB, free 314.1 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_1 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 314.4 MB)
17/10/26 12:33:24 INFO Executor: Finished task 1.0 in stage 1.0 (TID 2). 2983 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 1.0 in stage 1.0 (TID 2) in 4450 ms on localhost (executor driver) (3/4)
17/10/26 12:33:24 INFO MemoryStore: Block rdd_11_2 stored as values in memory (estimated size 18.2 MB, free 295.9 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added rdd_11_2 in memory on 127.0.0.1:51035 (size: 18.2 MB, free: 296.2 MB)
17/10/26 12:33:24 INFO Executor: Finished task 2.0 in stage 1.0 (TID 3). 2893 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 2.0 in stage 1.0 (TID 3) in 4514 ms on localhost (executor driver) (4/4)
17/10/26 12:33:24 INFO DAGScheduler: ShuffleMapStage 1 (sql at NativeMethodAccessorImpl.java:0) finished in 4.520 s
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:24 INFO DAGScheduler: running: Set()
17/10/26 12:33:24 INFO DAGScheduler: waiting: Set(ResultStage 2)
17/10/26 12:33:24 INFO DAGScheduler: failed: Set()
17/10/26 12:33:24 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 7.0 KB, free 295.9 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.9 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[17] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 5, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 2.0 (TID 5)
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 8 ms
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 2.0 (TID 5). 1952 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ResultStage 2 (sql at NativeMethodAccessorImpl.java:0) finished in 0.049 s
17/10/26 12:33:24 INFO DAGScheduler: Job 1 finished: sql at NativeMethodAccessorImpl.java:0, took 4.644159 s
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 5) in 47 ms on localhost (executor driver) (1/1)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO CodeGenerator: Code generated in 6.763772 ms
17/10/26 12:33:24 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:24 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `loan`
17/10/26 12:33:24 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:24 INFO DAGScheduler: Registering RDD 21 (collect at utils.scala:196)
17/10/26 12:33:24 INFO DAGScheduler: Got job 2 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:24 INFO DAGScheduler: Final stage: ResultStage 4 (collect at utils.scala:196)
17/10/26 12:33:24 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 3)
17/10/26 12:33:24 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 3)
17/10/26 12:33:24 INFO DAGScheduler: Submitting ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 26.9 KB, free 295.8 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 11.2 KB, free 295.8 MB)
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 127.0.0.1:51035 (size: 11.2 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 4 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 3 (MapPartitionsRDD[21] at collect at utils.scala:196)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 3.0 with 4 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 6, localhost, executor driver, partition 0, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 1.0 in stage 3.0 (TID 7, localhost, executor driver, partition 1, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 2.0 in stage 3.0 (TID 8, localhost, executor driver, partition 2, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO TaskSetManager: Starting task 3.0 in stage 3.0 (TID 9, localhost, executor driver, partition 3, PROCESS_LOCAL, 12193 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 3.0 (TID 6)
17/10/26 12:33:24 INFO Executor: Running task 1.0 in stage 3.0 (TID 7)
17/10/26 12:33:24 INFO Executor: Running task 2.0 in stage 3.0 (TID 8)
17/10/26 12:33:24 INFO Executor: Running task 3.0 in stage 3.0 (TID 9)
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_2 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_0 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_3 locally
17/10/26 12:33:24 INFO BlockManager: Found block rdd_11_1 locally
17/10/26 12:33:24 INFO Executor: Finished task 2.0 in stage 3.0 (TID 8). 2019 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 2.0 in stage 3.0 (TID 8) in 42 ms on localhost (executor driver) (1/4)
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 3.0 (TID 6). 2098 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 6) in 54 ms on localhost (executor driver) (2/4)
17/10/26 12:33:24 INFO Executor: Finished task 3.0 in stage 3.0 (TID 9). 2098 bytes result sent to driver
17/10/26 12:33:24 INFO TaskSetManager: Finished task 3.0 in stage 3.0 (TID 9) in 52 ms on localhost (executor driver) (3/4)
17/10/26 12:33:24 INFO Executor: Finished task 1.0 in stage 3.0 (TID 7). 2109 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ShuffleMapStage 3 (collect at utils.scala:196) finished in 0.066 s
17/10/26 12:33:24 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:24 INFO DAGScheduler: running: Set()
17/10/26 12:33:24 INFO DAGScheduler: waiting: Set(ResultStage 4)
17/10/26 12:33:24 INFO DAGScheduler: failed: Set()
17/10/26 12:33:24 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:24 INFO TaskSetManager: Finished task 1.0 in stage 3.0 (TID 7) in 63 ms on localhost (executor driver) (4/4)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 7.0 KB, free 295.8 MB)
17/10/26 12:33:24 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 3.7 KB, free 295.8 MB)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool 
17/10/26 12:33:24 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 296.2 MB)
17/10/26 12:33:24 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:24 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[24] at collect at utils.scala:196)
17/10/26 12:33:24 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks
17/10/26 12:33:24 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 10, localhost, executor driver, partition 0, ANY, 11470 bytes)
17/10/26 12:33:24 INFO Executor: Running task 0.0 in stage 4.0 (TID 10)
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:24 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:24 INFO Executor: Finished task 0.0 in stage 4.0 (TID 10). 1873 bytes result sent to driver
17/10/26 12:33:24 INFO DAGScheduler: ResultStage 4 (collect at utils.scala:196) finished in 0.008 s
17/10/26 12:33:24 INFO DAGScheduler: Job 2 finished: collect at utils.scala:196, took 0.094926 s
17/10/26 12:33:25 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 10) in 6 ms on localhost (executor driver) (1/1)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool 
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:25 INFO SparkSqlParser: Parsing command: SELECT *
FROM `loan` AS `zzz10`
WHERE (0 = 1)
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:25 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:25 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:25 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:25 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:25 INFO DAGScheduler: Got job 3 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:25 INFO DAGScheduler: Final stage: ResultStage 5 (collect at utils.scala:58)
17/10/26 12:33:25 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:25 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:25 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:25 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 8.7 KB, free 295.8 MB)
17/10/26 12:33:25 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 4.6 KB, free 295.8 MB)
17/10/26 12:33:25 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 296.2 MB)
17/10/26 12:33:25 INFO SparkContext: Created broadcast 6 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:25 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[30] at map at utils.scala:55)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Adding task set 5.0 with 1 tasks
17/10/26 12:33:25 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 11, localhost, executor driver, partition 0, PROCESS_LOCAL, 11878 bytes)
17/10/26 12:33:25 INFO Executor: Running task 0.0 in stage 5.0 (TID 11)
17/10/26 12:33:25 INFO Executor: Finished task 0.0 in stage 5.0 (TID 11). 1159 bytes result sent to driver
17/10/26 12:33:25 INFO DAGScheduler: ResultStage 5 (collect at utils.scala:58) finished in 0.014 s
17/10/26 12:33:25 INFO DAGScheduler: Job 3 finished: collect at utils.scala:58, took 0.018642 s
17/10/26 12:33:25 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 11) in 12 ms on localhost (executor driver) (1/1)
17/10/26 12:33:25 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool 
17/10/26 12:33:25 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: payment
17/10/26 12:33:26 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: CACHE TABLE `payment`
17/10/26 12:33:26 INFO SparkSqlParser: Parsing command: `payment`
17/10/26 12:33:26 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:26 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:26 INFO FileSourceStrategy: Output Data Schema: struct<loanId: string, installmentIndex: int, isCollection: boolean, paymentDate: double, principal: double ... 7 more fields>
17/10/26 12:33:26 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 303.3 KB, free 295.5 MB)
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 25.7 KB, free 295.5 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO SparkContext: Created broadcast 7 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:26 INFO FileSourceScanExec: Planning scan with bin packing, max size: 14247951 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:26 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:26 INFO DAGScheduler: Registering RDD 37 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO DAGScheduler: Got job 4 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:26 INFO DAGScheduler: Final stage: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 6)
17/10/26 12:33:26 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 6)
17/10/26 12:33:26 INFO DAGScheduler: Submitting ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 20.7 KB, free 295.4 MB)
17/10/26 12:33:26 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 9.4 KB, free 295.4 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 127.0.0.1:51035 (size: 9.4 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:26 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 6 (MapPartitionsRDD[37] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:26 INFO TaskSchedulerImpl: Adding task set 6.0 with 4 tasks
17/10/26 12:33:26 INFO TaskSetManager: Starting task 0.0 in stage 6.0 (TID 12, localhost, executor driver, partition 0, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 1.0 in stage 6.0 (TID 13, localhost, executor driver, partition 1, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 2.0 in stage 6.0 (TID 14, localhost, executor driver, partition 2, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO TaskSetManager: Starting task 3.0 in stage 6.0 (TID 15, localhost, executor driver, partition 3, PROCESS_LOCAL, 12201 bytes)
17/10/26 12:33:26 INFO Executor: Running task 0.0 in stage 6.0 (TID 12)
17/10/26 12:33:26 INFO Executor: Running task 1.0 in stage 6.0 (TID 13)
17/10/26 12:33:26 INFO Executor: Running task 2.0 in stage 6.0 (TID 14)
17/10/26 12:33:26 INFO Executor: Running task 3.0 in stage 6.0 (TID 15)
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 42743853-52797501, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 14247951-28495902, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 28495902-42743853, partition values: [empty row]
17/10/26 12:33:26 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_3f085fadccd6d76fe20a1fba40f7fc3c0ee1b8d25ef09d59fbfd0eb7c3b8f156.csv, range: 0-14247951, partition values: [empty row]
17/10/26 12:33:26 INFO CodeGenerator: Code generated in 19.158716 ms
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 235
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_4_piece0 on 127.0.0.1:51035 in memory (size: 11.2 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 416
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 417
17/10/26 12:33:26 INFO BlockManagerInfo: Removed broadcast_6_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 296.1 MB)
17/10/26 12:33:26 INFO ContextCleaner: Cleaned accumulator 470
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_3 stored as values in memory (estimated size 5.1 MB, free 290.4 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_3 in memory on 127.0.0.1:51035 (size: 5.1 MB, free: 291.0 MB)
17/10/26 12:33:28 INFO Executor: Finished task 3.0 in stage 6.0 (TID 15). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 3.0 in stage 6.0 (TID 15) in 1957 ms on localhost (executor driver) (1/4)
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_2 stored as values in memory (estimated size 7.1 MB, free 283.2 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_2 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 283.9 MB)
17/10/26 12:33:28 INFO Executor: Finished task 2.0 in stage 6.0 (TID 14). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 2.0 in stage 6.0 (TID 14) in 2454 ms on localhost (executor driver) (2/4)
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_0 stored as values in memory (estimated size 7.1 MB, free 276.1 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_0 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 276.8 MB)
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 6.0 (TID 12). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO MemoryStore: Block rdd_34_1 stored as values in memory (estimated size 7.1 MB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added rdd_34_1 in memory on 127.0.0.1:51035 (size: 7.1 MB, free: 269.7 MB)
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 6.0 (TID 12) in 2534 ms on localhost (executor driver) (3/4)
17/10/26 12:33:28 INFO Executor: Finished task 1.0 in stage 6.0 (TID 13). 2893 bytes result sent to driver
17/10/26 12:33:28 INFO DAGScheduler: ShuffleMapStage 6 (sql at NativeMethodAccessorImpl.java:0) finished in 2.548 s
17/10/26 12:33:28 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:28 INFO DAGScheduler: running: Set()
17/10/26 12:33:28 INFO DAGScheduler: waiting: Set(ResultStage 7)
17/10/26 12:33:28 INFO DAGScheduler: failed: Set()
17/10/26 12:33:28 INFO DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO TaskSetManager: Finished task 1.0 in stage 6.0 (TID 13) in 2545 ms on localhost (executor driver) (4/4)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 6.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 7 (MapPartitionsRDD[40] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 7.0 with 1 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 7.0 (TID 16, localhost, executor driver, partition 0, ANY, 11478 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 7.0 (TID 16)
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 7.0 (TID 16). 1873 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 7.0 (TID 16) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 7.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ResultStage 7 (sql at NativeMethodAccessorImpl.java:0) finished in 0.009 s
17/10/26 12:33:28 INFO DAGScheduler: Job 4 finished: sql at NativeMethodAccessorImpl.java:0, took 2.573610 s
17/10/26 12:33:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:28 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `payment`
17/10/26 12:33:28 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:28 INFO DAGScheduler: Registering RDD 44 (collect at utils.scala:196)
17/10/26 12:33:28 INFO DAGScheduler: Got job 5 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:28 INFO DAGScheduler: Final stage: ResultStage 9 (collect at utils.scala:196)
17/10/26 12:33:28 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 8)
17/10/26 12:33:28 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 8)
17/10/26 12:33:28 INFO DAGScheduler: Submitting ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 20.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 9.4 KB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 127.0.0.1:51035 (size: 9.4 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 8 (MapPartitionsRDD[44] at collect at utils.scala:196)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 8.0 with 4 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 8.0 (TID 17, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 1.0 in stage 8.0 (TID 18, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 2.0 in stage 8.0 (TID 19, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO TaskSetManager: Starting task 3.0 in stage 8.0 (TID 20, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 8.0 (TID 17)
17/10/26 12:33:28 INFO Executor: Running task 1.0 in stage 8.0 (TID 18)
17/10/26 12:33:28 INFO Executor: Running task 2.0 in stage 8.0 (TID 19)
17/10/26 12:33:28 INFO Executor: Running task 3.0 in stage 8.0 (TID 20)
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_3 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_1 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 12:33:28 INFO BlockManager: Found block rdd_34_2 locally
17/10/26 12:33:28 INFO Executor: Finished task 1.0 in stage 8.0 (TID 18). 2185 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 1.0 in stage 8.0 (TID 18) in 37 ms on localhost (executor driver) (1/4)
17/10/26 12:33:28 INFO Executor: Finished task 3.0 in stage 8.0 (TID 20). 2098 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 3.0 in stage 8.0 (TID 20) in 41 ms on localhost (executor driver) (2/4)
17/10/26 12:33:28 INFO Executor: Finished task 2.0 in stage 8.0 (TID 19). 2098 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 2.0 in stage 8.0 (TID 19) in 49 ms on localhost (executor driver) (3/4)
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 8.0 (TID 17). 2019 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 8.0 (TID 17) in 54 ms on localhost (executor driver) (4/4)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 8.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ShuffleMapStage 8 (collect at utils.scala:196) finished in 0.054 s
17/10/26 12:33:28 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:28 INFO DAGScheduler: running: Set()
17/10/26 12:33:28 INFO DAGScheduler: waiting: Set(ResultStage 9)
17/10/26 12:33:28 INFO DAGScheduler: failed: Set()
17/10/26 12:33:28 INFO DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 7.0 KB, free 269.0 MB)
17/10/26 12:33:28 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 3.7 KB, free 269.0 MB)
17/10/26 12:33:28 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:28 INFO SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:28 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[47] at collect at utils.scala:196)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Adding task set 9.0 with 1 tasks
17/10/26 12:33:28 INFO TaskSetManager: Starting task 0.0 in stage 9.0 (TID 21, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 12:33:28 INFO Executor: Running task 0.0 in stage 9.0 (TID 21)
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:28 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 12:33:28 INFO Executor: Finished task 0.0 in stage 9.0 (TID 21). 1873 bytes result sent to driver
17/10/26 12:33:28 INFO TaskSetManager: Finished task 0.0 in stage 9.0 (TID 21) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:28 INFO TaskSchedulerImpl: Removed TaskSet 9.0, whose tasks have all completed, from pool 
17/10/26 12:33:28 INFO DAGScheduler: ResultStage 9 (collect at utils.scala:196) finished in 0.009 s
17/10/26 12:33:28 INFO DAGScheduler: Job 5 finished: collect at utils.scala:196, took 0.077404 s
17/10/26 12:33:28 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:28 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment` AS `zzz11`
WHERE (0 = 1)
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 INFO CodeGenerator: Code generated in 7.535087 ms
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:29 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:29 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:29 INFO SparkContext: Starting job: collect at utils.scala:58
17/10/26 12:33:29 INFO DAGScheduler: Got job 6 (collect at utils.scala:58) with 1 output partitions
17/10/26 12:33:29 INFO DAGScheduler: Final stage: ResultStage 10 (collect at utils.scala:58)
17/10/26 12:33:29 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:29 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:29 INFO DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55), which has no missing parents
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 8.7 KB, free 269.0 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 4.6 KB, free 269.0 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 127.0.0.1:51035 (size: 4.6 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 12 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:29 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[55] at map at utils.scala:55)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Adding task set 10.0 with 1 tasks
17/10/26 12:33:29 INFO TaskSetManager: Starting task 0.0 in stage 10.0 (TID 22, localhost, executor driver, partition 0, PROCESS_LOCAL, 11933 bytes)
17/10/26 12:33:29 INFO Executor: Running task 0.0 in stage 10.0 (TID 22)
17/10/26 12:33:29 INFO Executor: Finished task 0.0 in stage 10.0 (TID 22). 1079 bytes result sent to driver
17/10/26 12:33:29 INFO DAGScheduler: ResultStage 10 (collect at utils.scala:58) finished in 0.009 s
17/10/26 12:33:29 INFO DAGScheduler: Job 6 finished: collect at utils.scala:58, took 0.015390 s
17/10/26 12:33:29 INFO TaskSetManager: Finished task 0.0 in stage 10.0 (TID 22) in 9 ms on localhost (executor driver) (1/1)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Removed TaskSet 10.0, whose tasks have all completed, from pool 
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_11_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 832
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 833
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_12_piece0 on 127.0.0.1:51035 in memory (size: 4.6 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_9_piece0 on 127.0.0.1:51035 in memory (size: 3.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO ContextCleaner: Cleaned accumulator 651
17/10/26 12:33:29 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 127.0.0.1:51035 in memory (size: 9.4 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: cuv
17/10/26 12:33:29 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: CACHE TABLE `cuv`
17/10/26 12:33:29 INFO SparkSqlParser: Parsing command: `cuv`
17/10/26 12:33:29 INFO FileSourceStrategy: Pruning directories with: 
17/10/26 12:33:29 INFO FileSourceStrategy: Post-Scan Filters: 
17/10/26 12:33:29 INFO FileSourceStrategy: Output Data Schema: struct<_underwritingdataclarity_clearfraud_clearfraudinquiry_thirtydaysago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_twentyfourhoursago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_oneminuteago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_onehourago: int, _underwritingdataclarity_clearfraud_clearfraudinquiry_ninetydaysago: int ... 52 more fields>
17/10/26 12:33:29 INFO FileSourceStrategy: Pushed Filters: 
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 303.3 KB, free 268.8 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 25.7 KB, free 268.7 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 127.0.0.1:51035 (size: 25.7 KB, free: 269.7 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 13 from sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:29 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4835699 bytes, open cost is considered as scanning 4194304 bytes.
17/10/26 12:33:29 WARN Utils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.debug.maxToStringFields' in SparkEnv.conf.
17/10/26 12:33:29 INFO SparkContext: Starting job: sql at NativeMethodAccessorImpl.java:0
17/10/26 12:33:29 INFO DAGScheduler: Registering RDD 62 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO DAGScheduler: Got job 7 (sql at NativeMethodAccessorImpl.java:0) with 1 output partitions
17/10/26 12:33:29 INFO DAGScheduler: Final stage: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 11)
17/10/26 12:33:29 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 11)
17/10/26 12:33:29 INFO DAGScheduler: Submitting ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_14 stored as values in memory (estimated size 71.4 KB, free 268.7 MB)
17/10/26 12:33:29 INFO MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 19.5 KB, free 268.6 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added broadcast_14_piece0 in memory on 127.0.0.1:51035 (size: 19.5 KB, free: 269.6 MB)
17/10/26 12:33:29 INFO SparkContext: Created broadcast 14 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:29 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 11 (MapPartitionsRDD[62] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:29 INFO TaskSchedulerImpl: Adding task set 11.0 with 4 tasks
17/10/26 12:33:29 INFO TaskSetManager: Starting task 0.0 in stage 11.0 (TID 23, localhost, executor driver, partition 0, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 1.0 in stage 11.0 (TID 24, localhost, executor driver, partition 1, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 2.0 in stage 11.0 (TID 25, localhost, executor driver, partition 2, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO TaskSetManager: Starting task 3.0 in stage 11.0 (TID 26, localhost, executor driver, partition 3, PROCESS_LOCAL, 12202 bytes)
17/10/26 12:33:29 INFO Executor: Running task 0.0 in stage 11.0 (TID 23)
17/10/26 12:33:29 INFO Executor: Running task 1.0 in stage 11.0 (TID 24)
17/10/26 12:33:29 INFO Executor: Running task 2.0 in stage 11.0 (TID 25)
17/10/26 12:33:29 INFO Executor: Running task 3.0 in stage 11.0 (TID 26)
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 4835699-9671398, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 9671398-14507097, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 14507097-15148492, partition values: [empty row]
17/10/26 12:33:29 INFO FileScanRDD: Reading File path: file:///C:/Users/scibr/AppData/Local/Temp/RtmpymdyhI/spark_serialize_25f77d5909ac1244391eebbaae86eb8d488769b7bc9ec117b0fa316f8f42c2a7.csv, range: 0-4835699, partition values: [empty row]
17/10/26 12:33:29 INFO CodeGenerator: Code generated in 37.229994 ms
17/10/26 12:33:29 INFO MemoryStore: Block rdd_59_3 stored as values in memory (estimated size 198.6 KB, free 268.4 MB)
17/10/26 12:33:29 INFO BlockManagerInfo: Added rdd_59_3 in memory on 127.0.0.1:51035 (size: 198.6 KB, free: 269.4 MB)
17/10/26 12:33:29 INFO Executor: Finished task 3.0 in stage 11.0 (TID 26). 2820 bytes result sent to driver
17/10/26 12:33:29 INFO TaskSetManager: Finished task 3.0 in stage 11.0 (TID 26) in 290 ms on localhost (executor driver) (1/4)
17/10/26 12:33:30 INFO ContextCleaner: Cleaned accumulator 886
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_2 stored as values in memory (estimated size 1444.5 KB, free 267.0 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_2 in memory on 127.0.0.1:51035 (size: 1444.5 KB, free: 268.0 MB)
17/10/26 12:33:30 INFO Executor: Finished task 2.0 in stage 11.0 (TID 25). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 2.0 in stage 11.0 (TID 25) in 618 ms on localhost (executor driver) (2/4)
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_0 stored as values in memory (estimated size 1296.0 KB, free 265.8 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_0 in memory on 127.0.0.1:51035 (size: 1296.0 KB, free: 266.8 MB)
17/10/26 12:33:30 INFO MemoryStore: Block rdd_59_1 stored as values in memory (estimated size 1374.8 KB, free 264.4 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added rdd_59_1 in memory on 127.0.0.1:51035 (size: 1374.8 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 11.0 (TID 23). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 11.0 (TID 23) in 642 ms on localhost (executor driver) (3/4)
17/10/26 12:33:30 INFO Executor: Finished task 1.0 in stage 11.0 (TID 24). 2893 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 1.0 in stage 11.0 (TID 24) in 654 ms on localhost (executor driver) (4/4)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 11.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ShuffleMapStage 11 (sql at NativeMethodAccessorImpl.java:0) finished in 0.656 s
17/10/26 12:33:30 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:30 INFO DAGScheduler: running: Set()
17/10/26 12:33:30 INFO DAGScheduler: waiting: Set(ResultStage 12)
17/10/26 12:33:30 INFO DAGScheduler: failed: Set()
17/10/26 12:33:30 INFO DAGScheduler: Submitting ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_15 stored as values in memory (estimated size 7.0 KB, free 264.4 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.4 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_15_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 12 (MapPartitionsRDD[65] at sql at NativeMethodAccessorImpl.java:0)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 12.0 with 1 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 12.0 (TID 27, localhost, executor driver, partition 0, ANY, 11479 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 12.0 (TID 27)
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 1 ms
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 12.0 (TID 27). 1873 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 12.0 (TID 27) in 7 ms on localhost (executor driver) (1/1)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 12.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ResultStage 12 (sql at NativeMethodAccessorImpl.java:0) finished in 0.008 s
17/10/26 12:33:30 INFO DAGScheduler: Job 7 finished: sql at NativeMethodAccessorImpl.java:0, took 0.683479 s
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SELECT count(*) FROM  `cuv`
17/10/26 12:33:30 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:30 INFO DAGScheduler: Registering RDD 69 (collect at utils.scala:196)
17/10/26 12:33:30 INFO DAGScheduler: Got job 8 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:30 INFO DAGScheduler: Final stage: ResultStage 14 (collect at utils.scala:196)
17/10/26 12:33:30 INFO DAGScheduler: Parents of final stage: List(ShuffleMapStage 13)
17/10/26 12:33:30 INFO DAGScheduler: Missing parents: List(ShuffleMapStage 13)
17/10/26 12:33:30 INFO DAGScheduler: Submitting ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_16 stored as values in memory (estimated size 71.4 KB, free 264.3 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 19.5 KB, free 264.3 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_16_piece0 in memory on 127.0.0.1:51035 (size: 19.5 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 16 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 4 missing tasks from ShuffleMapStage 13 (MapPartitionsRDD[69] at collect at utils.scala:196)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 13.0 with 4 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 13.0 (TID 28, localhost, executor driver, partition 0, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 1.0 in stage 13.0 (TID 29, localhost, executor driver, partition 1, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 2.0 in stage 13.0 (TID 30, localhost, executor driver, partition 2, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO TaskSetManager: Starting task 3.0 in stage 13.0 (TID 31, localhost, executor driver, partition 3, PROCESS_LOCAL, 12194 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 13.0 (TID 28)
17/10/26 12:33:30 INFO Executor: Running task 1.0 in stage 13.0 (TID 29)
17/10/26 12:33:30 INFO Executor: Running task 2.0 in stage 13.0 (TID 30)
17/10/26 12:33:30 INFO Executor: Running task 3.0 in stage 13.0 (TID 31)
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_1 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_3 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_0 locally
17/10/26 12:33:30 INFO BlockManager: Found block rdd_59_2 locally
17/10/26 12:33:30 INFO Executor: Finished task 3.0 in stage 13.0 (TID 31). 2098 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 3.0 in stage 13.0 (TID 31) in 27 ms on localhost (executor driver) (1/4)
17/10/26 12:33:30 INFO Executor: Finished task 2.0 in stage 13.0 (TID 30). 2188 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 2.0 in stage 13.0 (TID 30) in 31 ms on localhost (executor driver) (2/4)
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 13.0 (TID 28). 2019 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 13.0 (TID 28) in 37 ms on localhost (executor driver) (3/4)
17/10/26 12:33:30 INFO Executor: Finished task 1.0 in stage 13.0 (TID 29). 2019 bytes result sent to driver
17/10/26 12:33:30 INFO TaskSetManager: Finished task 1.0 in stage 13.0 (TID 29) in 41 ms on localhost (executor driver) (4/4)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 13.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 INFO DAGScheduler: ShuffleMapStage 13 (collect at utils.scala:196) finished in 0.043 s
17/10/26 12:33:30 INFO DAGScheduler: looking for newly runnable stages
17/10/26 12:33:30 INFO DAGScheduler: running: Set()
17/10/26 12:33:30 INFO DAGScheduler: waiting: Set(ResultStage 14)
17/10/26 12:33:30 INFO DAGScheduler: failed: Set()
17/10/26 12:33:30 INFO DAGScheduler: Submitting ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_17 stored as values in memory (estimated size 7.0 KB, free 264.3 MB)
17/10/26 12:33:30 INFO MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 3.7 KB, free 264.3 MB)
17/10/26 12:33:30 INFO BlockManagerInfo: Added broadcast_17_piece0 in memory on 127.0.0.1:51035 (size: 3.7 KB, free: 265.4 MB)
17/10/26 12:33:30 INFO SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 14 (MapPartitionsRDD[72] at collect at utils.scala:196)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Adding task set 14.0 with 1 tasks
17/10/26 12:33:30 INFO TaskSetManager: Starting task 0.0 in stage 14.0 (TID 32, localhost, executor driver, partition 0, ANY, 11471 bytes)
17/10/26 12:33:30 INFO Executor: Running task 0.0 in stage 14.0 (TID 32)
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Getting 4 non-empty blocks out of 4 blocks
17/10/26 12:33:30 INFO ShuffleBlockFetcherIterator: Started 0 remote fetches in 0 ms
17/10/26 12:33:30 INFO Executor: Finished task 0.0 in stage 14.0 (TID 32). 1873 bytes result sent to driver
17/10/26 12:33:30 INFO DAGScheduler: ResultStage 14 (collect at utils.scala:196) finished in 0.005 s
17/10/26 12:33:30 INFO DAGScheduler: Job 8 finished: collect at utils.scala:196, took 0.060612 s
17/10/26 12:33:30 INFO TaskSetManager: Finished task 0.0 in stage 14.0 (TID 32) in 5 ms on localhost (executor driver) (1/1)
17/10/26 12:33:30 INFO TaskSchedulerImpl: Removed TaskSet 14.0, whose tasks have all completed, from pool 
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv` AS `zzz12`
WHERE (0 = 1)
17/10/26 12:33:30 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:30 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:33:30 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:33:30 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:33:38 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:33:38 INFO SparkSqlParser: Parsing command: SELECT *
FROM `cuv`
LIMIT 10
17/10/26 12:33:38 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:33:38 INFO DAGScheduler: Got job 9 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:33:38 INFO DAGScheduler: Final stage: ResultStage 15 (collect at utils.scala:196)
17/10/26 12:33:38 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:33:38 INFO DAGScheduler: Missing parents: List()
17/10/26 12:33:38 INFO DAGScheduler: Submitting ResultStage 15 (MapPartitionsRDD[75] at collect at utils.scala:196), which has no missing parents
17/10/26 12:33:38 INFO MemoryStore: Block broadcast_18 stored as values in memory (estimated size 67.5 KB, free 264.3 MB)
17/10/26 12:33:38 INFO MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 17.6 KB, free 264.2 MB)
17/10/26 12:33:38 INFO BlockManagerInfo: Added broadcast_18_piece0 in memory on 127.0.0.1:51035 (size: 17.6 KB, free: 265.4 MB)
17/10/26 12:33:38 INFO SparkContext: Created broadcast 18 from broadcast at DAGScheduler.scala:996
17/10/26 12:33:38 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 15 (MapPartitionsRDD[75] at collect at utils.scala:196)
17/10/26 12:33:38 INFO TaskSchedulerImpl: Adding task set 15.0 with 1 tasks
17/10/26 12:33:38 INFO TaskSetManager: Starting task 0.0 in stage 15.0 (TID 33, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 12:33:38 INFO Executor: Running task 0.0 in stage 15.0 (TID 33)
17/10/26 12:33:38 INFO BlockManager: Found block rdd_59_0 locally
17/10/26 12:33:38 INFO CodeGenerator: Code generated in 53.019654 ms
17/10/26 12:33:38 WARN Executor: 1 block locks were not released by TID = 33:
[rdd_59_0]
17/10/26 12:33:38 INFO Executor: Finished task 0.0 in stage 15.0 (TID 33). 2749 bytes result sent to driver
17/10/26 12:33:38 INFO TaskSetManager: Finished task 0.0 in stage 15.0 (TID 33) in 102 ms on localhost (executor driver) (1/1)
17/10/26 12:33:38 INFO TaskSchedulerImpl: Removed TaskSet 15.0, whose tasks have all completed, from pool 
17/10/26 12:33:38 INFO DAGScheduler: ResultStage 15 (collect at utils.scala:196) finished in 0.102 s
17/10/26 12:33:38 INFO DAGScheduler: Job 9 finished: collect at utils.scala:196, took 0.100025 s
17/10/26 12:33:38 INFO CodeGenerator: Code generated in 28.926156 ms
17/10/26 12:34:23 WARN SparkSession$Builder: Using an existing SparkSession; some configuration may not take effect.
17/10/26 12:34:23 INFO SparkSqlParser: Parsing command: SELECT *
FROM `payment`
LIMIT 10
17/10/26 12:34:23 INFO SparkContext: Starting job: collect at utils.scala:196
17/10/26 12:34:23 INFO DAGScheduler: Got job 10 (collect at utils.scala:196) with 1 output partitions
17/10/26 12:34:23 INFO DAGScheduler: Final stage: ResultStage 16 (collect at utils.scala:196)
17/10/26 12:34:23 INFO DAGScheduler: Parents of final stage: List()
17/10/26 12:34:23 INFO DAGScheduler: Missing parents: List()
17/10/26 12:34:23 INFO DAGScheduler: Submitting ResultStage 16 (MapPartitionsRDD[77] at collect at utils.scala:196), which has no missing parents
17/10/26 12:34:23 INFO MemoryStore: Block broadcast_19 stored as values in memory (estimated size 16.8 KB, free 264.2 MB)
17/10/26 12:34:23 INFO MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 7.9 KB, free 264.2 MB)
17/10/26 12:34:23 INFO BlockManagerInfo: Added broadcast_19_piece0 in memory on 127.0.0.1:51035 (size: 7.9 KB, free: 265.4 MB)
17/10/26 12:34:23 INFO SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:996
17/10/26 12:34:23 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 16 (MapPartitionsRDD[77] at collect at utils.scala:196)
17/10/26 12:34:23 INFO TaskSchedulerImpl: Adding task set 16.0 with 1 tasks
17/10/26 12:34:23 INFO TaskSetManager: Starting task 0.0 in stage 16.0 (TID 34, localhost, executor driver, partition 0, PROCESS_LOCAL, 12120 bytes)
17/10/26 12:34:23 INFO Executor: Running task 0.0 in stage 16.0 (TID 34)
17/10/26 12:34:23 INFO BlockManager: Found block rdd_34_0 locally
17/10/26 12:34:23 INFO CodeGenerator: Code generated in 16.106808 ms
17/10/26 12:34:23 WARN Executor: 1 block locks were not released by TID = 34:
[rdd_34_0]
17/10/26 12:34:23 INFO Executor: Finished task 0.0 in stage 16.0 (TID 34). 1735 bytes result sent to driver
17/10/26 12:34:23 INFO DAGScheduler: ResultStage 16 (collect at utils.scala:196) finished in 0.035 s
17/10/26 12:34:23 INFO DAGScheduler: Job 10 finished: collect at utils.scala:196, took 0.033198 s
17/10/26 12:34:23 INFO TaskSetManager: Finished task 0.0 in stage 16.0 (TID 34) in 35 ms on localhost (executor driver) (1/1)
17/10/26 12:34:23 INFO TaskSchedulerImpl: Removed TaskSet 16.0, whose tasks have all completed, from pool 
17/10/26 12:34:23 INFO CodeGenerator: Code generated in 9.763335 ms
17/10/26 12:38:17 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:38:17 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:38:17 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:38:17 INFO MemoryStore: MemoryStore cleared
17/10/26 12:38:17 INFO BlockManager: BlockManager stopped
17/10/26 12:38:17 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:38:17 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:38:17 WARN SparkEnv: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.SparkEnv.stop(SparkEnv.scala:102)
	at org.apache.spark.SparkContext$$anonfun$stop$11.apply$mcV$sp(SparkContext.scala:1842)
	at org.apache.spark.util.Utils$.tryLogNonFatalError(Utils.scala:1283)
	at org.apache.spark.SparkContext.stop(SparkContext.scala:1841)
	at org.apache.spark.SparkContext$$anonfun$2.apply$mcV$sp(SparkContext.scala:581)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:17 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:38:17 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:38:17 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
17/10/26 12:38:17 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:17 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
17/10/26 12:38:17 ERROR ShutdownHookManager: Exception while deleting Spark temp dir: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
java.io.IOException: Failed to delete: C:\Users\scibr\AppData\Local\Temp\spark-8175e85b-ae04-4d80-9d8b-2e061a4fc579\userFiles-f4497cc9-9639-4fc7-9e37-6a3d6dc18cd0
	at org.apache.spark.util.Utils$.deleteRecursively(Utils.scala:1010)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:65)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1$$anonfun$apply$mcV$sp$3.apply(ShutdownHookManager.scala:62)
	at scala.collection.IndexedSeqOptimized$class.foreach(IndexedSeqOptimized.scala:33)
	at scala.collection.mutable.ArrayOps$ofRef.foreach(ArrayOps.scala:186)
	at org.apache.spark.util.ShutdownHookManager$$anonfun$1.apply$mcV$sp(ShutdownHookManager.scala:62)
	at org.apache.spark.util.SparkShutdownHook.run(ShutdownHookManager.scala:216)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1$$anonfun$apply$mcV$sp$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:1951)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply$mcV$sp(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anonfun$runAll$1.apply(ShutdownHookManager.scala:188)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.util.SparkShutdownHookManager.runAll(ShutdownHookManager.scala:188)
	at org.apache.spark.util.SparkShutdownHookManager$$anon$2.run(ShutdownHookManager.scala:178)
	at org.apache.hadoop.util.ShutdownHookManager$1.run(ShutdownHookManager.java:54)
17/10/26 12:38:27 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:38:27 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:38:27 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:38:27 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:38:27 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:38:27 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:38:27 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:38:27 INFO Utils: Successfully started service 'sparkDriver' on port 51384.
17/10/26 12:38:27 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:38:27 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:38:27 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:38:27 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:38:27 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-a449b908-f043-4f76-9b37-2e6f503f7178
17/10/26 12:38:27 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:38:27 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:38:28 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:38:28 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508989108243
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51384/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51384/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508989108244
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51384/jars/org.joda_joda-convert-1.7.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508989108245
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51384/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51384/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51384/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51384/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51384/jars/commons-io_commons-io-2.4.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51384/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508989108246
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51384/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51384/jars/log4j_log4j-1.2.15.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51384/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51384/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51384/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51384/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51384/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51384/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508989108247
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508989108248
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51384/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51384/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51384/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51384/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51384/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51384/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51384/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51384/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508989108249
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51384/jars/org.tukaani_xz-1.5.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51384/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51384/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51384/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51384/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51384/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51384/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51384/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51384/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51384/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508989108250
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51384/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51384/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51384/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51384/jars/sparklyr-2.1-2.11.jar with timestamp 1508989108251
17/10/26 12:38:28 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:38:28 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51405.
17/10/26 12:38:28 INFO NettyBlockTransferService: Server created on 127.0.0.1:51405
17/10/26 12:38:28 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:38:28 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51405 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:38:28 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51405, None)
17/10/26 12:39:14 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:39:14 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:39:14 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:39:15 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:39:15 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:39:15 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:39:15 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:39:16 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:39:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:18 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:39:18 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:39:18 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:39:18 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:39:19 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:39:19 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:39:19 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:39:19 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:39:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:39:19 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:39:19 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:39:19 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:39:19 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1_resources
17/10/26 12:39:19 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1
17/10/26 12:39:19 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1
17/10/26 12:39:20 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/cc0c2ed0-aca2-451f-945e-aa90fd7b01f1/_tmp_space.db
17/10/26 12:39:20 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:39:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:20 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:39:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:39:20 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:39:20 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:39:22 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:39:22 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:39:48 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:39:48 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:39:48 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:39:48 INFO MemoryStore: MemoryStore cleared
17/10/26 12:39:48 INFO BlockManager: BlockManager stopped
17/10/26 12:39:48 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:39:48 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:39:48 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:39:48 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:39:48 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-3228be77-c84f-4535-be99-c09f14cd68cf
17/10/26 12:40:11 INFO SparkContext: Running Spark version 2.1.0
17/10/26 12:40:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
17/10/26 12:40:12 INFO SecurityManager: Changing view acls to: scibr
17/10/26 12:40:12 INFO SecurityManager: Changing modify acls to: scibr
17/10/26 12:40:12 INFO SecurityManager: Changing view acls groups to: 
17/10/26 12:40:12 INFO SecurityManager: Changing modify acls groups to: 
17/10/26 12:40:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(scibr); groups with view permissions: Set(); users  with modify permissions: Set(scibr); groups with modify permissions: Set()
17/10/26 12:40:12 INFO Utils: Successfully started service 'sparkDriver' on port 51460.
17/10/26 12:40:12 INFO SparkEnv: Registering MapOutputTracker
17/10/26 12:40:12 INFO SparkEnv: Registering BlockManagerMaster
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
17/10/26 12:40:12 INFO DiskBlockManager: Created local directory at C:\Users\scibr\AppData\Local\Temp\blockmgr-62df241c-eb50-458c-a9d8-060e4a9e88f9
17/10/26 12:40:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MB
17/10/26 12:40:12 INFO SparkEnv: Registering OutputCommitCoordinator
17/10/26 12:40:12 INFO Utils: Successfully started service 'SparkUI' on port 4040.
17/10/26 12:40:12 INFO SparkUI: Bound SparkUI to 127.0.0.1, and started at http://127.0.0.1:4040
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-core_2.11-2.1.0.jar with timestamp 1508989212803
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-ml_2.11-2.1.0.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar at spark://127.0.0.1:51460/jars/ai.h2o_sparkling-water-repl_2.11-2.1.0.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/no.priv.garshol.duke_duke-1.2.jar at spark://127.0.0.1:51460/jars/no.priv.garshol.duke_duke-1.2.jar with timestamp 1508989212804
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-app-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-app-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-scala_2.11-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-persist-hdfs-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-persist-s3-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.joda_joda-convert-1.7.jar at spark://127.0.0.1:51460/jars/org.joda_joda-convert-1.7.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-web-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-web-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-algos-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-algos-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-core-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-core-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-genmodel-3.10.3.2.jar with timestamp 1508989212805
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_h2o-avro-parser-3.10.3.2.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/gov.nist.math_jama-1.0.3.jar at spark://127.0.0.1:51460/jars/gov.nist.math_jama-1.0.3.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.javassist_javassist-3.18.2-GA.jar at spark://127.0.0.1:51460/jars/org.javassist_javassist-3.18.2-GA.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-math3-3.3.jar at spark://127.0.0.1:51460/jars/org.apache.commons_commons-math3-3.3.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar at spark://127.0.0.1:51460/jars/org.apache.directory.studio_org.apache.commons.lang-2.6.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-io_commons-io-2.4.jar at spark://127.0.0.1:51460/jars/commons-io_commons-io-2.4.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar at spark://127.0.0.1:51460/jars/ai.h2o_google-analytics-java-1.1.2-H2O-CUSTOM.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.aggregate_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-server-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-plus-8.1.17.v20150415.jar with timestamp 1508989212806
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.github.rwl_jtransforms-2.4.0.jar at spark://127.0.0.1:51460/jars/com.github.rwl_jtransforms-2.4.0.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/log4j_log4j-1.2.15.jar at spark://127.0.0.1:51460/jars/log4j_log4j-1.2.15.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.guava_guava-16.0.1.jar at spark://127.0.0.1:51460/jars/com.google.guava_guava-16.0.1.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.gson_gson-2.3.1.jar at spark://127.0.0.1:51460/jars/com.google.code.gson_gson-2.3.1.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar at spark://127.0.0.1:51460/jars/ai.h2o_reflections-0.9.11-h2o-custom.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.sf.opencsv_opencsv-2.3.jar at spark://127.0.0.1:51460/jars/net.sf.opencsv_opencsv-2.3.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/ai.h2o_deepwater-backend-api-1.0.2.jar at spark://127.0.0.1:51460/jars/ai.h2o_deepwater-backend-api-1.0.2.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-lang_commons-lang-2.6.jar at spark://127.0.0.1:51460/jars/commons-lang_commons-lang-2.6.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.servlet-3.0.0.v201112011016.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-continuation-8.1.17.v20150415.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-http-8.1.17.v20150415.jar with timestamp 1508989212807
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-io-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-util-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.transaction-1.1.1.v201105210645.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-webapp-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-jndi-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-xml-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-servlet-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty_jetty-security-8.1.17.v20150415.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.mail.glassfish-1.4.1.v201005082020.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar at spark://127.0.0.1:51460/jars/org.eclipse.jetty.orbit_javax.activation-1.1.0.v201105071233.jar with timestamp 1508989212808
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.google.code.findbugs_jsr305-3.0.0.jar at spark://127.0.0.1:51460/jars/com.google.code.findbugs_jsr305-3.0.0.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.avro_avro-1.8.0.jar at spark://127.0.0.1:51460/jars/org.apache.avro_avro-1.8.0.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar at spark://127.0.0.1:51460/jars/org.codehaus.jackson_jackson-core-asl-1.9.13.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar at spark://127.0.0.1:51460/jars/org.codehaus.jackson_jackson-mapper-asl-1.9.13.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.thoughtworks.paranamer_paranamer-2.7.jar at spark://127.0.0.1:51460/jars/com.thoughtworks.paranamer_paranamer-2.7.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar at spark://127.0.0.1:51460/jars/org.xerial.snappy_snappy-java-1.1.1.3.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.commons_commons-compress-1.8.1.jar at spark://127.0.0.1:51460/jars/org.apache.commons_commons-compress-1.8.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.tukaani_xz-1.5.jar at spark://127.0.0.1:51460/jars/org.tukaani_xz-1.5.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.slf4j_slf4j-api-1.7.7.jar at spark://127.0.0.1:51460/jars/org.slf4j_slf4j-api-1.7.7.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/net.java.dev.jets3t_jets3t-0.6.1.jar at spark://127.0.0.1:51460/jars/net.java.dev.jets3t_jets3t-0.6.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-httpclient_commons-httpclient-3.1.jar at spark://127.0.0.1:51460/jars/commons-httpclient_commons-httpclient-3.1.jar with timestamp 1508989212809
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-s3-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpclient-4.3.6.jar at spark://127.0.0.1:51460/jars/org.apache.httpcomponents_httpclient-4.3.6.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-kms-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar at spark://127.0.0.1:51460/jars/com.amazonaws_aws-java-sdk-core-1.10.47.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-logging_commons-logging-1.1.3.jar at spark://127.0.0.1:51460/jars/commons-logging_commons-logging-1.1.3.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/joda-time_joda-time-2.8.1.jar at spark://127.0.0.1:51460/jars/joda-time_joda-time-2.8.1.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.httpcomponents_httpcore-4.3.3.jar at spark://127.0.0.1:51460/jars/org.apache.httpcomponents_httpcore-4.3.3.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/commons-codec_commons-codec-1.6.jar at spark://127.0.0.1:51460/jars/commons-codec_commons-codec-1.6.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-core-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-core-4.0.0.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-analyzers-common-4.0.0.jar with timestamp 1508989212810
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-spatial-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-spatial-4.0.0.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.mapdb_mapdb-0.9.9.jar at spark://127.0.0.1:51460/jars/org.mapdb_mapdb-0.9.9.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/com.spatial4j_spatial4j-0.3.jar at spark://127.0.0.1:51460/jars/com.spatial4j_spatial4j-0.3.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/.ivy2/jars/org.apache.lucene_lucene-queries-4.0.0.jar at spark://127.0.0.1:51460/jars/org.apache.lucene_lucene-queries-4.0.0.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO SparkContext: Added JAR file:/C:/Users/scibr/Documents/R/win-library/3.4/sparklyr/java/sparklyr-2.1-2.11.jar at spark://127.0.0.1:51460/jars/sparklyr-2.1-2.11.jar with timestamp 1508989212811
17/10/26 12:40:12 INFO Executor: Starting executor ID driver on host localhost
17/10/26 12:40:12 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51481.
17/10/26 12:40:12 INFO NettyBlockTransferService: Server created on 127.0.0.1:51481
17/10/26 12:40:12 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
17/10/26 12:40:12 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManagerMasterEndpoint: Registering block manager 127.0.0.1:51481 with 366.3 MB RAM, BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:12 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 127.0.0.1, 51481, None)
17/10/26 12:40:13 WARN SparkContext: Using an existing SparkContext; some configuration may not take effect.
17/10/26 12:40:13 INFO SharedState: Warehouse path is 'C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive'.
17/10/26 12:40:13 INFO HiveUtils: Initializing HiveMetastoreConnection version 1.2.1 using Spark classes.
17/10/26 12:40:14 INFO HiveMetaStore: 0: Opening raw store with implemenation class:org.apache.hadoop.hive.metastore.ObjectStore
17/10/26 12:40:14 INFO ObjectStore: ObjectStore, initialize called
17/10/26 12:40:14 INFO Persistence: Property hive.metastore.integral.jdo.pushdown unknown - will be ignored
17/10/26 12:40:14 INFO Persistence: Property datanucleus.cache.level2 unknown - will be ignored
17/10/26 12:40:15 INFO ObjectStore: Setting MetaStore object pin classes with hive.metastore.cache.pinobjtypes="Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order"
17/10/26 12:40:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:16 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MFieldSchema" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MOrder" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:17 INFO MetaStoreDirectSql: Using direct SQL, underlying DB is DERBY
17/10/26 12:40:17 INFO ObjectStore: Initialized ObjectStore
17/10/26 12:40:17 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 1.2.0
17/10/26 12:40:17 WARN ObjectStore: Failed to get database default, returning NoSuchObjectException
17/10/26 12:40:18 INFO HiveMetaStore: Added admin role in metastore
17/10/26 12:40:18 INFO HiveMetaStore: Added public role in metastore
17/10/26 12:40:18 INFO HiveMetaStore: No user is added in admin role, since config is empty
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_all_databases
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_all_databases	
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_functions: db=default pat=*
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_functions: db=default pat=*	
17/10/26 12:40:18 INFO Datastore: The class "org.apache.hadoop.hive.metastore.model.MResourceUri" is tagged as "embedded-only" so does not have its own datastore table.
17/10/26 12:40:18 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/Temp/7f784349-c07c-427b-8f4c-478ae4608fda_resources
17/10/26 12:40:18 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7f784349-c07c-427b-8f4c-478ae4608fda
17/10/26 12:40:18 INFO SessionState: Created local directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/7f784349-c07c-427b-8f4c-478ae4608fda
17/10/26 12:40:18 INFO SessionState: Created HDFS directory: C:/Users/scibr/AppData/Local/spark/spark-2.1.0-bin-hadoop2.7/tmp/hive/scibr/7f784349-c07c-427b-8f4c-478ae4608fda/_tmp_space.db
17/10/26 12:40:18 INFO HiveClientImpl: Warehouse location for Hive client (version 1.2.1) is C:UsersscibrAppDataLocalsparkspark-2.1.0-bin-hadoop2.7	mphive
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:18 INFO HiveMetaStore: 0: get_database: global_temp
17/10/26 12:40:18 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: global_temp	
17/10/26 12:40:18 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
17/10/26 12:40:18 INFO SparkSqlParser: Parsing command: SHOW TABLES
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_database: default
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_database: default	
17/10/26 12:40:20 INFO HiveMetaStore: 0: get_tables: db=default pat=*
17/10/26 12:40:20 INFO audit: ugi=scibr	ip=unknown-ip-addr	cmd=get_tables: db=default pat=*	
17/10/26 12:59:08 INFO SparkContext: Invoking stop() from shutdown hook
17/10/26 12:59:08 INFO SparkUI: Stopped Spark web UI at http://127.0.0.1:4040
17/10/26 12:59:08 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
17/10/26 12:59:08 INFO MemoryStore: MemoryStore cleared
17/10/26 12:59:08 INFO BlockManager: BlockManager stopped
17/10/26 12:59:08 INFO BlockManagerMaster: BlockManagerMaster stopped
17/10/26 12:59:08 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
17/10/26 12:59:08 INFO SparkContext: Successfully stopped SparkContext
17/10/26 12:59:08 INFO ShutdownHookManager: Shutdown hook called
17/10/26 12:59:08 INFO ShutdownHookManager: Deleting directory C:\Users\scibr\AppData\Local\Temp\spark-7c33f421-546c-4166-be54-22d9ba35f7b3
